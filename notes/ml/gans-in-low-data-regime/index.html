<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Training GANs in the Low-Data Regime</title>

    <!-- Bootstrap -->
    <link href="../../../css/bootstrap.min.css" rel="stylesheet">
    <link href="../../../css/theme.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- MathJax -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      loader: {load: ['[tex]/boldsymbol']},
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: {autoNumber: "AMS"} } 
    });
    </script>
    <script type="text/javascript"
            src="../../../MathJax/MathJax.js?config=TeX-AMS_HTML-full">
    </script>

    <script type="text/javascript" src="../../../js/jquery-3.4.1.min.js"></script>    
    <script type="text/javascript" src="../../../js/bigfoot.min.js"></script>    

    <link rel="stylesheet" type="text/css" href="../../../css/bigfoot-default.css">    

</head>
<body>
<div class="container">
    <span style="visibility: hidden;">
        \(
        \def\sc#1{\dosc#1\csod}
        \def\dosc#1#2\csod{{\rm #1{\small #2}}}

        \newcommand{\dee}{\mathrm{d}}
        \newcommand{\Dee}{\mathrm{D}}
        \newcommand{\In}{\mathrm{in}}
        \newcommand{\Out}{\mathrm{out}}
        \newcommand{\pdf}{\mathrm{pdf}}
        \newcommand{\Cov}{\mathrm{Cov}}
        \newcommand{\Var}{\mathrm{Var}}

        \newcommand{\ve}[1]{\mathbf{#1}}
        \newcommand{\mrm}[1]{\mathrm{#1}}
        \newcommand{\etal}{{et~al.}}
        \newcommand{\sphere}{\mathbb{S}^2}
        \newcommand{\modeint}{\mathcal{M}}
        \newcommand{\azimint}{\mathcal{N}}
        \newcommand{\ra}{\rightarrow}
        \newcommand{\mcal}[1]{\mathcal{#1}}
        \newcommand{\X}{\mathcal{X}}
        \newcommand{\Y}{\mathcal{Y}}
        \newcommand{\Z}{\mathcal{Z}}
        \newcommand{\x}{\mathbf{x}}
        \newcommand{\y}{\mathbf{y}}
        \newcommand{\z}{\mathbf{z}}
        \newcommand{\tr}{\mathrm{tr}}
        \newcommand{\sgn}{\mathrm{sgn}}
        \newcommand{\diag}{\mathrm{diag}}
        \newcommand{\Real}{\mathbb{R}}
        \newcommand{\sseq}{\subseteq}
        \newcommand{\ov}[1]{\overline{#1}}
        \DeclareMathOperator*{\argmax}{arg\,max}
        \DeclareMathOperator*{\argmin}{arg\,min}
        \)
    </span>

    <br>
    <h1>Training GANs in the Low-Data Regime</h1>

    <ul>
        <li>In order to get good results, GANs typically require a lot of data to train: thousands or ten thousands of examples.</li>

        <li>What, though, if it is hard or impossible to find such a large quantity of data?
        <ul>
            <li>Paintings by a specific painter.</li>
            <li>Illustrations a specific artists.</li>
            <li>Medical images from patients with a specific rare malady.</li>
        </ul>
        In other words, what to do if you have several hundreds or even several tens of the training examples?
        </li>

        <li>This notes contains summaries of papers dealing with this problem.</li>
    </ul>

    <hr>
    <h2></h2>

    <ul>
        <li>Citation: Charin Kong, Jeesoo Kim, Donghoon Han, and Nojin Kwak. <b>Smoothing the Generative Latent Space with Mixup-based Distance Learning.</b> 2021.</li>

        <li>Links: <a href="https://arxiv.org/pdf/2111.11672.pdf">[PDF]</a></li>
    </ul>

    <h2>1 &nbsp; Introduction</h2>

    <ul>
        <li>Training GANs with limited data typically yields bad results because the model will easily overfits.</li>

        <li>There are techniques such as DiffAugment <a href="https://data-efficient-gans.mit.edu/">[Zhao et al. 2020]</a> and adaptive discriminator augmentation <a href="https://arxiv.org/abs/2006.06676">[Karras et al. 2020]</a> that address this problem. However, the training set requires to have hundreds to thousands training samples.</li>

        <li>Another way to deal with scarce training data is transfer learning. There are two main approaches.
        <ul>
            <li>Adapting a pre-trained source generator to the target domain [<a href="https://arxiv.org/abs/2012.02780">Li et al. 2020</a>, <a href="https://arxiv.org/abs/2002.10964">Mo et al. 2020</a>, <a href="https://arxiv.org/abs/2104.06820">Ojha et al. 2021</a>].</li>

            <li>Generalization to unseen categories through feature fusion. [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_LoFGAN_Fusing_Local_Representations_for_Few-Shot_Image_Generation_ICCV_2021_paper.pdf">Gu et al. 2021</a>, <a href="https://arxiv.org/abs/2003.03497">Hong et al. 2020</a>]</li>
        </ul>
        However, these approach still requires large data to pre-train the GAN. It's also hard to find the appropriate domain to transfer from.
        </li>

        <li>The paper says it is inspired by Ojha et al.'s work <a href="https://arxiv.org/abs/2104.06820">2021</a>.
        <ul>
            <li>They propose a novel distance regularization to transfer diversity information from the source domain to the target domain.</li>
        </ul>
        </li>

        <li></li>
    </ul>

    <p>
    <hr>
    <div class="page-header"></div>
    <p>Last modified: 2021/12/04</p>    
</div>

<script type="text/javascript">
$.bigfoot();
</script>

</body>
</html>
