<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>0058</title>

    <!-- Bootstrap -->
    <link href="../../../../../css/bootstrap.min.css" rel="stylesheet">
    <link href="../../../../../css/theme.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- MathJax -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: {autoNumber: "AMS"} }
    });
    </script>
    <script type="text/javascript"
            src="../../../../../MathJax/MathJax.js?config=TeX-AMS_HTML-full">
    </script>

    <script type="text/javascript" src="../../../../../js/jquery-3.4.1.min.js"></script>
    <script type="text/javascript" src="../../../../../js/bigfoot.min.js"></script>

    <link rel="stylesheet" type="text/css" href="../../../../../css/bigfoot-default.css">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.1/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.1/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</head>
<body>
<div class="container">
    <span style="visibility: hidden;">
        \(
        \def\sc#1{\dosc#1\csod}
        \def\dosc#1#2\csod{{\rm #1{\small #2}}}

        \newcommand{\dee}{\mathrm{d}}
        \newcommand{\Dee}{\mathrm{D}}
        \newcommand{\In}{\mathrm{in}}
        \newcommand{\Out}{\mathrm{out}}
        \newcommand{\pdf}{\mathrm{pdf}}
        \newcommand{\Cov}{\mathrm{Cov}}
        \newcommand{\Var}{\mathrm{Var}}

        \newcommand{\ve}[1]{\mathbf{#1}}
        \newcommand{\ves}[1]{\boldsymbol{#1}}
        \newcommand{\mrm}[1]{\mathrm{#1}}
        \newcommand{\etal}{{et~al.}}
        \newcommand{\sphere}{\mathbb{S}^2}
        \newcommand{\modeint}{\mathcal{M}}
        \newcommand{\azimint}{\mathcal{N}}
        \newcommand{\ra}{\rightarrow}
        \newcommand{\mcal}[1]{\mathcal{#1}}
        \newcommand{\X}{\mathcal{X}}
        \newcommand{\Y}{\mathcal{Y}}
        \newcommand{\Z}{\mathcal{Z}}
        \newcommand{\x}{\mathbf{x}}
        \newcommand{\y}{\mathbf{y}}
        \newcommand{\z}{\mathbf{z}}
        \newcommand{\tr}{\mathrm{tr}}
        \newcommand{\sgn}{\mathrm{sgn}}
        \newcommand{\diag}{\mathrm{diag}}
        \newcommand{\Real}{\mathbb{R}}
        \newcommand{\sseq}{\subseteq}
        \newcommand{\ov}[1]{\overline{#1}}
        \DeclareMathOperator*{\argmax}{arg\,max}
        \DeclareMathOperator*{\argmin}{arg\,min}

        \newcommand{\data}{\mathrm{data}}
        \newcommand{\N}{\mathcal{N}}
        \newcommand{\Hil}{\mathcal{H}}
        \)
    </span>

    <h1>Instantaneous Change of Variable Formula</h1>
    
    <hr>
    <p>Another tool to have in the belt is how to compute probability $p_t(\phi_t(x))$ when you only have the vector field $v_t$ and not the exact form of $\phi_t$.</p>

    <hr>
    <p><b>Theorem (Instanteneous change of variable formula)</b>. Let $v_t$ be a vector field that generates a probability path $p_t$. Then,
    \begin{align*}
      \frac{\partial}{\partial t} \big(\log p_t(\phi_t(x))\big) 
      = -\mrm{tr}(\nabla_{\S 2}v_t(\phi_t(x))) 
      = - \sum_{i=1}^d \nabla_{i+1} v_t^{i}(\phi_t(x)).
    \end{align*}
    To make it especially clear,
    \begin{align*}
    \nabla_1 (\log \circ p)(t,\phi_t(x))
      = -\mrm{tr}\Big((\nabla_{\S 2} v )(t,\phi_t(x))\Big) 
      = - \sum_{i=1}^d \nabla_{i+1} v^{i}(t,\phi_t(x)).
    \end{align*}
    </p>

    <p>This first appear in the neural ODE paper <a href="https://arxiv.org/abs/1806.07366">[Chen et al. 2018]</a>. </p>

    <hr>
    <p>Let's say we want to compute $\log p_t(\phi_t(x))$. The instantaneous rate of change formula allows us to write
    \begin{align*}
      \log p_t(\phi_t(x)) &= (\log \circ p)(0, \phi_0(x)) + \int_0^t \nabla_1 (\log \circ p)(u, \phi_u(x))\, \dee u \\
      &= \log p_0(x) - \int_0^t \bigg( \sum_{i=1}^d \nabla_{i+1} v^{i}(u,\phi_u(x)) \bigg)\, \dee u.
    \end{align*}
    </p>

    <hr>
    <p>With this, we can integrate the log probability the same time we integrate the vector field.</p>

<pre><code class="language-python">def euler(v, t, x, p_0, K=50):
  du = t / K
  log_p = math.log(p_0(x))
  for k in range(K):
    log_p = log_p - du * jacobian_trace(v, u, x)
    x = x + du * v(t, x)
    u = u + du
  return x, log_p
</code></pre>

    <p>Here, the function <code>jacobian_trace</code> computes $\mrm{tr}(\nabla_{\S 2}v_t(\phi_t(x)))$.</p>

    <hr>
    <p>How do you compute the Jacobian trace though? Direct computation is not desirable because we don't want to compute the Jacobian and then use just only $n$ entries of it.</p>

    <hr>
    <p>The FFJORD paper <a href="https://arxiv.org/pdf/1810.01367">[Grathworl et al. 2019]</a> suggest using the Hutchinson's trace estimator <a href="https://www.researchgate.net/publication/245083270_A_stochastic_estimator_of_the_trace_of_the_influence_matrix_for_Laplacian_smoothing_splines">[1990]</a>.</p>

    <p><b>Theorem (Hutchinson's).</b> Let $A \in \Real^{d \times d}$ be a real matrix. 
    \begin{align*}
      \tr(A) = E_{\epsilon} [\epsilon^T A \epsilon]
    \end{align*}
    where $\epsilon \in \Real^d$ is a vector sampled from a distribution where each component of the vector (1) is independent from any ohter component, (2) has mean 0, and (3) has variance 1.
    </p>
    
    <p>In fact, we can use $\epsilon \sim \mcal{N}(0,I)$.</p>

    <hr>
    <p>If we use Hutchinson's trace estimator, then how to we compute $\epsilon^T \nabla_{\S 2}v_t(\phi_t(x)) \epsilon$?</p>

    <hr>
    <p>In ML software package, we have the ability do to forward-mode automatic differentiation. This means that, for a differentiable function $f: \Real^d \ra \Real^d$, computing $$y^T \nabla_x f(x) $$ for any $y \in \Real^d$ is a feature of the library.</p>

    <hr>
    <p>In PyTorch, the function that does this is <code>torch.autograd.grad</code>. In particlar, we can write <code>jacobian_trace</code> as follows.

<pre><code class="language-python">def jacobian_trace(v, t, x):
  e = torch.randn_like(x)
  v_out = v(t, x)
  eT_Dv = torch.autograd.grad(v_out, x, grad_outputs=e, retain_graph=True)
  return (eT_Dv * e).sum(dim=1)
</code></pre>
      
    <hr>
    <p>
        <a href="../_0057/index.html">[&lt;&lt;]</a> 
        <a href="../../index.html">[Top]</a>
        <a href="../_0059/index.html">[&gt;&gt;]</a> 
    </p>
  </div>

<script type="text/javascript">
$.bigfoot();
</script>

</body>
</html>