\documentclass[10pt]{article}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage[amsthm, thmmarks]{ntheorem}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{verse}
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{CJKutf8}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{definition}[lemma]{Definition}
\newtheorem{proposition}[lemma]{Proposition}
\newtheorem{corollary}[lemma]{Corollary}
\newtheorem{claim}[lemma]{Claim}
\newtheorem{example}[lemma]{Example}

\newcommand{\dee}{\mathrm{d}}
\newcommand{\Dee}{\mathrm{D}}
\newcommand{\In}{\mathrm{in}}
\newcommand{\Out}{\mathrm{out}}
\newcommand{\pdf}{\mathrm{pdf}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Var}{\mathrm{Var}}

\newcommand{\ve}[1]{\mathbf{#1}}
\newcommand{\ves}[1]{\boldsymbol{#1}}
\newcommand{\mrm}[1]{\mathrm{#1}}
\newcommand{\etal}{{et~al.}}
\newcommand{\sphere}{\mathbb{S}^2}
\newcommand{\modeint}{\mathcal{M}}
\newcommand{\azimint}{\mathcal{N}}
\newcommand{\ra}{\rightarrow}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\sseq}{\subseteq}
\newcommand{\ov}[1]{\overline{#1}}

\title{Introduction to Analytical Mechanics}
\author{Pramook Khungurn}

\begin{document}
  \maketitle

  This note is written as I read \begin{CJK}{UTF8}{min}「量子力学を学ぶための解析力学入門」\end{CJK} by Yasushi Takahashi. This is a book that briefly introduces analytical mechanics for those who want to use it do to something else, which is perfect for me.

  \section{Euler--Lagrange and Hamilton's Equations} \label{sec:el-hamilton}

  \begin{itemize}
  	\item Sovling a problem in classical mechanics generally involves two steps.
  	\begin{enumerate}
  		\item Writing the equations of motion of the system.
  		\item Solving the equations.
  	\end{enumerate}

  	\item When solving the equations of motion, it is advantageous to choose variables that simplify the problem.
  	\begin{itemize}
  		\item For example, change from Cartesian coordinates $(x,y,z)$ to spherical coordinates $(r,\theta,\phi)$.
  	\end{itemize}

  	\item The change of variable calculation is often cumbersome, especially when Newton's equation ($F = ma$) is used without modification.

  	\item However, if we rewrite Newton's equation in another form, we can simplify the calculation by a lot.
  	\begin{itemize}
  		\item One of such a form is using the {\bf Lagrangian}.
  		\item Another form is using the {\bf Hamiltonian}.
  	\end{itemize}

  	\item The Hamiltonian form is more powerful because it can perform changes of variables that the Lagrangian form cannot.
  \end{itemize}

  \subsection{Newton's Equation of Motion}

  \begin{itemize}
  	\item Consider a particle whose mass is $m$ and whose position is denoted by vector $\ve{x}$.

  	\item Suppose we want to compute the trajectory of a particle under the influence of a force field defined by a potential function $V(\ve{x})$ as follows:
  	\begin{align*}
  		\ve{F}(\ve{x}) = -\nabla_{\ve{x}} V(\ve{x}).
  	\end{align*}

  	\item The equation of motion is given by:
  	\begin{align*}
  		m \frac{\dee^2 \ve{x}}{\dee t} = \ve{F}(\ve{x}).
  	\end{align*}

  	\item The above equation is in given Cartesian coordinates $\ve{x} = (x,y,z)^T$. However, we may want to work with spherical coordinates $(r,\theta,\phi)$ where
  	\begin{align*}
  		x &= r \sin\theta \cos\phi \\
  		y &= r \sin\theta \sin\phi \\
  		z &= r \cos\theta
  	\end{align*}
  	instead.

  	\item To do so, we might write the equation of motion in its spherical coordinate form. The equations are given by:
  	\begin{align}
  		m \ddot{r} - mr(\dot{\theta}^2 + \dot{\phi} \sin^2 \theta) 
  		&= -\frac{\partial V(r, \theta,\phi)}{\partial r} \label{newton-polar-1}\\
  		\frac{\dee}{\dee t} (mr^2 \dot{\theta}) - mr^2\dot{\phi}^2 \sin \theta \cos \theta 
  		&= -\frac{\partial V(r, \theta,\phi)}{\partial \theta} \label{newton-polar-2} \\
  		\frac{\dee}{\dee t} (mr^2 \dot{\phi} \sin^2 \theta)
  		&= -\frac{\partial V(r, \theta,\phi)}{\partial \phi} \label{newton-polar-3}
  	\end{align}
  	You can try to derive the above three equations, but I assure you that the calculation would be long and tedious.

  	\item In order to simplify the calculation, it is advantageous to look for an invariance of the system.

  	\item One invariance that is well know is the {\bf conservation of energy}, which says that the total energy $$E = T + V$$ stays constant with respect to time. Here, $$T = \frac{1}{2} m \| \dot{\ve{x}} \|^2 = \frac{1}{2} m (\dot{\ve{x}} \cdot \dot{\ve{x}})$$ is the kinetic energy of the particle.

  	\item We can show that the time derivative of energy is indeed zero. In particular,
  	\begin{align*}
  		\frac{\dee E}{\dee t}
  		&= \frac{\dee}{\dee t} (T(\dot{\ve{x}}) + V(\ve{x}))
  		= \frac{\dee \dot{\ve{x}}}{\dee t} \cdot \frac{\partial T}{\partial \dot{\ve{x}}} + \frac{\dee\ve{x}}{\dee t} \cdot \frac{\partial V}{\partial \ve{x}}
  		= \ddot{\ve{x}} \cdot (m\dot{\ve{x}}) + \dot{\ve{x}} \cdot \nabla_{\ve{x}} V \\
  		&= \dot{\ve{x}} \cdot (m\ddot{\ve{x}} + \nabla_{\ve{x}} V).
  	\end{align*}
  	By our equation of motion, $m\ddot{\ve{x}} = - \nabla_{\ve{x}} V$, so $m\ddot{\ve{x}} + \nabla_{\ve{x}} V = 0$, and the total energy must be conserved.
  \end{itemize}

  \subsection{Lagragrian and Euler--Lagrange Equation}

  \begin{itemize}
  	\item Define the {\bf Lagragian} $L$ as:
  	\begin{align*}
  		L = T - V.
  	\end{align*}

  	\item Note that the Lagragian is not conserved like the energy $E$.

  	\item However, we have that
  	\begin{align*}
  		\frac{\partial L}{\partial \ve{x}} 
  		&= \frac{\partial }{\partial \ve{x}} (T(\dot{\ve{x}}) - V(\ve{x}))
  		= \frac{\partial V(\ve{x})}{\partial \ve{x}}
  		= - \nabla_{\ve{x}} V(\ve{x}) \\
  		\frac{\partial L}{\partial \dot{\ve{x}}}
  		&= \frac{\partial }{\partial \overline{\ve{x}}} (T(\dot{\ve{x}}) - V(\ve{x}))
  		= \frac{\partial T(\dot{\ve{x}})}{\partial \dot{\ve{x}}}
  		= m\dot{\ve{x}}.
  	\end{align*}
  	As a result,
  	\begin{align*}
  		\frac{\dee}{\dee t}\bigg( \frac{\partial L}{\partial \dot{\ve{x}}} \bigg) 
  		- \frac{\partial L}{\partial \ve{x}}
  		= m\ddot{\ve{x}} + \nabla_{\ve{x}} V = 0.
  	\end{align*}

  	\item The equation
  	\begin{align*}
  		\frac{\dee}{\dee t}\bigg( \frac{\partial L}{\partial \ve{x}} \bigg) - \frac{\partial L}{\partial \ve{x}} = 0
  	\end{align*}
  	is called the {\bf Euler--Lagrange equation}.

  	\item The Euler--Lagrange equation is equivalent to Newton's law of motion in the sense that $\ve{x}$ is a solution to the EL equation iff it is a solution to Newton's equation ($\ve{F} = m\ddot{\ve{x}}$).

  	\item As we shall see later, solving the EL equation is equivalent to finding a function $\ve{x}(t)$ that is a stationary point of a functional (the ``action integral''). Takahashi gives an interesting perspective by pointing out a similarity with unconstrained function optimization. In this setting, we are given a function $f(\cdot)$, we solve for $x$ that satisfies $\dee f / \dee x = 0$. The process is the same when solving for a trajectory. It's just that the equation becomes the EL equation instead.
  \end{itemize}

  \subsection{Invariance Under Coordinate System Change}

  \begin{itemize}
  	\item A nice property of the EL equation is that its form remain the same when we use a different coordinate system.

  	\item For example, the EL equation(s) under spherical coordinates would be:
  	\begin{align*}
  		\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{r}} \bigg) - \frac{\partial L}{\partial r} &= 0 \\
  		\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{\theta}} \bigg) - \frac{\partial L}{\partial \theta} &= 0 \\
  		\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{\phi}} \bigg) - \frac{\partial L}{\partial \phi} &= 0.
  	\end{align*}
  	One can check that the equations above are the same as Equations $\eqref{newton-polar-1}$, $\eqref{newton-polar-2}$, and $\eqref{newton-polar-3}$ by hand.

  	\item In order to prove invariance under coordinate system change, we shall move away from Cartesian and polar coordinates and work in {\bf generalized coordinates}. Say, the positions of particles in our system can be described by $f$ variables $q_1, q_2, \dotsc, q_f$. Here, $f$ is called the {\bf degrees of freedom} of the system.
  	\begin{itemize}
  		\item For example, if our system consists of only one particle, then its position can be described by 3 degrees of freedom: $(x,y,z)$ or $(r,\theta,\phi)$ or what have you. A system of $N$ independent particles would require $3N$ degrees of freedom.

  		\item It is important to note that the degrees of freedom in a system of $N$ particles need not be $3N$ because {\bf it can be lower}. For example, if we have a system of $2$ particles in 3D that are contrained so that the distance between them is constant, then the system has $5$ degrees of freedom instead of the full $6$.
  	\end{itemize}

  	\item Given that the system can be described by generalized coordinates $q_1, q_2, \dotsc, q_f$, the {\bf Lagrangian} is a scalar function of the generalized coordinates and their time derivatives
  	\begin{align*}
  		L = L(q_1, q_2, \dotsc, q_f, \dot{q}_1, \dot{q}_2, \dotsc, \dot{q}_f),
  	\end{align*}
  	such that the equation of motion of the system is the following Euler--Lagrange equations:
  	\begin{align}
  	\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_1} \bigg) - \frac{\partial L}{\partial q_1} &= 0 \notag \\
  	\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_2} \bigg) - \frac{\partial L}{\partial q_2} &= 0 \notag \\
  	&\ \,\vdots \label{euler-lagrange-gc} \\
  	\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_f} \bigg) - \frac{\partial L}{\partial q_f} &= 0. \notag
  	\end{align}

  	\item \begin{theorem} \label{lagrangian-change-of-coordiate}
  		The Euler--Lagrange equation is invariant under coordinate system change. In other words, let $Q_1, Q_2, \dotsc, Q_f$ be another system of coordinates where we can write
  		\begin{align*}
  			q_1 &= q_1(Q_1, Q_2, \dotsc, Q_f),\\
  			q_2 &= q_1(Q_1, Q_2, \dotsc, Q_f),\\
  			&\ \,\vdots \\
  			q_f &= q_f(Q_1, Q_2, \dotsc, Q_f).
  		\end{align*}
  		Then, if the system of equations $\eqref{euler-lagrange-gc}$ holds, then the following system of equations
  		\begin{align*}
	  	\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{Q}_1} \bigg) - \frac{\partial L}{\partial Q_1} &= 0 \\
	  	\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{Q}_2} \bigg) - \frac{\partial L}{\partial Q_2} &= 0 \\
	  	&\ \,\vdots \\
	  	\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{Q}_f} \bigg) - \frac{\partial L}{\partial Q_f} &= 0.
	  	\end{align*}
	  	also holds.
  	\end{theorem}

  	\begin{proof}
  		First, let us take the time derivative of $q_i$. By the law of total derivative, we have that
  		\begin{align} \label{q-time-deriv}
  			\dot{q}_i 
  			&= \frac{\partial q_i}{\partial Q_1} \dot{Q}_1 + \frac{\partial q_i}{\partial Q_2} \dot{Q}_2 + \dotsb + \frac{\partial q_i}{\partial Q_f} \dot{Q}_f
  			= \sum_{j=1}^f \frac{\partial q_i}{\partial Q_j} \dot{Q}_j.
  		\end{align}
  		Because we can write the $q_i$'s as functions of the $Q_k$'s and the $\dot{q}_i$'s as functions of the $Q_k$'s and the $\dot{Q}_k$'s, we have that $L$ is a function of the $Q_k$'s their time derivates.

  		Next, taking the partial derivative with respect to $\dot{Q}_k$ of both sides of Equation $\eqref{q-time-deriv}$, we have that
  		\begin{align} \label{dropping-dots}
  			\frac{\partial \dot{q}_i}{\partial \dot{Q}_k} 
  			= \sum_{j=1}^f \frac{\partial}{\partial \dot{Q}_k} \bigg( \frac{\partial q_i}{\partial Q_j} \dot{Q}_j \bigg)
  			= \sum_{j=1}^f \frac{\partial q_i}{\partial Q_j} \frac{\partial \dot{Q}_j }{\partial \dot{Q}_k}
  			= \frac{\partial q_i}{\partial Q_k}.
  		\end{align}
  		Taking the time derivative of both sides, we have that 
  		\begin{align} \label{dot-q-by-dot-big-Q}
  			\frac{\dee}{\dee t}\bigg( \frac{\partial \dot{q}_i}{\partial \dot{Q}_k}  \bigg)
  			&= \frac{\dee}{\dee t}\bigg( \frac{\partial q_i}{\partial Q_k}  \bigg)
  			= \sum_{j=1}^f \frac{\partial}{\partial Q_j} \bigg( \frac{\partial q_i}{\partial Q_k} \bigg) \dot{Q}_j
  			= \sum_{j=1}^f \frac{\partial^2 q_i}{\partial Q_j \partial Q_j} \dot{Q}_j.
  		\end{align}

  		On the other hand, consider Equation \eqref{q-time-deriv} again. Because each $\partial q_i / \partial Q_j$ on the RHS is a function of only $Q_1$, $Q_2$, and $Q_f$, we have that
  		\begin{align} \label{dot-q-by-big-q}
  		\frac{\partial \dot{q}_i}{\partial Q_k}
  		= \frac{\partial}{\partial Q_k} \bigg( \sum_{j=1}^f \frac{\partial q_i}{\partial Q_j} \dot{Q}_j \bigg)
  		= \sum_{j=1}^f \frac{\partial}{\partial Q_k} \bigg( \frac{\partial q_i}{\partial Q_j} \bigg) \dot{Q}_j
  		= \sum_{j=1}^f \frac{\partial^2 q_i}{\partial Q_j \partial Q_j} \dot{Q}_j.
  		\end{align}

  		Equating \eqref{dot-q-by-dot-big-Q} and \eqref{dot-q-by-big-q}, we have that
  		\begin{align} \label{time-deriv-qq-qq-relation}
  			\frac{\dee}{\dee t}\bigg( \frac{\partial \dot{q}_i}{\partial \dot{Q}_k} \bigg)
  			= \frac{\dee}{\dee t}\bigg( \frac{\partial q_i}{\partial Q_k} \bigg)
  			= \frac{\partial \dot{q}_i}{\partial Q_k}
  		\end{align}
  		for any $k$.

  		Let us now take the partial derivatives of $L$ with respect to $Q_k$ and $\dot{Q}_k$. First,
  		\begin{align} \label{partial-L-partial-Q}
  			\frac{\partial L}{\partial Q_k}
  			= \sum_{j=1}^f \bigg( \frac{\partial L}{\partial q_j} \frac{\partial q_j}{\partial Q_k}  + \frac{\partial L}{\partial \dot{q}_j} \frac{\partial \dot{q}_j}{\partial Q_k} \bigg)
  		\end{align}
  		Next,
  		\begin{align*}
  			\frac{\partial L}{\partial \dot{Q}_k}
  			= \sum_{j=1}^f \bigg( \frac{\partial L}{\partial q_j} \frac{\partial q_j}{\partial \dot{Q}_k}  + \frac{\partial L}{\partial \dot{q}_j} \frac{\partial \dot{q}_j}{\partial \dot{Q}_k} \bigg)
  		\end{align*}
  		However, because $q_j$ is a function of only $Q_1$, $\dotsc$, $Q_f$, we have that $\frac{\partial q_j}{\partial \dot{Q}_k} = 0$. As a result,
  		\begin{align*}
  			\frac{\partial L}{\partial \dot{Q}_k}
  			= \sum_{j=1}^f \frac{\partial L}{\partial \dot{q}_j} \frac{\partial \dot{q}_j}{\partial \dot{Q}_k}
  			= \sum_{j=1}^f \frac{\partial L}{\partial \dot{q}_j} \frac{\partial q_j}{\partial Q_k}.
  		\end{align*}
  		Here, the last part follows from Equation~\eqref{dropping-dots}. Taking the time derivative of the above equation, we have
  		\begin{align*}
  			\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{Q}_k} \bigg)
  			= \sum_{j=1}^f \frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \frac{\partial q_j}{\partial Q_k} \bigg)
  			= \sum_{j=1}^f 
  			\bigg[ 
  			\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \frac{\partial q_j}{\partial Q_k}
  			+  \frac{\partial L}{\partial \dot{q}_j} \frac{\dee}{\dee t} \bigg( \frac{\partial q_j}{\partial Q_k} \bigg)
  			\bigg]
  		\end{align*}
  		Using \eqref{time-deriv-qq-qq-relation}, the above equations becomes
  		\begin{align} \label{partial-L-partial-dot-Q}
  			\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{Q}_k} \bigg)
  			= \sum_{j=1}^f 
  			\bigg[ 
  			\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \frac{\partial q_j}{\partial Q_k}
  			+  \frac{\partial L}{\partial \dot{q}_j} \frac{\partial \dot{q}_j}{\partial Q_k}
  			\bigg]
  		\end{align}
  		Subtracing \eqref{partial-L-partial-Q} from \eqref{partial-L-partial-dot-Q}, we have that
  		\begin{align*}
  			\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{Q}_k} \bigg) - \frac{\partial L}{\partial Q_k}
  			&= \sum_{j=1}^f \bigg[ 
  			\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \frac{\partial q_j}{\partial Q_k}
  			 -  \frac{\partial L}{\partial q_j} \frac{\partial q_j}{\partial Q_k} \bigg]
  			= \sum_{j=1}^f \bigg[ 
  			\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) 
  			 -  \frac{\partial L}{\partial q_j} \bigg] \frac{\partial q_j}{\partial Q_k}
  			 = 0
  		\end{align*}
  		as required.
  	\end{proof}

  	\item Note that the form of the EL equation remains the same for all coordinate changes that only involves {\bf the values of the coordinates themselves}.
  	\begin{itemize}
  		\item In other words, if the $q_i$'s are functions of only the $Q_j$'s, then the form of the EL equation does not change.

  		\item On the other hand, we cannot have the $q_i$'s be functions of both the $Q_j$'s and $\dot{Q}_j$'s and expact that the EL equation would remain the same.
  	\end{itemize}
  \end{itemize}

  \subsection{Hamilton's Equations}

  \begin{itemize}
  	\item From the last section, we learned that the EL equation is invariant under a class of coordinate transformations. However, it is not invariant under transformations where we write $q$ as a function of both $Q$ and $\dot{Q}$.

  	\item The equation of motion formulated under the Hamiltonian formalism, however, remains invariant under a larger class of transformations.

  	\item To get to the Hamiltonian formalism, we rewrite Newton's equation with momentum
  	\begin{align} \label{momentum-def}
  		\ve{p} = m \dot{\ve{x}},
  	\end{align}
  	which results in
  	\begin{align} \label{newton-with-momentum}
  		\dot{\ve{p}} = -\nabla_{\ve{x}}V(\ve{x}).
  	\end{align}

  	\item Note that with the introdution of momentum, the one equation $m\ddot{\ve{x}} = -\nabla_{\ve{x}}V(\ve{x})$, which involves a second-order derivative, now becomes two equations \eqref{momentum-def} and \eqref{newton-with-momentum}, both involving only first order derivatives. It seems that we have traded one more equation with a reduction in the order of derivatives in the equations.

  	\item Using the momentum, the total energy can be written as:
  	\begin{align*}
  		E = T + V = \frac{1}{2m}  \| \ve{p} \|^2 + V
  	\end{align*}

  	\item Normally, the {\bf Hamiltonian} is defined to be the total energy of the system
  	\begin{align*}
  		H = \frac{1}{2m}  \| \ve{p} \|^2 + V.
  	\end{align*}
  	However, the actual definition is actually more general. We will discuss this later.

  	\item Taking the partial derivatives of $H$ with respect to $\ve{x}$ and $\ve{p}$, we have that
  	\begin{align*}
  		\frac{\partial H}{\partial \ve{p}} &= \frac{1}{m}\ve{p}, \\
  		\frac{\partial H}{\partial \ve{x}} &= \nabla_{\ve{x}} V
  	\end{align*}
  	In other words,
  	\begin{align*}
  		\frac{\partial H}{\partial \ve{p}} &= \dot{\ve{x}}, \\
  		\frac{\partial H}{\partial \ve{x}} &= -\dot{\ve{p}}.
  	\end{align*}
  	These two equations are {\bf Hamilton's equations}.

  	\item Let us show that Hamilton's equations remain unchanged under a more general class of coordinate transformations. Suppose we want to write the equations of motion in terms of $\ve{X}$ and $\ve{P}$ where
  	\begin{align*}
  		\ve{X} &= \alpha \ve{x} + \beta \ve{p} \\
  		\ve{P} &= -\beta \ve{x} + \alpha \ve{p}
  	\end{align*}
  	where $\alpha^2 + \beta^2 = 1$. (In other words, $(\ve{X},\ve{P})$ is a ``2D rotation'' $(\ve{x}, \ve{p})$.) Note that this transformation would not preserve the EL equation because it involves mixing $\ve{x}$ with $\ve{p}$. The latter contains time derivatives of $\ve{x}$.

  	We can rewrite the above equations in matrix form:
  	\begin{align*}
  		\begin{bmatrix}
  			\ve{X} \\
  			\ve{P}
  		\end{bmatrix}
  		&= \begin{bmatrix}
  			\alpha & \beta \\
  			-\beta & \alpha
  		\end{bmatrix}
  		\begin{bmatrix}
  			\ve{x} \\
  			\ve{p}
  		\end{bmatrix} \\
  		\begin{bmatrix}
  			\alpha & -\beta \\
  			\beta & \alpha
  		\end{bmatrix}
  		\begin{bmatrix}
  			\ve{X} \\
  			\ve{P}
  		\end{bmatrix}
  		&= 
  		\begin{bmatrix}
  			\alpha & -\beta \\
  			\beta & \alpha
  		\end{bmatrix}
  		\begin{bmatrix}
  			\alpha & \beta \\
  			-\beta & \alpha
  		\end{bmatrix}
  		\begin{bmatrix}
  			\ve{x} \\
  			\ve{p}
  		\end{bmatrix} \\
  		\begin{bmatrix}
  			\alpha & -\beta \\
  			\beta & \alpha
  		\end{bmatrix}
  		\begin{bmatrix}
  			\ve{X} \\
  			\ve{P}
  		\end{bmatrix}
  		&= 
  		\begin{bmatrix}
  			1 & 0 \\
  			0 & 1
  		\end{bmatrix}
  		\begin{bmatrix}
  			\ve{x} \\
  			\ve{p}
  		\end{bmatrix} \\
  		\begin{bmatrix}
  			\alpha & -\beta \\
  			\beta & \alpha
  		\end{bmatrix}
  		\begin{bmatrix}
  			\ve{X} \\
  			\ve{P}
  		\end{bmatrix}
  		&=   		
  		\begin{bmatrix}
  			\ve{x} \\
  			\ve{p}
  		\end{bmatrix}.
  	\end{align*}
  	In other words,
  	\begin{align*}
  		\ve{x} &= \alpha \ve{X} - \beta \ve{P} \\
  		\ve{p} &= \beta \ve{X} + \alpha \ve{P}.
  	\end{align*}
  	This gives
  	\begin{align*}
  		\frac{\partial\ve{x}}{\partial \ve{P}} &= -\beta I^{3\times 3}
  		&\frac{\partial\ve{x}}{\partial \ve{X}} &= \alpha I^{3\times 3} \\
  		\frac{\partial\ve{p}}{\partial \ve{P}} &= \alpha I^{3\times 3}
  		&\frac{\partial\ve{p}}{\partial \ve{X}} &= \beta I^{3\times 3}
  	\end{align*}
  	where $I^{3\times 3}$ is the $3 \times 3$ identity matrix. So,
  	\begin{align*}
  		\frac{\partial H}{\partial \ve{P}}
  		&= \frac{\partial H}{\partial \ve{x}} \frac{\partial \ve{x}}{\partial \ve{P}} + \frac{\partial H}{\partial \ve{p}} \frac{\partial \ve{p}}{\partial \ve{P}}
  		= -\beta \frac{\partial H}{\partial \ve{x}} + \alpha \frac{\partial H}{\partial \ve{p}} \\
  		\frac{\partial H}{\partial \ve{X}}
  		&= \frac{\partial H}{\partial \ve{x}} \frac{\partial \ve{x}}{\partial \ve{X}} + \frac{\partial H}{\partial \ve{p}} \frac{\partial \ve{p}}{\partial \ve{X}} 
  		=  \alpha \frac{\partial H}{\partial \ve{x}}  + \beta \frac{\partial H}{\partial \ve{p}}.
  	\end{align*}

  	From the definition of $\ve{X}$ and $\ve{P}$, we have that
  	\begin{align*}
  		\dot{\ve{X}} &= \alpha \dot{\ve{x}} + \beta \dot{\ve{p}} \\
  		\dot{\ve{P}} &= -\beta \dot{\ve{x}} + \alpha \dot{\ve{p}}.
  	\end{align*}
  	As a result,
  	\begin{align*}
  		\frac{\partial H}{\partial \ve{P}} - \dot{\ve{X}}
  		&= -\beta \frac{\partial H}{\partial \ve{x}} + \alpha \frac{\partial H}{\partial \ve{p}} -\alpha \dot{\ve{x}} - \beta \dot{\ve{p}}
  		= -\beta\bigg( \frac{\partial H}{\partial \ve{x}} + \dot{\ve{p}} \bigg) + \alpha \bigg( \frac{\partial H}{\partial \ve{p}} - \dot{\ve{x}} \bigg) = 0 \\
  		\frac{\partial H}{\partial \ve{X}} + \dot{\ve{P}}
  		&= \alpha \frac{\partial H}{\partial \ve{x}}  + \beta \frac{\partial H}{\partial \ve{p}} -\beta \dot{\ve{x}} + \alpha \dot{\ve{p}}
  		= \alpha \bigg( \frac{\partial H}{\partial \ve{x}} + \dot{\ve{p}} \bigg) + \beta \bigg( \frac{\partial H}{\partial \ve{p}} - \dot{\ve{x}} \bigg) = 0.
  	\end{align*}
  	In other words,
  	\begin{align*}
  		\frac{\partial H}{\partial \ve{P}} &= \dot{\ve{X}} \\
  		\frac{\partial H}{\partial \ve{X}} &= -\dot{\ve{P}}
  	\end{align*}
  	as required.

  	\item The change of coordinates that preserve Hamilton's equations are called {\bf canonical transformations}. We will discuss this later.

  	\item While it is clear right now what the relationship between the position $\ve{x}$ and the momentum $\ve{p}$ is, it might not be so clear when we define the Hamiltonian using generalized coordinates. (I mean, think of how would you expression momentum in polar coordinates.) We will discuss how to identify generalized momentum later as well.

  	\item For now, let us give a definition of the Hamiltonian using the generalized coordinates and generalized momentum.

  	Let the state of a system be described by generalized coordinates $q_1$, $q_2$, $\dotsc$, $q_f$ and generalized momentum $p_1$, $p_2$, $\dotsc$, $p_f$. The {\bf Hamiltonian} is a scalar function
  	$$H = H(q_1, q_2, \dotsc, q_f, p_1, p_2, \dotsc, p_f)$$ such that the equation of motion of the system is given by the following {\bf Hamilton's equations}:
  	\begin{align*}
  		\frac{\partial H}{\partial \ve{p}} &= \dot{\ve{q}} \\
  		\frac{\partial H}{\partial \ve{q}} &= -\dot{\ve{p}}.
  	\end{align*}
  	Here, $\ve{q} = (q_1, q_2, \dotsc, q_f)^T$ and $\ve{p} = (p_1, p_2, \dotsc, p_f)^T$.
  \end{itemize}
  
  \section{Hamilton's Principle} \label{sec:hamilton-principle}

  \begin{itemize}
  	\item The goal of this section is to derive the Euler--Lagrange equation from the condition that it yields a stationary point of the ``action integral.'' There are two reasons for doing this.
  	\begin{enumerate}
  		\item First, by showing that the EL equation arises from finding a stationary point of a functional, it becomes clear that its solution is the same no matter what coordinate systems are used.

  		\item Second, this fact about the EL equation is very convenient when we reason about transformations that preserve the Hamiltonian later.
  	\end{enumerate}

  	\item Let $L = L(q_1, q_2, \dots, q_f, \dot{q}_1, \dot{q}_2, \dotsc, \dot{q}_f)$ of $f$ generalized coordinate and their time derivatives. The {\bf action integral} is defined to be
  	\begin{align*}
  		I = I(q_1, q_2, \dots, q_f) = \int_{t_1}^{t_2} L(q_1, q_2, \dots, q_f, \dot{q}_1, \dot{q}_2, \dotsc, \dot{q}_f)\, \dee t.
  	\end{align*}
  	where $t_1 < t_2$ are given time values. 

  	\item \begin{theorem}[Hamilton's principle] Let the values of $q_1, q_2, \dotsc, q_f$ at $t_1$ and $t_2$ be given to us as initial conditios. Then, a solution to the Euler--Lagrange equation is a stationary point of the action integral.
  	\end{theorem}

  	\begin{proof}
  		Note that all the generalized coodinates $q_1$, $q_2$, $\dotsc$, $q_f$ are actually functions of $t$: $q_1(t)$, $q_2(t)$, $\dotsc$, $q_f(t)$. Let $\eta_1(t)$, $\eta_2(t)$, $\dotsc$, $\eta_f(t)$ be arbitrary functions with the constraints that $\eta_i(t_1) = \eta_i(t_2) = 0$ because we want to satisfy our initial conditions. Let $s$ be a scalar variable. Define
  		\begin{align*}
  			\phi(s) = I(q_1 + s\eta_1, q_2 + s\eta_2, \dotsc, q_f + s\eta_f).
  		\end{align*}
  		Consider the derivative of $\phi(s)$ with respect to $s$.
  		\begin{align*}
  		\frac{\dee \phi}{\dee s}  		
  		&= \frac{\dee}{\dee s} \int_{t_1}^{t_2} L(q_1 + s\eta_1, \dotsc, q_f + s\eta_f, \dot{q}_1 + s\dot{\eta}_1, \dotsc, \dot{q}_f + s\dot{\eta}_f)\ \dee t \\
  		&= \int_{t_1}^{t_2} \frac{\dee}{\dee s} L(q_1 + s\eta_1, \dotsc, q_f + s\eta_f, \dot{q}_1 + s\dot{\eta}_1, \dotsc, \dot{q}_f + s\dot{\eta}_f)\ \dee t \\
  		&= \int_{t_1}^{t_2} \frac{\dee}{\dee s} L(q_1 + s\eta_1, \dotsc, q_f + s\eta_f, \dot{q}_1 + s\dot{\eta}_1, \dotsc, \dot{q}_f + s\dot{\eta}_f)\ \dee t \\
  		&= \int_{t_1}^{t_2} \bigg( \sum_{j=1}^f \frac{\partial L}{\partial (q_j + s\eta_j)} \frac{\dee (q_j + s\eta_j)}{\dee s} + \sum_{j=1}^f \frac{\partial L}{\partial (\dot{q}_j + s\dot{\eta}_j)} \frac{\dee (\dot{q}_j + s\dot{\eta}_j)}{\dee s}\bigg)\, \dee t \\
  		&= \int_{t_1}^{t_2} \bigg( \sum_{j=1}^f \frac{\partial L}{\partial (q_j + s\eta_j)} \eta_j + \sum_{j=1}^f \frac{\partial L}{\partial (\dot{q}_j + s\dot{\eta}_j)} \dot{\eta}_j \bigg)\, \dee t.
  		\end{align*}
  		Setting $s = 0$, we have
  		\begin{align}
  		\frac{\dee \phi}{\dee s}\bigg|_{s=0}
  		&= \int_{t_1}^{t_2} \bigg( \sum_{j=1}^f \frac{\partial L}{\partial q_j} \eta_j + \sum_{j=1}^f \frac{\partial L}{\partial \dot{q}_j} \dot{\eta}_j \bigg)\, \dee t \notag \\
  		&= \sum_{j=1}^f \bigg( \int_{t_1}^{t_2} \frac{\partial L}{\partial q_j} \eta_j\, \dee t \bigg) + \sum_{j=1}^f \bigg( \int_{t_1}^{t_2} \frac{\partial L}{\partial \dot{q}_j} \dot{\eta}_j \, \dee t \bigg). \label{dee-phi-dee-s-zero}
  		\end{align}
  		Let us simplify the second integral on the RHS. We know that
  		\begin{align*}
  			\frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \eta_j \bigg)
  			= \frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \eta_j + \frac{\partial L}{\partial \dot{q}_j} \dot{\eta}_j.
  		\end{align*}
  		Integrating both side from $t_1$ to $t_2$, we have that
  		\begin{align*}	
  		\bigg[ \frac{\partial L}{\partial \dot{q}_j} \eta_j \bigg]_{t = t_1}^{t=t_2}
  		= \int_{t_1}^{t_2}  \frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \eta_j\, \dee t
  		+ \int_{t_1}^{t_2} \frac{\partial L}{\partial \dot{q}_j} \dot{\eta}_j\, \dee t
  		\end{align*}
  		Because we chose $\eta_j(t_1) = \eta_j(t_2) = 0$, we have that
  		\begin{align*}
  		0
  		= \int_{t_1}^{t_2}  \frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \eta_j\, \dee t
  		+ \int_{t_1}^{t_2} \frac{\partial L}{\partial \dot{q}_j} \dot{\eta}_j\, \dee t.
  		\end{align*}
  		In other words,
  		\begin{align*}
  		\int_{t_1}^{t_2} \frac{\partial L}{\partial \dot{q}_j} \dot{\eta}_j\, \dee t 
  		= - \int_{t_1}^{t_2}  \frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \eta_j\, \dee t.
  		\end{align*}
  		Substituting back to \eqref{dee-phi-dee-s-zero}, we have
  		\begin{align*}
  		\frac{\dee \phi}{\dee s}\bigg|_{s=0}
  		&= \sum_{j=1}^f \bigg( \int_{t_1}^{t_2} \frac{\partial L}{\partial q_j} \eta_j\, \dee t \bigg)
  		- \sum_{j=1}^f  \bigg[ \int_{t_1}^{t_2}  \frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \eta_j\, \dee t \bigg] \\
  		&= \sum_{j=1}^f \int_{t_1}^{t_2} \eta_j \bigg[ \frac{\partial L}{\partial q_j} - \frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \bigg]\, \dee t.
  		\end{align*}
  		At a stationary point of $I$, the LHS should be zero. In other words,
  		\begin{align*}
  		0 = \sum_{j=1}^f \int_{t_1}^{t_2} \eta_j \bigg[ \frac{\partial L}{\partial q_j} - \frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) \bigg]\, \dee t.
  		\end{align*}
  		The above quation holds for all choice of function $\eta_j$'s if and only if
  		\begin{align*}
  			\frac{\partial L}{\partial q_j} - \frac{\dee}{\dee t} \bigg( \frac{\partial L}{\partial \dot{q}_j} \bigg) = 0,
  		\end{align*}
  		which means the EL equations are satisfied. 

  		It should be clear that, if we start from a solution where the EL equations are satisified, we can deduce that $(\dee \phi / \dee s)(0) = 0$ for all functions $\eta_j$ by the same argument This establishes the other direction of the theorem.
  	\end{proof}

  	\item It should be clear from the Hamilton's principle that  solutions to the EL equation should be the same no matter what coordinate system is used to write the EL equation because extreme values are geometric properties of the functional $I$.

  	\item Note, however, if $(q_1, q_2, \dotsc, q_f)$ constitute a solution to the EL equation for a particular Lagragian $L$, then it is also a solution to the EL equation of a different Lagrangrian
  	$$\tilde{L} = L + \frac{\dee W}{\dee t}$$
  	where $W = W(q_1, \dotsc, q_f)$ is any arbitrary function of $q_1$, $\dotsc$, $q_f$. To see this, let
  	\begin{align*}
  		\widetilde{L} = L + \frac{\dee W}{\dee t}.  		
  	\end{align*}
  	Then,
  	\begin{align*}
  		\int_{t_1}^{t_2} \widetilde L\, \dee t
  		&= \int_{t_1}^{t_2} L\, \dee t + [W]_{t=t_1}^{t=t_2}
  		=  \int_{t_1}^{t_2} L\, \dee t + W(q_1(t_2), \dotsc, q_f(t_2)) - W(q_1(t_1), \dotsc, q_f(t_1)).
  	\end{align*}
  	However, the values of $q_1, \dotsc, q_f$ at $t_1$ and $t_2$ are constants because they are the initial conditions. Hence, $W(q_1(t_2), \dotsc, q_f(t_2)) - W(q_1(t_1), \dotsc, q_f(t_1))$ is a constant and has no effect on the identity of the stationary points of $\int_{t_1}^{t_2} \widetilde{L}\, \dee t$.

  	\item It might seem that specifying the Lagrangian and using Hamilton's principle would allow us to derive Newton's law of motion. However, this is not the case. In fact, if we are given an arbitrary force $\ve{F}$, it is not always possible to construct an $L$ that satisfies the EL equation.
  	\begin{itemize}
  		\item Consider a system of two particles. If the force one particle exerts on the other does not equal to the force the latter exerts on the former (i.e., action $\neq$ reaction), then we cannot construct a Lagrangian that satisfies Hamilton's princple.

  		\item When there's friction in the system, it is possible to construct a Lagrangian, but it is not simple to do so.
  	\end{itemize}
  	As a result, the existence of a Lagrangian that satisfies Hamilton's principle is quite special.

  	\item When solving problems, if we are given an equation of motion, then just constructing the simplest Lagrangian that agrees with that equation would be the standard way to proceed. However, if none is given, then you would have to construct a Lagrangian and try to simplify it as much as possible using some first principles or symmetry of the system. Then, you would derive an equation of motion from it and check it with experiments.
  \end{itemize}

  \section{Hamiltonian from Lagrangian}

  \begin{itemize}
    \item The goal of this section is to more generally define the Hamiltonian so that it can be applied to more physical systems. This entails a more general definition of momentum.    

    \item Let a physical system be described by generalized coordinates $q_1, q_2, \dotsc, q_f$. Let $L = L(q_1, \dotsc, q_f, \dot{q}_1, \dotsc, \dot{q}_f)$ be the Lagrangian of the system. We define the {\bf momentum} $p_i$ to be
    \begin{align} \label{momentum-def}
      p_i = \frac{\partial L}{\partial \dot{q}_i}.    
    \end{align}
    We also say that $p_i$ is $q_i$'s {\bf conjugated momentum}.

    \item For discussions to come, let us say that we can solve the above equation for $\dot{q}_i$ and write it in terms of $q_1, \dotsc, q_f, p_1, \dotsc, p_f$.
    \begin{itemize}
      \item If this is not true, we can still define the Hamiltonian, but it would make the discussion more complicated.
    \end{itemize}

    \item With the definition of momentum and the restriction above, we define the {\bf Hamiltonian} as:
    \begin{align} \label{hamiltonian-def}
      H = H(\ve{q}, \ve{p}) = H(q_1, \dotsc, q_f, p_1, \dotsc, p_f) = \sum_{i=1}^f p_i \dot{q}_i - L.    
    \end{align}
    Here, we regard the $q_i$'s and the $p_i$'s as independent variables.

    \item Let us perturb $q_i$ and $p_i$ by a little. Let us denote the infinitesimal perturbation of variable $a$ by $\delta a$. In other words, we can interested in the changes
    \begin{align*}
      q_i &\rightarrow q_i + \delta q_i \\
      p_i &\rightarrow p_i + \delta p_i
    \end{align*}
    and the perturbations of other variables and functions that result from them. These perturbations can be obtained from first order approximations. Because we can write $\dot{q}_i$ as a function of $\ve{q}$ and $\ve{p}$, we have
    \begin{align*}
      \delta\dot{q}_i =
      &\sum_{j=1}^f \bigg( \frac{\partial \dot{q}_i}{\partial q_j} \delta q_j + \frac{\partial \dot{q}_i}{\partial p_j} \delta p_j \bigg).
    \end{align*}
    Moreover, $L$ is a function of $\ve{q}$ and $\dot{\ve{q}}$, so
    \begin{align*}
      \delta L 
      &= \sum_{i=1}^f \frac{\partial L}{\partial q_i} \delta q_i + \sum_{i=1}^f \frac{\partial L}{\partial \dot{q}_i} \delta \dot{q}_i \\
      &= \sum_{i=1}^f \frac{\partial L}{\partial q_i} \delta q_i + \sum_{i=1}^f \frac{\partial L}{\partial \dot{q}_i} \bigg[ \sum_{j=1}^f \bigg( \frac{\partial \dot{q}_i}{\partial q_j} \delta q_j + \frac{\partial \dot{q}_i}{\partial p_j} \delta p_j \bigg) \bigg] \\
      &= \sum_{i=1}^f \frac{\partial L}{\partial q_i} \delta q_i + \sum_{i=1}^f p_i \bigg[ \sum_{j=1}^f \bigg( \frac{\partial \dot{q}_i}{\partial q_j} \delta q_j + \frac{\partial \dot{q}_i}{\partial p_j} \delta p_j \bigg) \bigg].
    \end{align*}
    Using the definion $H = \sum_{i} p_i \dot{q}_i - L$, we have that
    \begin{align*}
      \delta H 
      &= \sum_{i=1}^f \dot{q}_i \delta p_i + \sum_{i=1}^f p_i \delta \dot{q}_i - \delta L \\
      &= \sum_{i=1}^f \dot{q}_i \delta p_i 
      + \sum_{i=1}^f p_i \bigg[ \sum_{j=1}^f \bigg( \frac{\partial \dot{q}_i}{\partial q_j} \delta q_j + \frac{\partial \dot{q}_i}{\partial p_j} \delta p_j \bigg)\bigg] 
      - \sum_{i=1}^f \frac{\partial L}{\partial q_i} \delta q_i 
      - \sum_{i=1}^f p_i \bigg[ \sum_{j=1}^f \bigg( \frac{\partial \dot{q}_i}{\partial q_j} \delta q_j + \frac{\partial \dot{q}_i}{\partial p_j} \delta p_j \bigg) \bigg]\\
      &= \sum_{i=1}^f \dot{q}_i \delta p_i       
      - \sum_{i=1}^f \frac{\partial L}{\partial q_i} \delta q_i.      
    \end{align*}
    Now, because $H$ is a function of $\ve{q}$ and $\ve{p}$, we have
    \begin{align*}      
      \delta H 
      = \sum_{i=1}^f \bigg( \frac{\partial H}{\partial q_i} \delta q_i + \frac{\partial H}{\partial p_i} \delta p_i \bigg)
      = \sum_{i=1}^f \frac{\partial H}{\partial q_i} \delta q_i + \sum_{i=1}^f \frac{\partial H}{\partial p_i} \delta p_i.
    \end{align*}
    Comparing terms, we have
    \begin{align*}
      \frac{\partial H}{\partial p_i} &= \dot{q}_i \\
      \frac{\partial H}{\partial q_i} &= -\frac{\partial L}{\partial q_i}.
    \end{align*}    

    \item Combining the above equations with the EL equation, we have
    \begin{align*}
      0 
      = \frac{\partial L}{\partial q_i} - \frac{\partial}{\partial t}\bigg( \frac{\partial L}{\partial \dot{q}_i} \bigg)
      = -\frac{\partial H}{\partial q_i} - \frac{\partial p_i}{\partial t} 
      = -\frac{\partial H}{\partial q_i} - \dot{p}_i.
    \end{align*}
    In other words,
    \begin{align*}
      \frac{\partial H}{\partial q_i} = -\dot{p}_i.
    \end{align*}

    \item Putting the equations together, we have that
    \begin{align*}
      \frac{\partial H}{\partial p_i} &= \dot{q}_i \\
      \frac{\partial H}{\partial q_i} &= -\dot{p}_i.
    \end{align*}
    for $i = 1, \dotsc, f$. Rewriting these in in vector forms, we have
    \begin{align*}
      \frac{\partial H}{\partial \ve{p}} &= \dot{\ve{q}} \\
      \frac{\partial H}{\partial \ve{q}} &= -\dot{\ve{p}}.
    \end{align*}
    We call these two equations {\bf Hamilton's equations} or {\bf canonical equations of motion}.

    \item Hamilton's equations are equivalent to the EL equation and Newton's law of motion. Its form is a result of introducing an extra variable so that we can write equations that only involve single first order time derivatives.
    \begin{itemize}
      \item The EL equations involves two time derivatives. It has $\dee / \dee t$ and $\dot{q}$.
    \end{itemize}

    \item If $\ve{q}$ and $\ve{p}$ satisfy Hamilton's equations, we say that $\ve{q}$ and $\ve{p}$ are {\bf canonical variables}.    

    \item Here, we have defined the Hamiltonian from the Lagragian. Under some circumstances, it is possible to define the Lagrangian given the Hamiltonian.

    \item However, there are circumstances where we cannot do so. In quantum mechanics, there are Hamiltonians associated with spins (i.e., angular momentums) of elections, but there are no associated Lagrangians. With our treatment so far, it is unclear what the Hamiltonians in this case are. We will come back to this later though.
  \end{itemize}

  \section{Canonical Transformations}

  \begin{itemize}
    \item In this section, we will discuss changes of variables that preserve Hamilton's equations. 

    \item In order to do so, we will make use of the variational characterization of the Hamiltonian. In other words, we will derive something similar to Hamilton's principle for the Hamiltonian. 
  \end{itemize}

  \subsection{Hamilton's Principle and Hamilton's Equations}

  \begin{itemize}
    \item According to Equation $\eqref{hamiltonian-def}$, we define the Hamiltonian from the Lagrangian. Using the definition of $\ve{p}$ in Equation $\eqref{momentum-def}$, we can write the Hamiltoniam as a function of $\ve{q}$ and $\ve{p}$. We also see in the last section that, if the EL equation holds, then Hamilton's equations would also hold.

    \item In Section~\ref{sec:hamilton-principle}, we saw that $\ve{q}$ satisfies the EL equation if and only if it is a stationary point of the action integral. We now wish to say something similar for the solutions of Hamilton's equations.

    \item Now, let us say that a Hamiltonian $H = H(\ve{q},\ve{p})$ is given to us. Define
    \begin{align*}
      \overline{L}(\ve{q},\ve{p}) = \sum_{i=1}^f p_i \dot{q}_i - H(\ve{q},\ve{p}).
    \end{align*}
    The ``Lagrangian'' $\overline{L}$ is numerically the same as the Lagragian we have been discussed so far. However, it is now a function of $\ve{q}$ and $\ve{p}$ instead of that of $\ve{q}$ and $\dot{\ve{q}}$ as we have seen before.

    \item Define the ``action integral'' as
    \begin{align*}
      \overline{I} 
      = \int_{t_1}^{t_2} \overline{L}(\ve{q},\ve{p}) \, \dee t 
      = \int_{t_1}^{t_2} \bigg( \sum_{i=1}^f p_i \dot{q}_i - H(\ve{q},\ve{p}) \bigg)\, \dee t 
    \end{align*}
    where $t_1 < t_2$ are given time constants. We also hold as initial conditions that $\ve{q}(t_1)$, $\ve{q}(t_2)$, $\ve{p}(t_1)$, and $\ve{p}(t_2)$ are fixed.

    \item Let $\eta(t) = (\eta_1(t), \dotsc, \eta_f(t))^T$ and $\zeta(t) = (\zeta_1(t), \dotsc, \zeta_f(t))^T$ be vector functions such that $\eta(t_1) = \eta(t_2) = \zeta(t_1) = \zeta(t_2) = \ve{0}$. Define
    \begin{align*}
      \phi(s) 
      &= \int_{t_1}^{t_2} \overline{L}(\ve{q} + s\eta, \ve{p} + s\zeta)\, \dee t \\
      &= \int_{t_1}^{t_2} \bigg( \sum_{i=1}^f (p_i + s\zeta_i) (\dot{q}_i + s\dot{\eta}_i) - H(\ve{q} + s\eta, \ve{p} + s\zeta) \bigg)\, \dee t \\
      &= \int_{t_1}^{t_2} \bigg( \sum_{i=1}^f (p_i \dot{q}_i + sp_i \dot{\eta}_i + s \dot{q}_i \zeta_i + s^2 \dot{\eta}_i \zeta_i) - H(\ve{q} + s\eta, \ve{p} + s\zeta) \bigg)\, \dee t.
    \end{align*}
    So,
    \begin{align*}
      \frac{\dee \phi}{\dee s}
      &= \int_{t_1}^{t_2} \bigg( \sum_{i=1}^f (p_i \dot{q}_i + sp_i \dot{\eta}_i + s \dot{q}_i \zeta_i + s^2 \dot{\eta}_i \zeta_i) - H(\ve{q} + s\eta, \ve{p} + s\zeta) \bigg)\, \dee t \\
      &= \int_{t_1}^{t_2} \bigg( \sum_{i=1}^f (p_i \dot{\eta}_i + \dot{q}_i \zeta_i + 2s \dot{\eta}_i \zeta_i) - \frac{\dee}{\dee s}H(\ve{q} + s\eta, \ve{p} + s\zeta) \bigg)\, \dee t \\
      &= \int_{t_1}^{t_2} \bigg( \sum_{i=1}^f (p_i \dot{\eta}_i + \dot{q}_i \zeta_i + 2s \dot{\eta}_i \zeta_i) - \sum_{i=1}^f \frac{\partial H}{\partial(q_i + s\eta_i)}\frac{\dee (q_i + s\eta_i)}{\dee s} -\sum_{i=1}^f \frac{\partial H}{\partial(p_i + s\zeta_i)}\frac{\dee (p_i + s\zeta_i)}{\dee s} \bigg)\, \dee t.
    \end{align*}
    Taking $s = 0$, we have
    \begin{align*}
      \frac{\dee \phi}{\dee s}\bigg|_{s=0}
      &= \int_{t_1}^{t_2} \bigg( \sum_{i=1}^f (p_i \dot{\eta}_i + \dot{q}_i \zeta_i ) - \sum_{i=1}^f \frac{\partial H}{\partial q_i}\eta_i -\sum_{i=1}^f \frac{\partial H}{\partial p_i}\zeta_i \bigg)\, \dee t
    \end{align*}
    Because
    \begin{align*}
      \frac{\dee (p_i \eta_i)}{\dee t} = \dot{p}_i \eta_i + p_i \dot{\eta_i},
    \end{align*}
    we have that
    \begin{align*}
      [p_i \eta_i]_{t=t_1}^{t=t_2}
      &= \int_{t_1}^{t_2} \dot{p}_i \eta_i\, \dee t + \int_{t_1}^{t_2} p_i \dot{\eta}_i\, \dee t \\
      p_i(t_2)\eta_i(t_2) - p_i(t_1)\eta_i(t_1)
      &= \int_{t_1}^{t_2} \dot{p}_i \eta_i\, \dee t + \int_{t_1}^{t_2} p_i \dot{\eta}_i\, \dee t\\
      0
      &= \int_{t_1}^{t_2} \dot{p}_i \eta_i\, \dee t + \int_{t_1}^{t_2} p_i \dot{\eta}_i\, \dee t \\
      \int_{t_1}^{t_2} p_i \dot{\eta}_i
      &= - \int_{t_1}^{t_2} \dot{p}_i \eta_i\, \dee t.
    \end{align*}
    Hence,
    \begin{align*}
      \frac{\dee \phi}{\dee s}\bigg|_{s=0}
      &= \int_{t_1}^{t_2} \bigg( \sum_{i=1}^f (-\dot{p}_i \eta_i + \dot{q}_i \zeta_i ) - \sum_{i=1}^f \frac{\partial H}{\partial q_i}\eta_i -\sum_{i=1}^f \frac{\partial H}{\partial p_i}\zeta_i \bigg)\, \dee t \\
      &= \int_{t_1}^{t_2} \bigg[ -\sum_{i=1}^f \bigg( \frac{\partial H}{\partial q_i} + \dot{p}_i \bigg) \eta_i - \sum_{i=1}^f \bigg( \frac{\partial H}{\partial p_i} - \dot{q}_i \bigg) \zeta_i \bigg] \, \dee t
    \end{align*}
    We now note that that $(\dee \phi/\dee s)(0) = 0$ for all choice of $\eta$ and $\zeta$ if and only if
    \begin{align*}
      \frac{\partial H}{\partial p_i} &= \dot{q}_i \\
      \frac{\partial H}{\partial q_i} &= -\dot{p}_i
    \end{align*}
    for all $i = 1,\dotsc, f$.

    \item \begin{theorem} Let $H = H(\ve{q}, \ve{p})$ be a scalar function that depends on $2f$ time-varying generalized coordinates $q_1, \dotsc, q_f, p_1, \dotsc, p_f$. Let $t_1 < t_2$ be given time constants, and let the values of $\ve{q}(t_1)$, $\ve{q}(t_2)$, $\ve{p}(t_1)$, and $\ve{p}(t_2)$ be given and fixed. Then, any solutions to the Hamilton's equations above are stationary points of the action integral
    \begin{align*}
      \overline{I} 
      = \int_{t_1}^{t_2} \overline{L}(\ve{q},\ve{p}) \, \dee t 
      = \int_{t_1}^{t_2} \bigg( \sum_{i=1}^f p_i \dot{q}_i - H(\ve{q},\ve{p}) \bigg)\, \dee t.
    \end{align*}
    \end{theorem}

    \item Note that, like in Section~\ref{sec:hamilton-principle}, the theorem still holds if we replace $\overline{L}$ by
    \begin{align*}
      \overline{L} + \frac{\dee W(\ve{q}, \ve{p})}{\dee t}.
    \end{align*}
  \end{itemize}

  \subsection{Canonical Transformation}

  \begin{itemize}
    \item We are now concerned with changes of variables
    \begin{align*}
      q_i &= q_i(Q_1, \dotsc, Q_f, P_1, \dotsc, P_f) \\
      p_i &= p_i(Q_1, \dotsc, Q_f, P_1, \dotsc, P_f).
    \end{align*}
    where we assume that the inverse transformation also exists. We are interested in identifying the kinds of transformations that would still perserve Hamilton's equations.

    \item The Hamiltonian function for the new variables is in general not the same as the old one. Let us denote it by
    \begin{align*}
      K = K(\ve{Q}, \ve{P}).
    \end{align*}
    We are interested in the transformations such that Hamilton's equations
    \begin{align*}
      \frac{\partial K}{\partial \ve{P}} &= \dot{\ve{Q}} \\
      \frac{\partial K}{\partial \ve{Q}} &= -\dot{\ve{P}}
    \end{align*}
    hold.

    \item The answer are the transformations that satisfies the equation
    \begin{align*}
      \sum_{i=1}^f p_i \dot{q}_i - H(\ve{q},\ve{p}) = \sum_{i=1}^f P_i \dot{Q}_i - K(\ve{Q}, \ve{P}) + \frac{\dee W}{\dee t}
    \end{align*}
    where $W$ is an arbitrary function. We call these transformations {\bf canonical transformations.}

    \item To see such a transformation work, integrate both sides from $t_1$ to $t_2$ and fix the values of $\ve{q}$ and $\ve{p}$ at these two times. The stationary points of the action integrals defined on both sides should be the same, and they should all satisfy Hamilton's equations written in terms of $H$ and $K$.

    \item Let us state the result more precisely.
    \begin{theorem}[Canonical Transformation]
    Let $q_1, \dotsc, q_f$, $p_1, \dotsc, p_f$, $Q_1, \dotsc, Q_f$, $P_1, \dotsc, P_f$ be time-dependent variables that are related by the transformation
    \begin{align*}
      q_i &= q_i(Q_1, \dotsc, Q_f, P_1, \dotsc, P_f) \\
      p_i &= p_i(Q_1, \dotsc, Q_f, P_1, \dotsc, P_f)
    \end{align*}
    whose inverse exists. Let $H(\ve{q},\ve{p})$ and $K(\ve{Q}, \ve{P})$ be scalar functions such that
    \begin{align} \label{canonical-transform}
      \sum_{i=1}^f p_i \dot{q}_i - H(\ve{q},\ve{p}) = \sum_{i=1}^f P_i \dot{Q}_i - K(\ve{Q}, \ve{P}) + \frac{\dee W}{\dee t}    
    \end{align}
    where $W$ is an arbitrary function. Then, for any $\ve{q}$ and $\ve{p}$ such that (1) the values $\ve{q}(t_1)$, $\ve{q}(t_2)$, $\ve{p}(t_1)$, $\ve{p}(t_2)$ are given as initial conditions and (2) the equations
    \begin{align*}
      \frac{\partial H}{\partial \ve{p}} &= \dot{\ve{q}} \\
      \frac{\partial H}{\partial \ve{q}} &= -\dot{\ve{p}},
    \end{align*}
    hold, we have that
    \begin{align*}
      \frac{\partial K}{\partial \ve{P}} &= \dot{\ve{Q}} \\
      \frac{\partial K}{\partial \ve{Q}} &= -\dot{\ve{P}}
    \end{align*}
    also hold.
    \end{theorem}
  \end{itemize}

  \subsection{Generating Function}

  \begin{itemize}
    \item The function $W$ in Equation~\ref{canonical-transform} is called a {\bf generating function} in the sense that, given $W$, the change of variable can be derived. (Note: The opposite is also true.)

    \item For example, suppose that $W$ is a function of $\ve{q}$ and $\ve{Q}$. Then, we have that
    \begin{align*}
      \frac{\dee W}{\dee t} = \sum_{i=1}^f \bigg( \frac{\partial W}{\partial q_i} \dot{q}_i + \frac{\delta W}{\partial Q_i}\dot{Q}_i \bigg).
    \end{align*}
    Equation~\ref{canonical-transform} becomes
    \begin{align*}
      \sum_{i=1}^f p_i \dot{q}_i - H(\ve{q},\ve{p}) 
      &= \sum_{i=1}^f P_i \dot{Q}_i - K(\ve{Q}, \ve{P}) + \sum_{i=1}^f \bigg( \frac{\partial W}{\partial q_i} \dot{q}_i + \frac{\delta W}{\partial Q_i}\dot{Q}_i \bigg) \\
       \sum_{i=1}^f \bigg( p_i - \frac{\partial W}{\partial q_i} \bigg)\dot{q}_i - H(\ve{q},\ve{p}) 
       &= \sum_{i=1}^f \bigg( P_i + \frac{\partial W}{\partial Q_i} \bigg) + \dot{Q}_i - K(\ve{Q}, \ve{P}).
    \end{align*}
    We can get the equation to hold if the following equations are satisifed:
    \begin{align*}
      p_i &= \frac{\partial W}{\partial q_i} \\
      P_i &= -\frac{\partial W}{\partial Q_i} \\
      H(\ve{q},\ve{p}) &= K(\ve{Q}, \ve{P}).
    \end{align*}

    \item Note that we can derive equations similar to the above equations for other forms of $W$. There are three more forms which come from making $W$ a function of 
    \begin{itemize}
      \item $\ve{q}$ and $\ve{P}$,
      \item $\ve{p}$ and $\ve{Q}$, and
      \item $\ve{p}$ and $\ve{P}$.
    \end{itemize}

    \item However, the derivations for the other three forms are not as simple as the example above. For example, if we are given that $W$ is a function of $\ve{q}$ and $\ve{P}$. Then, we cannot simply perform the exact same computation as above. We have to rename the given $W$ as $\widetilde{W}$ and add a term to it to make the calculation work. That is, define
    \begin{align*}
      W = -\sum_{i=1}^f P_i Q_i + \widetilde{W}(\ve{q},\ve{P}),
    \end{align*}
    which gives
    \begin{align*}
      \frac{\dee W}{\dee t}
      = -\sum_{i=1}^f (\dot{P}_i Q_i + P_i \dot{Q}_i)
      + \sum_{i=1}^f \bigg( \frac{\partial \widetilde{W}}{\partial q_i} \dot{q}_i + \frac{\partial \widetilde{W}}{\partial P_i} \dot{P}_i \bigg). 
    \end{align*}
    Equation~\ref{canonical-transform} becomes
    \begin{align*}
      \sum_{i=1}^f p_i \dot{q}_i - H(\ve{q},\ve{p}) 
      &= \sum_{i=1}^f P_i \dot{Q}_i - K(\ve{Q}, \ve{P})
      -\sum_{i=1}^f (\dot{P}_i Q_i + P_i \dot{Q}_i)
      + \sum_{i=1}^f \bigg( \frac{\partial \widetilde{W}}{\partial q_i} \dot{q}_i + \frac{\partial \widetilde{W}}{\partial P_i} \dot{P}_i \bigg) \\
      \sum_{i=1}^f \bigg( p_i - \frac{\partial \widetilde{W}}{\partial q_i} \bigg) \dot{q}_i - H(\ve{q},\ve{p}) 
      &= - K(\ve{Q}, \ve{P})
      -\sum_{i=1}^f \bigg( Q_i - \frac{\partial \widetilde{W}}{\partial P_i} \bigg) \dot{P}_i.
    \end{align*}
    The above equation yields
    \begin{align}
      p_i &= \frac{\partial \widetilde{W}}{\partial q_i} \label{qP-p} \\
      Q_i &= \frac{\partial \widetilde{W}}{\partial P_i} \label{qP-Q} \\
      H(\ve{q},\ve{p}) &= K(\ve{Q}, \ve{P}) \notag.
    \end{align}
    This example illustrates the trick of introducing an extra term to the given function to make it possible to relate variables to one another.

    \item The canonical transformation is a type of {\bf Legendre transformations}. We will talk about this later.

    \item If we are given and equation of the form Equation~\ref{canonical-transform}, we can check whether it leads to a canonical transform or not by using the {\bf Poisson bracket}. We will discuss this later as well.    
  \end{itemize}

  \subsection{Identity Transformation}

  \begin{itemize}
    \item We call the coordinate change
    \begin{align*}
      q_i &= Q_i \\
      p_i &= P_i
    \end{align*}
    the {\bf identity transformation} or the {\bf unit transformation}.

    \item What is the generating function of the identity transformation?

    \item Using
    \begin{align*}
      \widetilde{W} &= \sum_{i=1}^f P_i q_i 
    \end{align*}
    and
    \begin{align*}
      W 
      = - \sum_{i=1}^f P_i Q_i  + \widetilde{W} 
      = - \sum_{i=1}^f P_i Q_i  + \sum_{i=1}^f P_i q_i 
      = - \sum_{i=1}^f P_i ( Q_i - q_i ),
    \end{align*}
    we have that, by Equation~\ref{qP-p} and \ref{qP-Q},
    \begin{align*}
      p_i 
      &= \frac{\partial \widetilde{W}}{\partial q_i} 
      = \frac{\partial}{\partial q_i} \bigg( \sum_{j=1}^f P_j q_j \bigg)
      = P_j \\
      Q_i 
      &= \frac{\partial \widetilde{W}}{\partial P_i} 
      = \frac{\partial}{\partial P_i} \bigg( \sum_{j=1}^f P_j q_j \bigg)
      = q_i
    \end{align*}
    as required.
  \end{itemize}

  \subsection{Infinitestimal Canonical Transformation}

  \begin{itemize}
    \item Consider a canonical transformation that is very close to the identity transformation. That is, the generating function is of the form     
    \begin{align*}
      W = -\sum_{i=1}^f P_i Q_i + \widetilde{W}(\ve{q}, \ve{P})
    \end{align*}
    where
    \begin{align*}
    \widetilde{W}(\ve{q}, \ve{P})
    = \sum_{i=1}^f P_i q_i + \epsilon G(\ve{q}, \ve{P}),
    \end{align*}
    and $\epsilon$ is an infinitesimal function and $G$ is some function.

    \item For the above transformation to be canonical, we must have that
    \begin{align*}
      p_i &= \frac{\partial \widetilde{W}}{\partial q_i} = P_i + \epsilon \frac{\partial G(\ve{q}, \ve{P})}{\partial q_i} \\
      Q_i &= \frac{\partial \widetilde{W}}{\partial P_i} = q_i + \epsilon \frac{\partial G(\ve{q}, \ve{P})}{\partial P_i}.
    \end{align*}.

    \item So, the change in $q_i$ and $p_i$ induced by this canonical transformation is given by:
    \begin{align*}
      \delta p_i &= P_i - p_i = -\epsilon \frac{\partial G(\ve{q},\ve{P})}{\partial q_i} \\
      \delta q_i &= Q_i - q_i = \epsilon \frac{\partial G(\ve{q},\ve{P})}{\partial P_i}.
    \end{align*}

    \item The above $G$ is not very convenient to work with because $G$ is a function of $\ve{q}$ amd $\ve{P}$. We'd rather have $G$ be a function of $\ve{q}$ and $\ve{p}$ instead. So, define
    \begin{align*}
      \widetilde{G}(\ve{q},\ve{p}) &= G(\ve{q}, \ve{P}(\ve{q},\ve{p})).
    \end{align*}
    We have that
    \begin{align*}
      \frac{\partial\widetilde{G}}{\partial q_i}
      &= \frac{\partial G}{\partial q_i} + \sum_{j=1}^f \frac{\partial G}{\partial P_j} \frac{\partial P_j}{\partial q_i}
      = \frac{\partial G}{\partial q_i} + \sum_{j=1}^f \frac{\partial G}{\partial P_j} \frac{\partial (p_j + \delta p_j)}{\partial q_i}\\
      &= \frac{\partial G}{\partial q_i} + \sum_{j=1}^f \frac{\partial G}{\partial P_j} \frac{\partial \delta p_j}{\partial q_i}
      = \frac{\partial G}{\partial q_i} + \sum_{j=1}^f \frac{\partial G}{\partial P_j} \frac{\partial}{\partial q_i}\bigg(-\epsilon \frac{\partial G}{\partial q_j} \bigg) \\
      &= \frac{\partial G}{\partial q_i} - \epsilon \sum_{j=1}^f \frac{\partial G}{\partial P_j} \frac{\partial^2 G}{\partial q_i \partial q_j}.
    \end{align*}
    As a result,
    \begin{align*}
      \delta p_i 
      &= -\epsilon \frac{\partial G}{\partial q_i}
      = -\epsilon \bigg( \frac{\partial \widetilde{G}}{\partial q_i} + \epsilon  \sum_{j=1}^f \frac{\partial G}{\partial P_j} \frac{\partial^2 G}{\partial q_i \partial q_j}  \bigg)
      = -\epsilon \frac{\partial \widetilde{G}}{\partial q_i} + \epsilon^2  \sum_{j=1}^f \frac{\partial G}{\partial P_j} \frac{\partial^2 G}{\partial q_i \partial q_j} \\
      &= -\epsilon \frac{\partial \widetilde{G}}{\partial q_i}
    \end{align*}
    because $\epsilon^2 = 0$ as $\epsilon$ is infinitesimal.

    \item Note that, by the derivation similar to the above, we may show that
    \begin{align*}
      \delta q_i = \epsilon \frac{\partial \widetilde{G}}{\partial p_i}.
    \end{align*}

    \item As a result, we may rename $\tilde{G}(\ve{q},\ve{p})$ as $G(\ve{q},\ve{p})$ and have $G$ that is more convenient to work with.

    \item We have seen that, given $G(\ve{q}, \ve{p})$, the infinitesimal changes $\delta p_i$ and $\delta q_i$ are determined. So, we call $G$ the {\bf infinitesimal generating function}.
  \end{itemize}

  \subsection{Genarating Functions of Some Infinitesimal Canonical Transformations}

  \subsubsection{Translation}

  \begin{itemize}
    \item Consider a particle in 3-dimentional space whose position is given by vector $\ve{x} = (x_1,x_2,x_3)^T$ in Cartesian coordinates.

    \item Suppose we transform $\ve{x}$ to $\ve{X}$ by adding a constant infinitesimal displacement $\boldsymbol{\epsilon} = (\epsilon_1, \epsilon_2, \epsilon_3)^T$. That is,
    \begin{align*}
      \ve{x} = \ve{x} + \boldsymbol{\epsilon}.
    \end{align*}
    In other words,
    \begin{align*}
      \delta \ve{x} = \boldsymbol{\epsilon}.
    \end{align*}

    \item The momentum of the particle in the old coordinate system is given by $$\ve{p} = m\dot{\ve{x}}.$$ The momentum under the transformed coordinate symtem is given by $$\ve{P} = m\dot{\ve{X}} = m \frac{\dee (\ve{x} + \ves{\epsilon})}{\dee t} = m\dot{\ve{x}} = \ve{p}.$$
    So, $$\delta \ve{p} = \ve{0}.$$

    \item Choosing the generativing function
    \begin{align*}
      \epsilon G = \sum_{i=1}^3 \epsilon_i p_i = \ves{\epsilon} \cdot \ve{p},
    \end{align*}
    we have that
    \begin{align*}
      \frac{\partial (\epsilon G)}{\partial p_i} &= \epsilon_i  = \delta q_i \\
      -\frac{\partial (\epsilon G)}{\partial q_i} &= 0 = \delta p_i.
    \end{align*}    

    \item As a result, we may say that {\bf momentum is the infinitesimal generating function of translation}.
  \end{itemize}

  \subsubsection{Rotation}

  \begin{itemize}
    \item Consider a small rotation by an infinitesimally small angle $\epsilon$ in 2D. In other words, we transform coordinate $\ve{x} = (x_1, x_2)^T$ to $\ve{X} = (X_1, X_2)^T$ as follows:
    \begin{align*}
      \begin{bmatrix}
        X_1 \\ X_2
      \end{bmatrix}
      =
      \begin{bmatrix}
        \cos \epsilon & -\sin \epsilon \\
        \sin \epsilon & \cos \epsilon
      \end{bmatrix}
      \begin{bmatrix}
        x_1 \\ x_2
      \end{bmatrix}.
    \end{align*}

    \item When $\epsilon$ is infinitesimal, we have that
    \begin{align*}
      \cos \epsilon &= 1 - \frac{\epsilon^2}{2!} + O(\epsilon^4) = 1\\
      \sin \epsilon &= \epsilon - \frac{\epsilon^3}{3!} + O(\epsilon^5) = \epsilon.
    \end{align*}
    So,
    \begin{align*}
      \begin{bmatrix}
        X_1 \\ X_2
      \end{bmatrix}
      =
      \begin{bmatrix}
        1 & -\epsilon \\
        \epsilon & 1
      \end{bmatrix}
      \begin{bmatrix}
        x_1 \\ x_2
      \end{bmatrix}
      =
      \begin{bmatrix}
        x_1 - \epsilon x_2 \\
        \epsilon x_1 + x_2
      \end{bmatrix}
    \end{align*}
    Hence,
    \begin{align*}
      \delta \ve{x}
      =
      \begin{bmatrix}
        X_1 \\ X_2
      \end{bmatrix}
      -
      \begin{bmatrix}
        x_1 \\ x_2
      \end{bmatrix} 
      =
      \begin{bmatrix}
        -\epsilon x_2 \\ \epsilon x_1
      \end{bmatrix}
      = \epsilon \begin{bmatrix}
        -x_2 \\ x_1
      \end{bmatrix}.
    \end{align*}

    \item For the momentum,
    \begin{align*}
      \delta \ve{p} 
      = \ve{P} - \ve{p} 
      = m \dot{\ve{X}} - m\dot{\ve{x}}
      = m \begin{bmatrix}
        \dot{x}_1 - \epsilon \dot{x}_2 \\
        \epsilon \dot{x}_1 + \dot{x}_2 
      \end{bmatrix}
      - m \begin{bmatrix}
        \epsilon \dot{x}_1 \\
        \epsilon \dot{x}_2
      \end{bmatrix}
      = \epsilon \begin{bmatrix}
        -m \dot{x}_2 \\
        m \dot{x}_1
      \end{bmatrix}
      = \epsilon \begin{bmatrix}
        -p_2 \\ p_1
      \end{bmatrix}
    \end{align*}

    \item Choosing
    \begin{align*}
      G = x_1 p_2 - x_2 p_1,
    \end{align*}
    we have that
    \begin{align*}
      \delta x_1 &= \epsilon \frac{\partial G}{\partial p_1} = -\epsilon x_2 \\
      \delta x_2 &= \epsilon \frac{\partial G}{\partial p_2} =  \epsilon x_1 \\
      \delta p_1 &= -\epsilon \frac{\partial G}{\partial x_1} =- \epsilon p_2 \\
      \delta p_2 &= -\epsilon \frac{\partial G}{\partial x_2} = \epsilon p_1,
    \end{align*}
    which agrees with what we derived before.

    \item Now, $G = x_1 p_2 - x_2 p_1$ is the magnitude of the cross product $\ve{x} \times \ve{p}$ when we view $\ve{x}$ and $\ve{p}$ as a three dimentional vectors that lie in the $(x_1, x_2)$-plane. You may recall that $\ve{x} \times \ve{p}$ is the angular momentum.

    \item In 3-dimensional space, suppose that we transform the coordinates by rotating it around an axis $\ve{e}$ by an infinitesimal angle $\epsilon$.

    \item We have that the old coordinate $\ve{x} = (x_1, x_2, x_3)^T$ is changed to
    \begin{align*}
      \ve{X} = (X_1, X_2, X_3)^T = \ve{x} + \epsilon(\ve{e} \times \ve{x}).
    \end{align*}
    In other words,
    \begin{align*}
      \delta\ve{x} = \epsilon(\ve{e} \times \ve{x}).
    \end{align*}

    \item The velocity $\dot{\ve{X}}$ is given by:
    \begin{align*}
      \dot{\ve{X}} 
      = \frac{\dee (\ve{x} + \epsilon(\ve{e} \times \ve{x}))}{\dee t}
      = \dot{\ve{x}} + \epsilon(\ve{e} \times \dot{\ve{x}}).
    \end{align*}
    As a result,
    \begin{align*}
      m\dot{\ve{X}} 
      &= m\dot{\ve{x}} + \epsilon(\ve{e} \times m\dot{\ve{x}})\\
      \dot{\ve{P}} 
      &= \ve{p} + \epsilon(\ve{e} \times \ve{p}) \\
      \delta \ve{p} 
      &= \epsilon(\ve{e} \times \ve{p}).
    \end{align*}

    \item Choosing
    \begin{align*}
      G = (\ve{x} \times \ve{p}) \cdot \ve{e},
    \end{align*}
    we have
    \begin{align*}
      \frac{\partial (\epsilon G)}{\partial x_i} 
      = \frac{\partial (\epsilon (\ve{x} \times \ve{p}) \cdot \ve{e})}{\partial x_i} 
      = \frac{\partial (\epsilon (\ve{p} \times \ve{e}) \cdot \ve{x})}{\partial x_i} 
      = -\frac{\partial (\epsilon (\ve{e} \times \ve{p}) \cdot \ve{x})}{\partial x_i} 
      = - (\epsilon(\ve{e} \times \ve{p}))[i]
    \end{align*}
    as a result
    \begin{align*}
      \frac{\partial (\epsilon G)}{\partial \ve{x}} = -\epsilon(\ve{x} \times \ve{p}) = -\delta \ve{p}.
    \end{align*}
    Similarly, we can show that
    \begin{align*}
      \frac{\partial (\epsilon G)}{\partial \ve{p}} = \delta\ve{x}.
    \end{align*}

    \item So, we can conclude that {\bf angular momentum is the infinitesimal generating function of rotation}.
  \end{itemize}

  \subsubsection{Time Evolution}

  \begin{itemize}
    \item Recall that $\ve{q}$ and $\ve{p}$ are functions of time, which we will write in this section as $\ve{q}(t)$ and $\ve{p}(t)$.

    \item Consider the values of $\ve{q}$ and $\ve{p}$ at $t + \epsilon$ where $\epsilon$ is infinitesimal. Define
    \begin{align*}
      \ve{Q}(t) &= \ve{q}(t + \epsilon) \\
      \ve{P}(t) &= \ve{p}(t + \epsilon).
    \end{align*}
    In other words, we view infinitesimal time evolution as a canonical transform. What is its generating function then?

    \item By Taylor's series expansion, we have that
    \begin{align*}
      \delta \ve{q}(t) 
      &= \ve{Q}(t) - \ve{q}(t)
      = \ve{q}(t + \epsilon) - \ve{q}(t)
      = \epsilon \dot{\ve{q}}(t)
      = \epsilon \frac{\partial H}{\partial \ve{p}} \\
      \delta \ve{p}(t)
      &= \ve{P}(t) - \ve{p}(t)
      = \ve{p}(t + \epsilon) - \ve{p}(t)
      = \epsilon \dot{\ve{p}}(t)
      = -\epsilon \frac{\partial H}{\partial \ve{q}}
    \end{align*}

    \item As a result, we have that {\bf the Hamilonian is the infinitesimal generating function of time evolution}.
  \end{itemize}

  \section{Poisson Bracket}

  \begin{itemize}
    \item 
  \end{itemize}
  \bibliographystyle{apalike}
  \bibliography{intro-analytical-mechanics}  
\end{document}