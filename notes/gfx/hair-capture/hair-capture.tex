\documentclass[10pt]{article}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage[amsthm, thmmarks]{ntheorem}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{enumerate}
\usepackage{verse}

\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{definition}[lemma]{Definition}
\newtheorem{proposition}[lemma]{Proposition}
\newtheorem{corollary}[lemma]{Corollary}
\newtheorem{claim}[lemma]{Claim}

\newcommand{\dee}{\mathrm{d}}
\newcommand{\In}{\mathrm{in}}
\newcommand{\Out}{\mathrm{out}}
\newcommand{\pdf}{\mathrm{pdf}}

\newcommand{\ve}[1]{\mathbf{#1}}
\newcommand{\mrm}[1]{\mathrm{#1}}
\newcommand{\etal}{{et~al.}}
\newcommand{\sphere}{\mathbb{S}^2}
\newcommand{\modeint}{\mathcal{M}}
\newcommand{\azimint}{\mathcal{N}}
\newcommand{\ra}{\rightarrow}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\likelihood}{\mathcal{L}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\new}{\mathrm{new}}

\title{Capturing Hair Assemblies Fiber by Fiber}
\author{Pramook Khungurn}

\begin{document}
	\maketitle	
	
	This is the ``untangled'' version of ``Capturing Hair Assemblies Fiber by Fiber'' by Wenzel, John Moon, and Steve. I wrote this because I was so confused when I read the article. 
	
	\section{Measurement}
	
	\begin{itemize}
	  \item The hair assembly is mounted on a turntable whose rotation axis is vertical.\\
	  The hair assembly is hung vertically, and the volume of hair is approximately centered around the center of rotation.
	 
	  \item The camera is mounted on a linear translation stage.\\ 
	  The direction of translation is parallel to the optical axis of the camera.\\
	  Moreover, the optical axis is perpendicular to the rotation axis of the turntable.
	 
	  \item The lens used was Cannon $100\mathrm{mm}$ $f/2.8$ used.\\
	  The aperture was opened fully to create small depth of field.\\
	  The paper reported the depth of field was about $1.2\mathrm{mm}$.
	  
	  \item There's a blue background behind the hair.\\
	  As the background is blue, the paper uses only the red pixels from Bayer pattern to do hair reconstrution.
	  
	  \item The system rotates the table around its axis, simulating the camera movement around the hair.\\
	  For each rotation angle of the table, the system translates the camera\\ along the translation. For each distance along the translation stage, it takes a photograph of the hair assembly.
	\end{itemize}
	
	\section{Interpreting the Data}
	\begin{itemize}
	  \item The positions in the hair volume is described in coordinate system $(x,y,z)$ such that the $y$-axis is the axis of the rotation. The coordinate system moves with the hair as the table is rotated.
	  
	  \item The focal plane is parameterized by coordinate system $(u,v)$ where the $v$-axis is vertical and coincides with the axis of rotation of the turntable.
	  
	  \item Let $d$ be the distance from the camera's translation from the position where the focal plane passes the rotation axis. We have that $u$, $v$, and $d$ constitute another coordinate system for 3D points.
	  
	  \item For any point in the hair volume, it's $(x,y,z)$ coordinate is related to its $(u,v,d)$ coordinate by a simple rotation around the $y$-axis. That is:
	  \begin{align*}
	    \begin{bmatrix}
	      u \\ d
	    \end{bmatrix}
	    &= R(\theta) \begin{bmatrix}
	     x \\ z
	    \end{bmatrix}
	  \end{align*}
	  where $\theta$ is the angle of rotation of the turntable, and $R(\theta)$ is the corresponding rotation matrix. Since the rotation do not affect the $y$-coordinate, we have that
	  \begin{align*}
	    v = y.
	  \end{align*}
	  
	  \item When a point on a fiber appears in focus, it's $u$-position can be determined very precisely because its footprint on the image is small due to the fact that the camera is of high resolution.
	  
	  \item However, its $d$-position is more fuzzy. The paper claims there's an error about $1\mathrm{mm}$ in the $d$-direction.
	  
	  \item As such the point that appears in focus is interpreted as begin a short strip in the $d$-direction.

	  A hair strand is therefore a ribbon strip that is always edge-on to the camera's view direction.
	  
	  \item ``Finding hair in the volume amounts to finding sets of intersecting ribbons that are mutally consistent.''
	\end{itemize}

	\section{Image Filtering} % (fold)
	\label{sec:image_filtering}
	
	\begin{itemize}
		\item For each of the photograph capture, we need to apply a ridge detector to detect hair fibers.

		\item The paper uses a modified version of the Canny operator for edge detection.

		\item Before applying the filtering, the paper chooses a scale which will corresponds to the width of the filter to be applied to the image. This filter should corresponds to the width of the hair fiber.
		
		\item The filter applied is the \emph{two-dimensional Gabor filter}.
		\begin{align*}
		  G(u,v) = \exp\bigg( -\frac{1}{2} \bigg[ \frac{\tilde{u}^2}{\sigma_u^2} + \frac{\tilde{v}^2}{\sigma_v^2} \bigg] \bigg) \cos\bigg( \frac{2\pi\tilde{u}}{\lambda} \bigg)
		\end{align*}
		where
		\begin{align*}
		  \tilde{u} &= u \cos \varphi + v \sin \varphi, \mbox{ and}\\
		  \tilde{v} &= -u \cos \varphi + v \cos \varphi.
		\end{align*}
		The parameter $\varphi$ and $\lambda$ determines the orientation and the period of the sinusoid plane wave. The $\sigma_u$ and $\sigma_v$ parameter control the standard deviation of the Gaussian envelope.
		
		\item The ``scale'' that we determine in the last item is the values of $\lambda$, $\sigma_u$ and $\sigma_v$.
		
		The paper uses $\sigma_u = \sigma_v = 1$ and $\lambda = 3$.
		
		\item The uses $32$ values of $\varphi$ to get $32$ directions. This results in $32$ Gabor filters to convolve with each photograph.
		
		\item To detect a ridge, we go to the pixels of the $32$ convolved images. We do non-maximum suppression on it.
		
		That is, for a pixel with intensity $M$, let $M_1$ and $M_2$ be bilinearly interpolated values resulting from a lookup normal to the local orientation of the Gabor filter. We create a new image with intensity given by:
		\begin{align*}
		  M' = \frac{M - M_{\max}}{M_{\max}+c}
		\end{align*}
		where $M_{\max} = \max\{ M_1, M_2 \}$ and $c$ is a constant.
		
		\item Hysteresis thresholding is applied to the output of the non-maximum suppresion step.
    
    \item {\bf Hysteresis thresholding} uses two thresholds: $T_{high}$ and $T_{low}$. With this, each pixel is classified into three classes:
    \begin{itemize}
      \item A pixel is \emph{strong} if its intensity is greater than $T_{high}$.
      \item A pixel is \emph{weak} if its intensity is less than or equal to $T_{low}$.
      \item A pixel is a \emph{candidate} otherwise.
    \end{itemize}
    
    Then:
    \begin{itemize}
      \item The algorithm discards a pixel if it is weak.
      \item The algorithm retains a pixel if it is strong.
      \item For a candidate pixel, find the transitive closure of candidate and strong pixels to that pixel. It the connected component has a strong pixel, then retain the pixel. If not, discard the pixel.
    \end{itemize}
    
    \item The output of the hysteresis thresholding is a binary image. If a pixel is turned on, it indicates that there's a ridge in that pixel.
    
    \item If a pixel is turned on after the original image is convolved with a Gabor filter of a certain orientation, then the orientation of the ridege is given by the orientation of the Gabor filter.
    
    \item Hence, the output of the filtering stage are pixel positions and the associated orientation of the ridge at that pixel.
	\end{itemize}
	% section image_filtering (end)
	
	\section{Growing Hair} % (fold)
	\label{sec:growing_hair}
	
	\begin{itemize}
	  \item The gist of the hair growing algorithm is to start with an initial position, estimate the local direction at that position, take a step in that direction, and then do the same for the new position until we cannot do so. This should trace a path through one of the hair strand.
	  
	  \item However, this process outline above is not very robust spurious ridge detection. We need a more robust process.
	  
	  \item The paper proposes correcting the position after following a step in the local direction so that the new position is still located in the ribbon corresponding to the ridges.
	  
	  This correction step can be described as a least-square problem.	  
	\end{itemize}

	  \subsection{Direction Estimation} % (fold)
	  \label{sub:direction_estimation}
	  
	  \begin{itemize}
	    \item The pixel position and the depth associated with the image it comes from gives a $(u,v,d)$ coordinate of a 3D point. We take all the $(u,v,d)$ and its corresponding orientation and transform them into the $(x,y,z)$ coordinate system by the simple rotation outlined earlier.
	    
	    \item The algorithm relies on the ability to find near 3D point to a given query point. So, the $(x,y,z)$-positions of the ridge points should be put into a kd-tree to enable this capability.
	    
	    \item Given a point $\ve{x} = (x,y,z)^T$, let there be $m$ near ridge points.\\
	    Let these points be viewed from camera angles $\theta_{i_1}, \theta_{i_2}, \dotsc, \theta_{i_m}$.\\
	    Let the image space coordinates of the points be $\ve{s}_1, \ve{s}_2, \dotsc, \ve{s}_m$.\\
	    Let the translation of the camera for these points be $d_1, d_2, \dotsc, d_m$.\\
	    Let the 2D orientation of these points be $\ve{o}_1, \ve{o}_2, \dotsc, \ve{o}_m$.

	    \item We shall use the information in the last item to deduce the fiber orientation near $\ve{x}$.

	    \item Now, we assume the perfect camera model.\\
	    Let $l$ be the distance from the camera's ``eye'' to the focal plane.\\
	    Let $f$ be the distance from the ``eye'' to the image plane.\\
	    Let $\ve{s}_k = (s_k, t_k, 1)^T$ in homogeneous coordiate.\\
	    Let $\ve{x} = (x, y, z, 1)$ in homogeneous coordinate as well.

	    Expressing $\ve{x}$ in the $(u,v,d)$-coordinate system, we have that
	    \begin{align*}
	    	\begin{bmatrix}
	    		u_k \\ v_k \\ d_k
	    	\end{bmatrix}
	    	=
	    	\begin{bmatrix}
	    		\cos \theta_{i_k} & 0 & \sin \theta_{i_k} & 0\\
	    		0 & 1 & 0 & 0\\
	    		-\sin \theta_{i_k} & 0 & \cos \theta_{i_k} & 0
	    	\end{bmatrix}
	    	\begin{bmatrix}
	    		x \\ y \\ z \\ 1	    		
	    	\end{bmatrix}
	    \end{align*}

	    Simple proportionality tells us that
	    \begin{align*}
	    	\frac{u_k}{l} = \frac{s_k}{f},  \mbox{ and } \frac{v_k}{l} = \frac{t_k}{f}.
	    \end{align*}
	    In other words, in homogeneous coordinates,
	    \begin{align*}
	    	\begin{bmatrix}
	    		s_k \\ t_k \\ 1
	    	\end{bmatrix}
	    	=
	    	\begin{bmatrix}
	    		u_k \\
	    		v_k \\
	    		\frac{l}{f}
			\end{bmatrix}
			=
			\begin{bmatrix}
	    		\cos \theta_{i_k} & 0 & \sin \theta_{i_k} & 0\\
	    		0 & 1 & 0 & 0\\
	    		-\frac{\sin \theta_{i_k}}{f} & 0 & \frac{\cos \theta_{i_k}}{f} & \frac{l-d_k}{f}
	    	\end{bmatrix}
	    	\begin{bmatrix}
	    		x \\ y \\ z \\ 1
	    	\end{bmatrix}
	    \end{align*}
	    As such
	    \begin{align*}
	    	\ve{u}_k =
	    	\begin{bmatrix}
	    		\cos \theta_{i_k} & 0 & \sin \theta_{i_k} & 0\\
	    		0 & 1 & 0 & 0\\
	    		-\frac{\sin \theta_{i_k}}{f} & 0 & \frac{\cos \theta_{i_k}}{f} & \frac{l-d_k}{f}
	    	\end{bmatrix}
	    	\ve{x}.
	    \end{align*}

	    For convenience, let the mapping from $\ve{x}$ to $\ve{u}_k$ be denoted by $P_{k}$
	  \end{itemize}


	  % subsection direction_estimation (end)

	
	% section growing_hair (end)
	
\bibliographystyle{plain}
\bibliography{hair-capture}	

\end{document}