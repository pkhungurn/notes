\documentclass[10pt]{article}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage[amsthm, thmmarks]{ntheorem}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{verse}
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{hyperref}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{definition}[lemma]{Definition}
\newtheorem{proposition}[lemma]{Proposition}
\newtheorem{corollary}[lemma]{Corollary}
\newtheorem{claim}[lemma]{Claim}
\newtheorem{example}[lemma]{Example}

\def\sc#1{\dosc#1\csod}
\def\dosc#1#2\csod{{\rm #1{\small #2}}}

\newcommand{\dee}{\mathrm{d}}
\newcommand{\Dee}{\mathrm{D}}
\newcommand{\In}{\mathrm{in}}
\newcommand{\Out}{\mathrm{out}}
\newcommand{\pdf}{\mathrm{pdf}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Var}{\mathrm{Var}}

\newcommand{\ve}[1]{\mathbf{#1}}
\newcommand{\mrm}[1]{\mathrm{#1}}
\newcommand{\ves}[1]{\boldsymbol{#1}}
\newcommand{\etal}{{et~al.}}
\newcommand{\sphere}{\mathbb{S}^2}
\newcommand{\modeint}{\mathcal{M}}
\newcommand{\azimint}{\mathcal{N}}
\newcommand{\ra}{\rightarrow}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\sseq}{\subseteq}
\newcommand{\ov}[1]{\overline{#1}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{A Primer on Stochastic Differential Equations}
\author{Pramook Khungurn}

\begin{document}
\maketitle

This note gives basic information on stochastic differential equations. The materials come primarity two books: \cite{Evans:2013}, \cite{Morters:2012}, and \cite{Sarkka:2012}.

What got me interested in the subject was an attempt to understand recent works on deep generativ models, score-based models, in particular. I read a blog post by Yang Song \cite{Song:2021}, and I found that this body of work involves the Langevin equation:
\begin{align*}
  \dee\ve{x} = \frac{1}{2} \nabla \log \pi(\ve{x})\, \dee t + \dee\ve{W}.
\end{align*}
And I have to admit that I have no idea what this equation is about. This note is an attempt to understand the subject to the level that allows me to carry out further reading into the subject.

\section{Introduction}

\begin{itemize}
  \item We study ordinary differential equations to be able to solve the initial value problem: find a function $\ve{x}: [0,\infty) \rightarrow \Real^n$ that satisfies the quations
  \begin{align*}
    \frac{ \dee \ve{x}(t) }{\dee t} &= \ve{b}(\ve{x}(t), t), \\
    \ve{x}(0) &= \ve{x}_0,
  \end{align*}
  where $\ve{b}: \Real^n \times \Real \rightarrow \Real^n$ is a smooth, time-varying vector field, and $\ve{x}_0 \in \Real^n$ is a point in $\Real^n$.

  \item Because the vector field $\ve{b}$ is smooth, the trajectory of $\ve{x}$ would be smooth.
  
  \item In many applications such as molecular simulation and modeling of stock prices, however, the trajectories we want to model are not at all smooth: they are influenced by random noise. It is thus common to change the differential equation to
  \begin{align*}
    \frac{\dee\ve{x}(t)}{\dee t} = \ve{b}(\ve{x}(t), t) + B(\ve{x}(t), t)\ves{\xi}(t)
  \end{align*}
  where $B: \Real^n \times \Real \rightarrow \Real^{n \times m}$ is a matrix-valued function, and $\ves{\xi}(t): [0,\infty) \rightarrow \Real^m$ is an $m$-dimensional ``white noise'' function.

  \item We will go into details about what a white noise is later, but it suffices to say that it corresponds to noise that is i.i.d. in time.
  
  \item It would turn out that our white noise is the time derivative of the {\bf standard Brownion motion}:
  \begin{align*}
    \frac{\dee\ve{W}(t)}{\dee t} = \ves{\xi}(t).
  \end{align*}
  (I think we use the letter $\ve{W}$ because the standard Brownian motion has another name: the {\bf Wiener process}.) We will go into more details on what a Brownian motion is later.

  \item Hence, we can rewrite the differential equation as
  \begin{align}
    \dee\ve{x}(t) &= \ve{b}(\ve{x}(t), t)\, \dee t + B(\ve{x}(t), t)\, \dee\ve{W}(t) \label{eqn:sde}
  \end{align}
  or simply
  \begin{align*}
    \dee\ve{x} &= \ve{b}(\ve{x},t)\, \dee t + B(\ve{x},t)\, \dee\ve{W}, 
  \end{align*}
  and this is a {\bf stochastic differential equation} (SDE).

  \item The standard Brownian motion and the solution to the SDE above are, of course, functions. However, they are not deterministic, but random. Random functions are called {\bf stochastic processes} in literature. We will of course go deeper into what they are later.

  \item Examples of stochastic differential equations include the {\bf Langevin equation}:
  \begin{align*}
    \dee\ve{x} = \frac{1}{2} \nabla \log \pi(\ve{x})\, \dee t + \dee\ve{W}.
  \end{align*}
  Here, in the context of probabilistic modeling, $\pi: \Real^n \rightarrow [0,1]$ is a probability density function of the $\ve{x}$'s.

  \item Another example is from financial modeling. A stock price is often modeled as a {\bf geometric Brownian motion}, which is governed by the following equation:
  \begin{align*}
    \dee S(t) = \mu S(t)\, \dee t + \sigma S(t)\, \dee W(t).
  \end{align*}
  Here, $S: [0,\infty) \rightarrow \Real$ is the scalar stock price, $\mu \in \Real$ is called the {\bf percentage drift}, $\sigma \in \Real^+$ is called the {\bf percentage volatility}, and $W: [0,\infty) \rightarrow \Real$ is the 1D standard Brownian motion. This model is, in turn, used in the famous Black--Scholes formula.\footnote{\url{https://en.wikipedia.org/wiki/Black\%E2\%80\%93Scholes_model}}

  \item To solve an SDE, we integrate both sides of Equation~\ref{eqn:sde} to obtain
  \begin{align*}
    \ve{x}(t) = \ve{x}_0 + \int_0^t \ve{b}(\ve{x}(t), t)\, \dee t + \int_0^t B(\ve{x}(t), t)\, \dee\ve{W}(t).
  \end{align*}
  
  \item The non-obvious part is how to integrate with respect to $\dee\ve{W}(t)$. This integral is neither the Riemann or Lebesgue integral, but a new type of integral called the {\bf It\^{o} integral}. It is a main object of study of this note.
  
  \item Lastly, we will also study how we solve SDEs numerically and will at least cover the Euler--Maruyama method.
\end{itemize}

\section{Brownian Motion and White Noise}

\subsection{Definition and Basic Properties}

\begin{itemize}
  \item In the rest of this note, we will be working with a probability space $(\Omega, \Sigma, P)$ where $\Omega$ is the sample space, $\Sigma$ is a $\sigma$-algebra on $\Omega$, and $P$ is the probability measure on $(\Omega,\Sigma)$.

  \item \begin{definition}
    A {\bf stochastic process} is a collection $\{\ve{X}(t) \in \Real^n : t \geq 0\}$ of random variables. For each point $\omega \in \Omega$, the mapping $t \mapsto \ve{X}(t,\omega)$ is called the {\bf sample path}.
  \end{definition}  

  \item From the above definition, we see that there are two ways to view a stochastic process.
  \begin{itemize}
    \item When viewed as collection of random variables, we see it as a collection of (potentially correlated) random values on the real line.
    \item When viewed from the lens of the sample path, it becomes a random function.
  \end{itemize}

  \item \begin{definition}
    A stochastic process $\{ \ve{X}(t) \in \Real^n: t \geq 0 \}$ is called a {\bf Gaussian process} if, for any $0 \leq t_1 < t_2 < \dotsc < t_k$, the vector $(X(t_1), X(t_2), \dotsc, X(t_k))$ has a (multi-variate) Gaussian distribution. Equivalently, it is a Gaussian process if every linear combination $\sum_{i=1}^k a_i \ve{X}_{t_i}$ is either identically zero or has a (multi-variate) Gausssian distribution.
  \end{definition}

  \item \begin{definition}
    A stochastic process $\{W(t) \in \Real : t \geq 0\}$ is called a {\bf Brownian motion} starting at $x_0 \in \Real$ if the following properties hold.
    \begin{itemize}
      \item $W(0) = x_0$.
      \item The process has independent increments. That is, for all times $0 \leq t_1 < t_2 < \dotsb < t_n$, the increments $W(t_2) - W(t_1)$, $W(t_3) - W(t_2)$, $\dotsc$, $W(t_n) - W(t_{n-1})$ are independent random variables.
      \item For all $t \geq 0$ and $h > 0$, the increment $W(t+h) - W(t)$ is normally distributed with expectation $0$ and variance $h$. In other words, $W(t+h) - W(h) \sim \mcal{N}(0, h)$.
      \item The sample path $t \mapsto W(t,\omega)$ is continuous almost surely (i.e. with probability $1$).
    \end{itemize}
    When $x_0 = 0$, we call it a {\bf standard Brownian motion}.    
  \end{definition}

  \item Note that because, for any $t > 0$, we have that $W(t) = x_0 + W(t) - W(0)$. Hence, $W(t)$ is distributed according to $\mcal{N}(x_0,t)$ for any $t > 0$. (For $t = 0$, we may say that $W(0)$ is a Gaussian distribution with mean $x_0$ and variance $0$.) As a result, a Brownian motion is always a Gaussian process.
  
  \item \begin{theorem}[Weiner 1923]
    The standard Brownian motion exists.
  \end{theorem}

  \begin{proof}[Proof sketch]
    We present a construction by L\'{e}vy and Ciesielski. We first construct the standard Brownian motion on the interval $[0,1]$. Then, the Brownian motion can be extended to $[0,\infty)$ by ``tiling.''

    We start by a family of $\{ h_k(\cdot) \}_{k=0}^\infty$ of {\bf Haar functions}, where each $h_k$ has signature $[0,1] \rightarrow \Real$. The functions are defined as follows.
    \begin{align*}
      h_0(t) &= 1, \\
      h_1(t) &= \begin{cases}
        1, & t \in [0,1/2] \\
        -1, & t \in (1/2,1] \\
      \end{cases}.
    \end{align*}
    For $2^n \leq k < 2^{n+1}$, 
    \begin{align*}
      h_k(t) = \begin{cases}
        1, & t \in [\frac{k-2^n}{2^n}, \frac{k+1/2-2^n}{2^n}]\\
        -1, & t \in [\frac{k+1/2-2^n}{2^n}, \frac{k+1-2^n}{2^n}]\\
        0, & \mbox{otherwise}
      \end{cases}
    \end{align*}
    We have that $\{ h_k(\cdot) \}_{k=0}^\infty$ is an orthonormal basis of the set $L^2(0,1)$ of functions $f: \Real \rightarrow \Real$ such that $\int_0^1 |f(x)|^2 \, \dee x$ is finite.

    From the Harr functions, define the {\bf Schauder functions} as
    \begin{align*}
      s_k(t) = \int_{0}^t h_k(u)\, \dee u
    \end{align*}
    for $t \in [0,1]$. The graph of $s_k$ is a tent of height $2^{-n/2-1}$ on the interval $[\frac{k-2^n}{2^n}, \frac{k+1-2^n}{2^n}]$.

    Let $\{ A_k \}_{k=0}^\infty$ be a sequence of independent $\mcal{N}(0,1)$ random variables. We can define
    \begin{align*}
      W(t,\omega) = \sum_{k=0}^\infty A_k(\omega) s_k(t),
    \end{align*}
    and it can be shown that this function has all the properties of the Brownian motion.
  \end{proof}

  \item \begin{lemma}
    If $W(t)$ is the standard Brownian motion, we have that $E[W(t)] =0$, $E[W^2(t)] = t$, and $$E[W(t)W(s)] = t \wedge s = \min(t,s)$$ for all $t, s \geq 0$.
  \end{lemma}

  \begin{proof}
    Note that, because $W(\cdot)$ is the standard Brownian motion, we have that $W(t) \sim \mcal{N}(0,t)$. So, obviously, $E[W(t)] = 0$. Moreover, we have that $$E[W^2(t)] = E[W^2(t)] - 0 = E[W^2(t)] - E[(W(t))^2] = \mrm{Var}(W(t)) = t.$$
    Now, Assume $t \geq s \geq 0$. We have that.
    \begin{align*}
      E[W(t)W(s)] 
      &= E[(W(s) + W(t) - W(s))W(s)] \\
      &= E[W^2(s)] + E[(W(t) - W(s))W(s)] \\
      &= s + E[(W(t)-W(s))(W(s)-W(0))] \\
      &= s + E[W(t)-W(s)]E[W(s)-W(0)] \\
      &= s + (E[W(t)] - E[W(s)])(E[W(s)] - E[W(0)]) \\
      &= s = \min(t,s) = t \wedge s
    \end{align*}
    as required.    
  \end{proof}

  \item It can be shown that, if $X(t)$ is a Gaussian process such that $E[X(t)X(s)] = t \wedge s$ and $\mrm{Var}(X(0)) = 0$, then it is a Brownian motion.
  
  \item We said earlier that it turned out that the derivative of the Brownian motion is the ``white noise.'' In one dimension, this means that $$\dee W(t) / \dee t = \xi(t)$$ where $\xi(t)$ is the one-dimensional white noise.
  
  \item However, it also turns out that the sample path $t \mapsto W(t,\omega)$ is not differentiable at any $t \geq 0$. So, the derivative does not really exist.

  \item Neverless, we can show that, in a sense, $$E[\xi(t)\xi(s)] = \delta(t-s)$$ where $\delta$ is the Dirac delta function. 
  
  The ``proof'' is as follows. Fix $h > 0$ and $t > 0$. Define
  \begin{align*}
    \phi_h(s) 
    &= E\bigg[ \bigg( \frac{W(t+h) - W(t)}{h} \bigg) \bigg( \frac{W(s+h) - W(s)}{h} \bigg) \bigg] \\
    &= \frac{1}{h^2}\Big( E[W(t+h)W(s+h)] - E[W(t+h)W(s)] - E[W(t)W(s+h)] + E[W(t)W(s)] \Big) \\
    &= \frac{1}{h^2}\Big( (t+h) \wedge (s+h) - (t+h) \wedge s - t \wedge (s+h) + t \wedge s \Big).    
  \end{align*}
  There are 4 cases.
  \begin{enumerate}
    \item If $t+h < s$, then $\phi_s(s) = (t+h - t+h - t + t)/h^2 = 0$.
    \item If $t \leq s < t+h$, then $\phi_s(s) = (t+h - s - t + t)/h^2 = (h+t-s)/h^2$.
    \item If $t-h \leq s < t$, then $\phi_s(s) = (s+h - s - t + s)/h^2 = (h-t+s)/h^2$.
    \item If $s < t-h$, then $\phi_s(s) = (s+h - s - s+h + s)/h^2 = 0$.
  \end{enumerate}
  As a result, $\phi_h(s)$ is a tent function of height $1/h$ over the interval $[t-h,t+h]$. It follows that $\int \phi_h(s)\ \dee s = 1$, and $\lim_{h \rightarrow 0} \phi_h(s) = 0$ when $s \neq t$. As a result, $\lim_{h \rightarrow 0} \phi_h(s) = \delta(t-s)$ where $\delta$ is the Direct delta function.

  \item \begin{definition}
    Let $X(t)$ be a real-valued stochastic process with $E[X^2(t)] < \infty$ for all $t \geq 0$. The {\bf autocorrelation function of $X$} is the function
    \begin{align*}
      r(t,s) = E[X(t)X(s)]
    \end{align*}
    defined for $t, s \geq 0$.
  \end{definition}

  \item \begin{definition}
    We call a stochastic process $X(t)$ {\bf stationary in the wide sence} if
    \begin{itemize}
      \item $r(t-s) = c(t-s)$ for some function $c: \Real \rightarrow \Real$, and
      \item $E[X(t)] = E[X(s)]$
    \end{itemize}
    for all $t, s \geq 0$.
  \end{definition}

  \item \begin{definition}
    Let $X(t)$ be a stochastic process that is stationary in the wide sense with autocorrelation function $c(\cdot)$. The process's {\bf spectral density} is the Fourier transform of the autocorrelation function:
    \begin{align*}
      f(\lambda) = \frac{1}{2\pi} \int_{-\infty}^\infty e^{-i\lambda t} c(t)\ \dee t
    \end{align*}
    for any $\lambda \in \Real$.
  \end{definition}  

  \item Note that the white noise $\xi(t)$ is, in a sense, stationary in the wide sense (i.e., its mean should be zero), and its autocorrelation is given by $c(t-s) = \delta(t-s)$. Its spectral density is given by
  \begin{align*}
    f(\lambda) = \frac{1}{2\pi} \int_{-\infty}^\infty e^{-i\lambda t} \delta(t) \ \dee t = \frac{1}{2\pi}
  \end{align*}
  for all $\lambda$. This is why it is called ``white'' noise.  

  \item We can extend the standard Brownian motion in $\Real$ to one in $\Real^n$.
  \begin{definition}
    A stochastic process $\{ \ve{W}(t) \in \Real^n : t \geq 0 \}$ where $\ve{W}(t) = (W_1(t), W_2(t), \dotsc, W_n(t))$ is an {\bf $n$-dimensional Brownian motion} if it satisfies the following conditions.
    \begin{itemize}
      \item For each $k = 1, 2, \dotsc, n$, we have that $W_k(t)$ is a one-dimensional Brownian motion.
      \item The $\sigma$-algebras
      $\mcal{W}_k = \sigma\bigg( \bigcup_{t \geq 0} \sigma(W_k(t)) \bigg)$,
      for $k = 1, 2, \dotsc, n$, are independent of one another.
    \end{itemize}
  \end{definition}

  \item For an $n$-dimensional Brownian motion, we have that
  \begin{align*}
    E[W_k(t)W_l(t)] &= (t \wedge s)\delta_{kl} \\
    E[(W_k(t) - W_k(s))(W_l(t) - W_l(s))] &= (t - s)\delta_{kl} \\
  \end{align*}
  where 
  \begin{align*}
    \delta_{kl} = \begin{cases}
      1, & k = l \\
      0, & k \neq l
    \end{cases}
  \end{align*}
  is the Kronecker delta function.    
\end{itemize}

\subsection{Properties of Sample Paths}

\begin{itemize}
  \item \begin{definition}
    A function $f: [0, \infty) \rightarrow \Real$ is said to be {\bf locally $\alpha$-H\"{o}lder continuous at} $x \geq 0$ if there exists $\varepsilon > 0$ and $c > 0$ such that
    \begin{align*}
      |f(x) - f(y)| \leq c |x-y|^\alpha
    \end{align*}
    for all $y \geq 0$ such that $|y - x| < \varepsilon$. We refer to $\alpha > 0$ as the {\bf H\"{o}lder exponent} and to $c > 0$ as the {\bf H\"{o}lder constant}.    
  \end{definition}

  \item \begin{theorem}
    Let $W(t)$ be a Brownian motion in 1D.
    \begin{itemize}
      \item If $\alpha < 1/2$, then the sample path $t \mapsto W(t,\omega)$ is everywhere locally $\alpha$-H\"{o}lder continuous almost surely.
      \item If $\alpha > 1/2$, however, it is not locally $\alpha$-H\"{o}lder anywhere almost surely.
    \end{itemize}     
  \end{theorem}

  \item \begin{theorem}
    For all $0 < a < b < \infty$, the sample path $t \mapsto W(t,\omega)$ is not monotone on the interval $[a,b]$ almost surely.
  \end{theorem}

  \item \begin{definition}
    For a function $f: \Real \rightarrow \Real$, the {\bf upper} and {\bf lower right derivatives} are defined as
    \begin{align*}
      D^*\,f(t) &= \limsup_{h\rightarrow 0} \frac{f(t+h)-f(t)}{h}, \\
      D_*\,f(t) &= \liminf_{h\rightarrow 0} \frac{f(t+h)-f(t)}{h}.
    \end{align*}
  \end{definition}

  \item Note that the derivative of $f$ at $t$ exists if and only if $D^*\,f(t) = D_*\,f(t)$.
  
  \item \begin{theorem}[Paley, Wiener, and Zygmund 1933]
    The sample path $t \mapsto W(t,\omega)$ is nowhere differentiable almost surely, Furthermore, for all $t \geq 0$, either $D^*\, W(t) = \infty$ or $D_*\,W(t) = -\infty$, or both almost surely.   
  \end{theorem}

  \item \begin{definition}
    A {\bf partition} $\mcal{P}$ of the interval $[a,b]$ is a set of real numbers where $$\{ a = t_0 < t_1 < t_2 < \dotsb < t_k = b \}.$$ The {\bf mesh size} of $\mcal{P}$ is given by
    $$|\mcal{P}| = \max_{0 < j \leq k} |t_k - t_{k-1}|.$$    
  \end{definition}  

  \item \begin{definition}
    Consider a sequence of partitions $\{ \mcal{P}^{(n)} \}_{n=1}^\infty$ where $$\mcal{P}^{(n)} = \{ a = t_1^{(n)} < t_2^{(n)} < \dotsb < t_{k(n)}^{(n)} = b \}.$$ We call the sequence {\bf nested} if $\mcal{P}^{(n)}$ is a proper subset of $\mcal{P}^{(n+1)}$ for all $n$. In other words, at least one more point is added to each subsequent partition.
  \end{definition}

  \item \begin{definition}
    A function $f: \Real \rightarrow \Real$ is the {\bf variation} of $f$ on the $[a,b]$ is given by
    \begin{align*}
      V^{(1)}_{[a,b]}(f) = \lim_{\substack{n \rightarrow \infty\\|\mcal{P}^{(n)}| \rightarrow 0}} \sum_{j=1}^{k(n)} |f(t_j^{(n)}) - f(t_{j-1}^{(n)})|.
    \end{align*}
    The limit is taken over any nested sequence of partitions $\{ \mcal{P}^{(n)} \}_{n=1}^\infty$ such that $|\mcal{P}^{(n)}| \rightarrow 0$ as $n \rightarrow \infty$. On the other hand, the {\bf quadratic variation} of $f$ on $[a,b]$ is
    \begin{align*}
      V^{(2)}_{[a,b]}(f) = \lim_{\substack{n \rightarrow \infty\\|\mcal{P}^{(n)}| \rightarrow 0}} \sum_{j=1}^{k(n)} \Big( f(t_j^{(n)}) - f(t_{j-1}^{(n)})\Big)^2.
    \end{align*}    
  \end{definition}

  \item \begin{theorem}
    Let $W(t)$ be a Brownian motion. We have that
    \begin{align*}
      V^{(2)}_{[a,b]}(W) &= b-a \\
      V^{(1)}_{[a,b]}(W) &= \infty
    \end{align*}
    for any $0 \leq a < b$. In other words, a Brownian motion has finite quadratic variation but infinite variation.
  \end{theorem}

  \item Note that the fact that $V^{(1)}_{[a,b]}(W)$ follows from the fact that $V^{(2)}_{[a,b]}(W)$ is finite. To see this, note that $W(t)$ is locally $\alpha$-H\"{o}lder. So, for $n$ large enough, we would have that, for any $0 < \alpha < 1/2$.
  \begin{align*}
    |W(t^{(n)}_j) - W(t^{(n)}_{j-1})| &\leq c| t^{(n)}_j - t^{(n)}_{j-1} |^\alpha \leq c| \mcal{P}^{(n)} |^\alpha \\
    \frac{1}{|W(t^{(n)}_j) - W(t^{(n)}_{j-1})|}  & \geq \frac{1}{c|\mcal{P}^{(n)}|^\alpha} \\
    \frac{(W(t^{(n)}_j) - W(t^{(n)}_{j-1}))^2}{|W(t^{(n)}_j) - W(t^{(n)}_{j-1})|}  & \geq \frac{1}{c|\mcal{P}^{(n)}|^\alpha} (W(t^{(n)}_j) - W(t^{(n)}_{j-1}))^2 \\
    |W(t^{(n)}_j) - W(t^{(n)}_{j-1})| &\geq \frac{1}{c|\mcal{P}^{(n)}|^\alpha} (W(t^{(n)}_j) - W(t^{(n)}_{j-1}))^2 \\
    \sum_{j=1}^{k(n)} |W(t^{(n)}_j) - W(t^{(n)}_{j-1})| &\geq \frac{1}{c|\mcal{P}^{(n)}|^\alpha} \sum_{j=1}^{k(n)} (W(t^{(n)}_j) - W(t^{(n)}_{j-1}))^2.
  \end{align*} 
  Taking the limit on both sides, we have that
  \begin{align*}
    V^{(1)}_{[a,b]}(W) \geq V^{(2)}_{[a,b]}(W) \bigg( \lim_{|\mcal{P}^{(n)}| \rightarrow 0} \frac{1}{c|\mcal{P}^{(n)}|^\alpha} \bigg).
  \end{align*}
  So, if $V^{(2)}_{[a,b]}(W)$ is a positive, then $V^{(1)}_{[a,b]}(W)$ would have to be infinite.
\end{itemize}

\subsection{Markov Properties}

\begin{itemize}
  \item Consider a stochastic process $\{ \ve{X}(t) : t \geq 0 \}$. Informally, we say that the process has {\bf Markov property} if, when we want to predict the future $\{ \ve{X}(t) : t \geq s \}$ for some $s \geq 0$ using information from the past $\{ X(t) : 0 \leq t \leq s \}$, then the only useful information is the value of $X(s)$.
  
  \item A process is called a {\bf (time-homogeneous) Markov process} if starts afresh at any fixed time $s$. In other words, the time-shifted process $\{ \ve{X}(s+t) : t \geq 0 \}$ has the same distribution as the processed starting at $\ve{X}(s)$ at time $0$.
  
  \item \begin{theorem}[Markov property]
    A Brownian motion is a Markov process. More precisely, let $\{\ve{W}(t) : t \geq 0\}$ be a Brownian motion starting at $\ve{x}_0 \in \Real^n$, and let $s > 0$. Then, the process $\{ \ve{W}(t+s) - \ve{W}(s) : t \geq 0\}$ is again a Brownian motion starting at the origin, and it is independent of the process $\{ \ve{W}(t) : 0 \leq t \leq s \} $.
  \end{theorem}

  \item \begin{definition}
    A {\bf filtration} on a probability space $(\Omega, \Sigma, P)$ is a family $\{ \Sigma(t): t \geq 0 \}$ of $\sigma$-algebras such that $\Sigma(s) \subseteq \Sigma(t)$ for all $s < t$. 
    
    
    A probabilty space together with a filtration is called a {\bf the filtered probability space}. 
    
    A stochastic process ${X(t): t \geq 0}$ defined on a filtered probability space with filtration $\{ \Sigma(t): t \geq 0 \}$ is said to be {\bf adapted to the filtration} if $X(t)$ is $\Sigma(t)$-measurable for any $t \geq 0$. 
  \end{definition}

  \item Let $\ve{W}(t)$ be a Brownian motion defined on a probabilty space $(\Omega,\Sigma,P)$. We can define a filtration
  \begin{align*}
    \Sigma^0(t) = \sigma(W(s) : 0 \leq s \leq t) = \sigma\bigg( \bigcup_{0\leq s \leq t} \sigma(\ve{W}(s)) \bigg)
  \end{align*}
  to be the $\sigma$-algebra generated by the random variables $\ve{W}(s)$ for $0 \leq s \leq t$. We have that the Brownian motion is adapted to the filtration. The Markov property says that $\{ \ve{W}(t+s) - \ve{W}(s) : t \geq 0 \}$ is independent of $\Sigma^0(s)$.

  \item The Markov property can be slightly improved. Define
  \begin{align*}
    \Sigma^+(s) = \bigcap_{t > s} \Sigma^0(t).
  \end{align*}
  Intuitively, it contains all information common to the future of the Brownian motion from time $s$. We have that the family $\{ \Sigma^+(t): t \geq 0 \}$ is a filtration. Moreover, $\Sigma^0(s) \subseteq \Sigma^+(s)$ because $\Sigma^+(s)$ has an infinitesimally more information about the future.

  \item \begin{theorem}[Slightly stronger Markov property]
    The process $\{ \ve{W}(t+s) - \ve{W}(s) : t \geq 0 \}$ is independent of the $\sigma$-algebra $\Sigma^+(s)$.
  \end{theorem}

  \item The Markov property means that a Brownian motion is started anew at each deterministic time instance. However, this is also true for a class of random times called ``stopping time.''
  
  \item Intuitively, a stopping time $T$ is a random variable such that we can deduce whether $T \leq t$ by only observing the path of the stochastic process up to time $t$. In other words, the set $\{ T \leq t\}$ (which is an abbreviation for $\{ \omega \in \Omega : T(\omega) \leq t \} $) is an event in $\Sigma(t)$.
  
  \begin{definition}
    A random variable $T$ with values in $[0,\infty)$ defined on a probability space with filtration $\{ \Sigma(t): t \geq 0 \}$ is called a {\bf stopping time} with respect to the filtration if $\{ T \leq t \} \in \Sigma(t)$ for all $t \geq 0$.
  \end{definition}

  \item \begin{theorem}[Strong Markov property]
    For every almost surely finite stopping time $T$, the process $\{ \ve{W}(T+t) - \ve{W}(T) : t \geq 0 \}$ is a Brownian motion starting at $\ve{0}$ independent of $\Sigma^+(T)$.
  \end{theorem}
\end{itemize}

\section{Stochastic Integrals}

\begin{itemize}
  \item Recall that our end goal is to solve the initial value problem
  \begin{align*}
    \dee\ve{X}(t) &= \ve{b}(\ve{X}(t), t)\, \dee t + B(\ve{X}(t), t)\, \dee\ve{W}(t) \\
    \ve{X}(0) &= \ve{x}_0
  \end{align*}
  where $\ve{X}(t)$ is a stochastic process, and $\ve{W}(t)$ is the standard Brownian motion in $\Real^n$.

  \item We said in the introduction would be
  \begin{align*}
    \ve{X}(t) = \ve{x}_0 + \int_0^t \ve{b}(\ve{X}(t), t)\, \dee t + \int_0^t B(\ve{X}(t), t)\, \dee\ve{W}(t)
  \end{align*}
  As a result, we need to define the integral of the form
  \begin{align*}
    \int_0^t \ve{G}(t)\, \dee\ve{W}(t)
  \end{align*}
  where $\ve{G}$ is a stochastic process.

  \item Note that, in real analysis, there is a way to define integrals of the form $$\int_a^b f(x)\, \dee \alpha(x)$$ where $f$ and $\alpha$ are both functions. This is the {\bf Riemann--Stieltjes integral}, which is defined as follows.
  
  \begin{itemize}
    \item We start with a sequence of nested partitions $\{ \mcal{P}^{(n)} \}_{n=1}^\infty$ of $[a,b]$.
    
    \item Given a partition $\mcal{P}^{(n)}$, we define the Riemann--Stieltjes sums: 
    \begin{align*}
      \mcal{S}(f, \alpha, \mcal{P}^{(n)}) &= \sum_{j=1}^{k(n)} f(\tau_j^{(n)}) [\alpha(t_j^{(n)}) - \alpha(t_{j-1}^{(n)})]
    \end{align*}
    where $\tau_j^{(n)} \in [t_{j-1}^{(n)}, t_{j}^{(n)}]$.
    
    \item The Riemann--Stieltjes integral is the defined as
    \begin{align*}
      \int_a^b f(x)\, \dee\alpha(x) = \lim_{\substack{ n \rightarrow \infty \\ |\mcal{P}^{(n)}| \rightarrow 0 }} \mcal{S}(f, \alpha, \mcal{P}^{(n)})
    \end{align*}
    provided that the limit exists.
  \end{itemize}

  \item If $\alpha$ is differentiable on $[a,b]$, we have that
  \begin{align*}
    \int_a^b f(x)\, \dee\alpha(x) = \int_a^b f(x)\alpha'(x)\, \dee x.
  \end{align*}
  Hence, the integral $\int \ve{G}(t)\, \dee\ve{W}(t)$ that we want to compute would correspond to $\int \ve{G}(t)\ves{\xi}(t) \, \dee t$, and the form $\ve{G}(t)\ves{\xi}(t)$ is the one we started our modeling with.

  \item It is tempting to use the Riemann--Stieltjes integral to define the stochastic integral. However, the existence of the Riemann--Stieltjes integrals rests on the premise that $\mcal{S}(f, \alpha, \mcal{P}^{(n)})$ does not change based on the choise of $\tau^{(n)}_j$ as we take the limit. This is true for deterministic functions, but is not true for the Brownian motion.
  
  \item In fact, one can show that, for any $0 \leq \lambda \leq 1$, one can show that, if we pick
  \begin{align*}
    \tau_{j}^{(n)} = (1-\lambda) t_{j-1}^{(n)} + \lambda t_{j}^{(n)},
  \end{align*}
  then
  \begin{align*}
    \lim_{\substack{ n \rightarrow \infty \\ |\mcal{P}^{(n)}| \rightarrow 0 }} \mcal{S}(W, W, \mcal{P}^{(n)}) = \frac{(W(T))^2}{2} + \bigg( \lambda - \frac{1}{2} \bigg) T
  \end{align*}
  when $\{ \mcal{P}^{(n)} \}_{n=1}^\infty$ partitions $[0,T]$.

  \item It\^{o}'s definition of stochastic integral uses $\lambda = 0$. So, 
  \begin{align*}
    \int_0^T W\, \dee W = \frac{W(T)^2}{2} - \frac{T}{2}.
  \end{align*}
  This shows that stochastic integrals are different from deterministic integrals. Who could have expected the $-T/2$ term to show up?  
\end{itemize}

\subsection{One-Dimensional It\^{o} Integral}

\begin{itemize}
  \item The It\^{o} integral is defined using a combination of three techniques.
  \begin{itemize}
    \item[(a)] Integration with respect to a function as done in the Riemann--Stieltjes integral.
    \item[(b)] Approximation by simple functions as used in the Lebesgue integral.
    \item[(c)] Fixing $\tau_{j}^{(n)} = t_{j}^{(n)}$ (i.e., $\lambda = 0$) as discussed above.
  \end{itemize}
  Using (a) and (b) together gets you the ``Lebesgue--Stieltjes integral,'' adding (c) yields the It\^{o} integral.

  \item First, however, we need to discuss the class of stochastic processes $G$ upon which the integral $\int G\, \dee W$ can be defined.
  
  \item \begin{definition}
    A stochastic process $\{ X(t, \omega): t \geq 0, \omega \in \Omega \}$ defined on a probability space $(\Omega, \Sigma, P)$ that is adapted to a filtration $\{ \Sigma(t) : t \geq 0 \}$ is called {\bf progressively measurable} if, for each $t \geq 0$, the mapping $X: [0,t] \times \Omega \rightarrow \Real$ is measurable with respect to the $\sigma$-algebra $\mcal{B}([0,,1]) \times \Sigma(t)$.
  \end{definition}

  \item \begin{lemma}
    Any process which is adapted and is either right or left continuous is progressively measurable.
  \end{lemma}

  \item We then proceeed with the definition of simple functions in the context of stochastic processes.
  
  \begin{definition}
    A {\bf step process on $[0,T]$} is a real-valued stochastic process $\{ H(t,\omega) : t \geq 0, \omega \in \Omega \}$ of the form
    \begin{align*}
      H(t,\omega) = \sum_{i=1}^k A_i(\omega) \chi_{[t_{i}, t_{i+1})}(t)
    \end{align*}
    where $0 = t_1 \leq t_2 \leq \dotsb \leq t_{k+1} = T$, $A_i$ is a $\Sigma(t)$-measurable random variable (which only depends on $\omega$), and $\chi_{[t_{i-1}, t_{i+1})}(t)$ is the charactistic function of the interval $[t_{i}, t_{i+1})$. That is,
    \begin{align*}
      \chi_{[t_{i}, t_{i+1})}(t) = \begin{cases}
        1, & t_{i} \leq t < t_{i+1} \\
        0, & \mbox{otherwise}
      \end{cases}.
    \end{align*}        
  \end{definition}

  Note that a step process only takes finitely many values.

  \item \begin{definition}
    Let $\{H(t,\omega): t \geq 0, \omega \in \Omega\}$ be a real-valued progressively measurable step process on $[0,T]$ defined on a probability space $(\Omega,\Sigma,P)$ with filtration $\{ \Sigma(t): t \geq 0 \}$ to which the standard Brownian motion $\{W(t) : t \geq 0\}$ is adapted. Define the {\bf It\^{o} integral of $H$ with respect to $W$} to be
    \begin{align*}
      \int_0^T H(t)\, \dee W(t) = \sum_{i=1}^k A_i ( W(t_{i+1}) - W(t_{i})).
    \end{align*}    
  \end{definition}

  \item The definition of the Lebegue integral relies on the fact that every measurable function has a sequence of simple functions that converges to it. The construcion involes a series of increasing and non-negative step functions, which converges as a result of the monotone convergence theorem. The construction of the It\^{o} integral, however, typically uses a different notion of convergence: convergence in the $L^2$ norm.
  
  \item \begin{definition}
    Let $\{H(t) : t \geq 0\}$ be a real-valued stochastic process. The {\bf $L^p$ norm of $H$ on $[0,T]$} is given by
    \begin{align*}
      \| H \|_p = \bigg( E \bigg[ \int_0^T |H(t)|^p\, \dee t \bigg] \bigg)^{1/p}
    \end{align*}
    where the integration on the RHS is the Lebesgue integral on the real line performed on a sample path of $H$. We denote by $\mcal{L}^p(0,T)$ the space of all real-valued, progressively measurable stochastic process $H$ such that $\| H \|_p < \infty$.    
  \end{definition}

  \item \begin{lemma}
    If $G \in \mcal{L}^2(0,T)$, there exists a sequence of bounded step processes $\{H^{(n)} \}_{n=1}^\infty$ in $\mcal{L}^2(0,T)$ such that
    $\lim_{n \rightarrow 0} \| G - H^{(n)} \|_2 = 0$.    
  \end{lemma}

  \item \begin{definition}
    Let $G \in \mcal{L}^2(0,T)$. The {\bf It\^{o} integral of $G$ on $[0,T]$} is defined to be
    \begin{align*}
      \int_0^T G\, \dee W = \lim_{n \rightarrow 0} \int_0^T H^{(n)}\, \dee W
    \end{align*}
    where $\{H^{(n)} \}_{n=1}^\infty$ is a sequence of step processes in $\mcal{L}^2(0,T)$ such that $\lim_{n \rightarrow 0} \| G - H^{(n)} \|_2 = 0$. The integral defined in this way does not depend on the particular sequence of step processes used to approximate $G$.
  \end{definition}  

  \item \begin{theorem}
    For all constants $a, b \in \Real$ and for all $G, H \in \mcal{L}^2(0,T)$, we have that
    \begin{align*}
      \int_0^T (aG + bH)\, \dee W &= a \int_0^T G\, \dee W + b \int_0^T H\, \dee W, \\
      E\bigg[ \int_0^T G\, \dee W \bigg] &= 0, \\
      E\bigg[ \bigg( \int_0^T G\, \dee W \bigg)^2 \bigg] &= E \bigg[ \int_0^T G^2\, \dee W \bigg], \\
      E\bigg[ \bigg( \int_0^T G\, \dee W \bigg) \bigg( \int_0^T H\, \dee W \bigg) \bigg] &= E \bigg[ \int_0^T GH \, \dee W \bigg]. 
    \end{align*}
  \end{theorem}
\end{itemize}

\subsection{It\^{o}'s Chain and Product Rules}

\begin{itemize}
  \item \begin{definition}
    Suppose that $\{ X(t) : t \geq 0 \}$ is a real-valued stochastic process satisfying
    \begin{align*}
      X(r) = X(s) + \int_s^r F\, \dee t + \int_s^r G\, \dee W
    \end{align*}
    for some $F \in \mcal{L}^1(0,T)$, $G \in \mcal{L}^2(0,T)$, and all times $0 \leq s \leq t \leq T$. We say that $X(t)$ has a {\bf stochastic differential}
    \begin{align*}
      \dee X = F\, \dee t + G\, \dee W
    \end{align*}
    for $0 \leq t \leq T$.
  \end{definition}

  \item \begin{theorem}[It\^{o}'s chain rule]
    Suppose that $X(t)$ has a stochastic differential $\dee X = F\, \dee t + G\, \dee W$. Let $u: \Real \times [0,T] \rightarrow \Real$ be a constinuous function that $u(x,t)$ has continuous partial derivatives $$u_t = \frac{\partial u}{\partial t},\mbox{ }u_x = \frac{\partial u}{\partial x},\mbox{ and }\mu_{xx} = \frac{\partial^2 u}{\partial x^2}.$$ Then, $Y(t) = u(X(t),t)$ has a stochastic differential 
    \begin{align*}
      \dee Y = \dee U(X,t) 
      &= u_t\,\dee t + u_x\, \dee X + \frac{1}{2} u_{xx} G^2\, \dee t \\
      &= \bigg(u_t + u_x F + \frac{1}{2}u_{xx} G^2\bigg)\, \dee t + u_x G\, \dee W.
    \end{align*}
  \end{theorem}

  \item \begin{example}
    Let $X = W$, and $u(x) = x^m$. We have that $u_t(W) = 0$, $u_x(W) = mW^{m-1}$, and $u_{xx}(W) = m(m-1)W^{m-2}$. Moreover, $F = 0$ and $G = 1$, so the It\^{o}'s chain rule yields
    \begin{align*}
      \dee(W^m) 
      = \dee u(W)
      &= \bigg(u_t(W) + u_x(W) F + \frac{1}{2}u_{xx}(W) G^2\bigg)\, \dee t + u_x(W) G\, \dee W \\
      &= \frac{1}{2} m(m-1) W^{m-2}\, \dee t + mW^{m-1}\, \dee W.
    \end{align*}
  \end{example}
  
  
\end{itemize}

\bibliographystyle{apalike}
\bibliography{sde-primer}  
\end{document} 