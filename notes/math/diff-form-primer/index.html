<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>A Primer on Differential Forms</title>

    <!-- Bootstrap -->
    <link href="../../../css/bootstrap.min.css" rel="stylesheet">
    <link href="../../../css/theme.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- MathJax -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: {autoNumber: "AMS"} } 
    });
    </script>
    <script type="text/javascript"
            src="../../../MathJax/MathJax.js?config=TeX-AMS_HTML-full">
    </script>

    <script type="text/javascript" src="../../../js/jquery-3.4.1.min.js"></script>    
    <script type="text/javascript" src="../../../js/bigfoot.min.js"></script>    

    <link rel="stylesheet" type="text/css" href="../../../css/bigfoot-default.css">    

</head>
<body>
<div class="container">
    <span style="visibility: hidden;">
        \(
        \def\sc#1{\dosc#1\csod}
        \def\dosc#1#2\csod{{\rm #1{\small #2}}}

        \newcommand{\dee}{\mathrm{d}}
        \newcommand{\Dee}{\mathrm{D}}
        \newcommand{\In}{\mathrm{in}}
        \newcommand{\Out}{\mathrm{out}}
        \newcommand{\pdf}{\mathrm{pdf}}
        \newcommand{\Cov}{\mathrm{Cov}}
        \newcommand{\Var}{\mathrm{Var}}

        \newcommand{\ve}[1]{\mathbf{#1}}
        \newcommand{\mrm}[1]{\mathrm{#1}}
        \newcommand{\etal}{{et~al.}}
        \newcommand{\sphere}{\mathbb{S}^2}
        \newcommand{\modeint}{\mathcal{M}}
        \newcommand{\azimint}{\mathcal{N}}
        \newcommand{\ra}{\rightarrow}
        \newcommand{\mcal}[1]{\mathcal{#1}}
        \newcommand{\X}{\mathcal{X}}
        \newcommand{\Y}{\mathcal{Y}}
        \newcommand{\Z}{\mathcal{Z}}
        \newcommand{\x}{\mathbf{x}}
        \newcommand{\y}{\mathbf{y}}
        \newcommand{\z}{\mathbf{z}}
        \newcommand{\tr}{\mathrm{tr}}
        \newcommand{\sgn}{\mathrm{sgn}}
        \newcommand{\diag}{\mathrm{diag}}
        \newcommand{\Real}{\mathbb{R}}
        \newcommand{\sseq}{\subseteq}
        \newcommand{\ov}[1]{\overline{#1}}
        \DeclareMathOperator*{\argmax}{arg\,max}
        \DeclareMathOperator*{\argmin}{arg\,min}

        \newcommand{\data}{\mathrm{data}}
        \newcommand{\N}{\mathcal{N}}
        \newcommand{\Hil}{\mathcal{H}}
        \)
    </span>

    <br>
    <h1>A Primer on Differential Forms</h1>
    <hr>

    <p>This is an introductory on differential forms that goes through the materials without touching the concept of tensors. It ends with an introduction of the generalized Stoke's theorem and discusses its connection to the famous theorems of vector calculus (Green's, Gauss's (aka divergence), and Stoke's).</p>

    <p>The material for this note is lifted from several sources:
    <ul>
        <li><a href="https://arxiv.org/abs/1604.07862">Lecture Notes on Differential Forms</a> by Lorenzo Sadun.</li>
        <li><a href="https://www.cefns.nau.edu/~schulz/diff.pdf">A Practical Introduction to Differential Forms</a> by Alexia E. Schulz and William C. Schulz.</li>
        <li><a href="https://www.math.purdue.edu/~arapura/preprints/diffforms.pdf">Introduction to differential forms</a> by Donu Arapura.</li>
        <li>The book <a href="https://www.amazon.com/Analysis-Manifolds-Advanced-Books-Classics/dp/0201315963">Analysis on Manifolds</a> by James Munkres.</li>
    </ul>
    </p>

    <h1>1 &nbsp; Differential Forms</h1>

    <p>We denote a point in $\Real^n$ with $\ve{x} = (x^1, x^2, \dotsc, x^n)$.</p><hr>

    <p>For $\Real^n$, there are $n$ differential symbols $\dee x^1$, $\dee x^2$, $\dotsc$, $\dee x^n$. In this note, we shall not care what they exactly mean.</p><hr>

    <p>We say that the set $$\{ a_1 \dee x^1 + \dotsb + a_n \dee x^n : a_1 \in \Real, a_2 \in \Real, \dotsc, a_n \in \Real \}$$ is an $n$-dimensional real vector with $\dee x^1$, $\dotsc,$ $\dee x^n$ acting as its basis vectors. In other words, we say that additions and multiplications by scalar can be performed on the symbols. The usual rules of vector spaces apply here.</p><hr>

    <p>We define a binary operator called the <b>wedge product</b>, denoted by $\wedge$, on the elements of the above vector space. The wedge product is <b>anti-symmetric:</b> 
    $$\dee x^i \wedge \dee x^j = - \dee x^j \wedge \dee x^i$$ for all $i,j \in [n] = \{ 1,2,\dotsc, n \}.$ It also interacts sensibly with itself, addition, and multiplication by scalar. In other words, let $\alpha, \beta, \gamma$ be arbitrary wedge productsof $\dee x^i$'s, and let $c$ be an arbitrary constant. The following identities hold:
    <ul>
        <li><b>Right distribution.</b> $$(\alpha + \beta) \wedge \gamma = \alpha \wedge \gamma + \beta \wedge \gamma.$$</li>
        <li><b>Left distribution.</b> $$\alpha \wedge (\beta + \gamma) = \alpha \wedge \beta + \alpha \wedge \gamma.$$</li>
        <li><b>Association.</b> $$(\alpha \wedge \beta) \wedge \gamma = \alpha \wedge (\beta \wedge \gamma).$$</li>
        <li><b>Commutativity with multiplication.</b> $$(c \alpha) \wedge \beta = \alpha \wedge (c\beta) = c(\alpha \wedge \beta).$$</li>
    </ul>
    </li>
    </p><hr>

    <p>Anti-symmetry implies that $\dee x^i \wedge \dee x^i = 0$. As a consequence, for any $\dee x^{i_1} \wedge \dotsb \wedge \dee x^{i_k}$ with a pair of repeated index, we have that $\dee x^{i_1} \wedge \dotsb \wedge \dee x^{i_k} = 0$. Hence, in a simplified expression, we would only see each $\dee x^i$ appearing no more than once in each term.</p><hr>

    <p><b>Definition.</b> In $\Real^n$, a <b>$k$-form</b> is an expression of the form
    \begin{align*}
        \sum_{I} f_I(\ve{x}) \dee x^I
    \end{align*}
    where 
    <ul>
        <li>$I$ is a sequence $(i_1, i_2, \dotsc, i_k) \in [n]^k$ whose elements are distinct,</li>
        <li>$f_I(\ve{x})$ is a function from $\Real^n \rightarrow \Real$, and</li>
        <li>$\dee x^I$ is a shorthand for $\dee x^{i_1} \wedge \dee x^{i_2} \wedge \dotsb \wedge \dee x^{i_k}$.</li>
    </ul>
    Note that a $0$-form is just a function $f: \Real^n \rightarrow \Real$.
    </p>
    <hr>

    <p><b>Example.</b> In $\Real^3$, a 0-form has the form 
    $$f(x,y,z).$$
    A 1-form has the form 
    \begin{align*}
    f(x,y,z)\,\dee x + g(x,y,z)\,\dee y + h(x,y,z)\,\dee z.
    \end{align*}
    A 2-form has the from
    \begin{align*}
    f(x,y,z)\,\dee y \wedge \dee z 
    + g(x,y,z)\,\dee z \wedge \dee x 
    + h(x,y,z)\,\dee x \wedge \dee y.
    \end{align*}
    A 3-form has the form 
    $$f(x,y,z)\, \dee x \wedge \dee y \wedge \dee z.$$
    There is no 4-form, 5-form, or any other higer order form on $\Real^3$ as any of them would have repeated differential symbols.    
    </p><hr>

    <p>We say that a $k$-form has degree $k$. In $\Real^n$, there is ${n \choose k}$ linearly independent $\dee x^I$'s of degree $k$, and there are $2^n$ linearly independent $\dee x^I$'s of all possible degrees.</p><hr>

    <p>If $I'$ is a permutation of $I$', then $\dee x^{I'} = \pm \dee x^I$. Hence, when expanding a $k$-form, we would choose a natural ordering of the indices (typically $i_1 < i_2 < \dotsc < i_k$) and write out the terms with the wedge product part conforming to this ordering.</p><hr>

    <p><b>Definition.</b> Let $\alpha = \sum \alpha_I(\ve{x})\, \dee x^I$ be a $k$-form and $\beta = \sum_J \beta_J(\ve{x})\, \dee x^J$ be an $\ell$-form. Then, define
    \begin{align*}
        \alpha \wedge \beta = \sum_{I,J} \alpha_I(\ve{x}) \beta_J(\ve{x})\, \dee x^I \wedge \dee x^J.
    \end{align*}
    </p><hr>

    <p>Because going from $(I,J)$ to $(J,I)$ involves $k \ell$ swaps, we have that
    \begin{align*}
        \dee x^I \wedge \dee x^J = (-1)^{k\ell} \dee x^J \wedge \dee x^J.
    \end{align*}
    As a result,
    \begin{align*}
    \alpha \wedge \beta = (-1)^{k\ell} \alpha \wedge \beta.
    \end{align*}
    </p><hr>

    <p>
    We can compute the wedge project between a 0-form (i.e., a function $\Real^n \rightarrow \Real$) with a $k$-form. The result is just the multiplication of the 0-form function with the coefficient functions. In other words,
    \begin{align*}
        f(\ve{x}) \wedge \bigg( \sum_{I} \alpha_I(\ve{x})\, \dee x^I \bigg) = \sum_{I} f(\ve{x}) \alpha_I(\ve{x})\, \dee x^I = \bigg( \sum_{I} \alpha_I(\ve{x})\, \dee x^I \bigg) \wedge f(\ve{x}).
    \end{align*}
    In other words, the wedge product with a $0$-form is just a straight multiplication.
    </p><hr>

    <h2>2 &nbsp; Derivative of Forms</h2>

    <p><b>Definition.</b> Let $\alpha = \sum_I \alpha_I(\ve{x})\, \dee x^I$ be a $k$-form on $\Real^n$. Its <b>exterior derivative</b> is the $(k+1)$-form
    \begin{align*}
        \dee \alpha = \sum_{I} \sum_{j=1}^n \frac{\partial \alpha_I(\ve{x})}{\partial x^j}\, \dee x^j \wedge \dee x^I.
    \end{align*}
    </p><hr>

    <p><b>Example.</b> Let $\alpha = xy\,\dee x + e^x \, \dee y.$ Then,
    \begin{align*}
        \dee \alpha 
        &= y\, \dee x \wedge \dee x + x\, \dee y \wedge \dee x + e^x\, \dee x \wedge \dee y \\
        &= (e^x -y)\, \dee x \wedge \dee y.
    \end{align*}
    </p><hr>

    <p><b>Example.</b> If $f$ is a 0-form, then we have that
    \begin{align*}
        \dee f = \sum_{j=1}^n \frac{\partial f(\ve{x})}{\partial x^j}\, \dee x^j,
    \end{align*}
    which is a formula for the total differential of $f$.
    </p><hr>

    <p><b>Example.</b> Recall that $x^i$ is a function on $\Real^n$. It sends $\ve{x}$ to its $i$th component. With this, we have that
    \begin{align*}
        \dee (x^i) = \sum_{j=1}^n \frac{\partial x_i}{\partial x_j}\, \dee x^j = \dee x^i.
    \end{align*}
    So, the definition above is consistent.
    </p><hr>

    <p><b>Proposition.</b> $\dee$ is a linear operator. In particular, for any $k$-form $\alpha$ and $\beta$ and constants $a,b \in \Real$, we have that
    \begin{align*}
    d(a\alpha + b\beta) = a\,\dee\alpha + b\,\dee\beta
    \end{align*}    
    </p>

    <p><i>Proof.</i> Algebraic manipulation because I'm too lazy to write it out. $\square$</p>
    <hr>

    <p><b>Proposition.</b> If $\alpha$ is a $k$-form and $\beta$ is an $\ell$-form, then
    \begin{align*}
    \dee(\alpha \wedge \beta) = (\dee \alpha) \wedge \beta + (-1)^k \alpha \wedge (\dee \beta).
    \end{align*}    
    </p>

    <p><i>Proof.</i> Algebraic manipulation because I'm too lazy to write it out. $\square$</p>
    <hr>

    <p><b>Propoisiton.</b> We have that $\dee(\dee\alpha) = 0$ for any $k$-form $\alpha$.</p>

    <p><i>Proof.</i> We do induction on the order of $\alpha$.</p>

    <p>In the base case, $\alpha$ is a 0-form. So, $\alpha = f(\ve{x})$ for some $f: \Real^n \rightarrow \Real$. So,
    \begin{align*}
        \dee \alpha &= \dee f = \sum_{j=1}^n \frac{\partial f}{\partial x^j}\, \dee x^j \\
        \dee(\dee\alpha) &= \dee \bigg( \sum_{i=1}^n \frac{\partial f}{\partial x^i}\, \dee x^i \bigg) \\
        &= \sum_{i=1}^n \sum_{j=1}^n \frac{\partial}{\partial x^j} \bigg( \frac{\partial f}{\partial x^i} \bigg)\, \dee x^j \wedge \dee x^i \\
        &= \sum_{i=1}^n \sum_{j=1}^n \frac{\partial^2 f}{\partial x^i \partial x^j} \, \dee x^j \wedge \dee x^i \\
        &= \bigg( \sum_{i=1}^n\frac{\partial^2 f}{(\partial x^i)^2} \, \dee x^i \wedge \dee x^i \bigg) + \bigg( \sum_{i=1}^n \sum_{j\neq i} \frac{\partial^2 f}{\partial x^i \partial x^j} \, \dee x^j \wedge \dee x^i \bigg) \\
        &= 0.        
    \end{align*}
    The first term is zero because $\dee x^i \wedge \dee x^i = 0$. The second term is zero because $\dee x^i \wedge \dee x^j = -\dee x^j \wedge \dee x^i$, and so each term has another term that cancels it.
    </p>

    <p>Suppose by way of induction that $\dee(\dee\alpha) = 0$ for all $\alpha$ of order up to $k$. Consider the $(k+1)$-form
    \begin{align*}
        \alpha_I(\ve{x})\, \dee x^I 
        = \alpha_I(\ve{x})\, \dee x^{i_1} \wedge \dee x^{i_2} \wedge \dotsc \wedge \dee x^{i_{k+1}}
        = (\alpha_I(\ve{x})\, \dee x^{i_1}) \wedge (\dee x^{i_2} \wedge \dotsc \wedge \dee x^{i_{k+1}}).
    \end{align*}
    Let us abbreviate $\alpha_I(\ve{x})\, \dee x^{i_1}$ with $\beta$ and $\dee x^{i_2} \wedge \dotsc \wedge \dee x^{i_{k+1}}$ with $\gamma$. The expression becomes:
    \begin{align*}
        \alpha_I(\ve{x})\, \dee x^I = \beta \wedge \gamma.
    \end{align*}
    So,
    \begin{align*}
        \dee(\beta \wedge \gamma) 
        &= \dee\beta \wedge \gamma - \beta \wedge \dee\gamma \\
        \dee\big( \dee(\beta \wedge \gamma) \big)
        &= \dee\big( \dee\beta \wedge \gamma \big) - \dee\big( \beta \wedge \dee\gamma \big) \\
        &= \dee(\dee\beta) \wedge \gamma + \dee\beta \wedge \dee\gamma - \dee\beta \wedge \dee\gamma + \beta \wedge \dee\dee(\gamma) \\
        &= \dee(\dee\beta) \wedge \gamma + (\dee\beta \wedge \dee\gamma - \dee\beta \wedge \dee\gamma) + \beta \wedge \dee\dee(\gamma) \\
        &= 0 + 0 + 0 = 0.
    \end{align*}
    Because all $(k+1)$-form can be written as $\sum_{I} \alpha_I(\ve{x})\, \dee x^I$, it follows that $\dee(\dee\alpha) = 0$ for all $(k+1)$-form. $\square$
    </p>
    <hr>

    <h2>3 &nbsp; grad, curl, and div</h2>

    <p>Consider a vector field $\ve{v}(\ve{x}) = \big(v_1(\ve{x}), v_2(\ve{x}), v_3(\ve{x})\big)$ in $\Real^3$.</p>

    <p>From it, we define a 1-form
    \begin{align*}
        w^1_{\ve{v}} = v_1\, \dee x + v_2\, \dee y + v_3\, \dee z,
    \end{align*}
    and a 2-form
    \begin{align*}
        w^2_{\ve{v}} = v_1\, \dee y \wedge \dee z + v_2\, \dee z \wedge \dee x + v_3 \, \dee x \wedge \dee y.
    \end{align*}
    </p><hr>

    <p>Let $f: \Real^3 \rightarrow \Real$ be a smooth scalar function. The <b>gradient</b> of $f$, denoted by $\nabla f$ or $\mathrm{grad}\,f$, is the vector field
    \begin{align*}
        \nabla f = \bigg( \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z} \bigg).
    \end{align*}
    Note that
    \begin{align*}
        \dee f 
        &= \frac{\partial f}{\partial x}\, \dee x 
        + \frac{\partial f}{\partial y}\, \dee y
        + \frac{\partial f}{\partial z}\, \dee z
        = w^1_{\nabla f}.
    \end{align*}
    </p><hr>

    <p>For any smooth vector field $\ve{v}$ in $\Real^3$, the <b>curl</b> of $\ve{v}$, denoted by $\nabla \times \ve{v}$ or $\mathrm{curl}\,\ve{v}$, is the vector field
    \begin{align*}
        \nabla \times \ve{v}
        = \begin{vmatrix}
        \ve{i} & \ve{j} & \ve{k} \\
        \frac{\partial}{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z} \\
        v_1 & v_2 & v_3        
        \end{vmatrix}
        = \bigg( \frac{\partial v_3}{\partial y} - \frac{\partial v_2}{\partial z} \bigg) \ve{i}
        + \bigg( \frac{\partial v_1}{\partial z} - \frac{\partial v_3}{\partial x} \bigg) \ve{j}
        + \bigg( \frac{\partial v_2}{\partial x} - \frac{\partial v_1}{\partial y} \bigg) \ve{k}.
    \end{align*}
    Note that
    \begin{align*}
        w^2_{\nabla \times \ve{v}}
        &= \bigg( \frac{\partial v_3}{\partial y} - \frac{\partial v_2}{\partial z} \bigg)\, \dee y \wedge \dee z
        + \bigg( \frac{\partial v_1}{\partial z} - \frac{\partial v_3}{\partial x} \bigg)\, \dee z \wedge \dee x
        + \bigg( \frac{\partial v_2}{\partial x} - \frac{\partial v_1}{\partial y} \bigg)\, \dee x \wedge \dee y,
    \end{align*}    
    and also that
    \begin{align*}
        \dee w^1_{\ve{v}}
        &= \dee (v_1\, \dee x + v_2\, \dee y + v_3\, \dee z) \\
        &= \bigg( 
            \frac{\partial v_1}{\partial x}\, \dee x \wedge \dee x 
            + \frac{\partial v_1}{\partial y}\, \dee y \wedge \dee x 
            + \frac{\partial v_1}{\partial z}\, \dee z \wedge \dee x 
        \bigg) \\
        & \quad + \bigg( 
            \frac{\partial v_2}{\partial x}\, \dee x \wedge \dee y 
            + \frac{\partial v_2}{\partial y}\, \dee y \wedge \dee y 
            + \frac{\partial v_2}{\partial z}\, \dee z \wedge \dee y 
        \bigg) \\
        & \quad + \bigg( 
            \frac{\partial v_3}{\partial x}\, \dee x \wedge \dee z 
            + \frac{\partial v_3}{\partial y}\, \dee y \wedge \dee z 
            + \frac{\partial v_3}{\partial z}\, \dee z \wedge \dee z 
        \bigg) \\
        &= \bigg( 
            - \frac{\partial v_1}{\partial y}\, \dee x \wedge \dee y 
            + \frac{\partial v_1}{\partial z}\, \dee z \wedge \dee x 
        \bigg) \\
        & \quad + \bigg( 
            \frac{\partial v_2}{\partial x}\, \dee x \wedge \dee y 
            - \frac{\partial v_2}{\partial z}\, \dee y \wedge \dee z 
        \bigg) \\
        & \quad + \bigg( 
            - \frac{\partial v_3}{\partial x}\, \dee z \wedge \dee x 
            + \frac{\partial v_3}{\partial y}\, \dee y \wedge \dee z 
        \bigg) \\
        &= \bigg( \frac{\partial v_3}{\partial y} - \frac{\partial v_2}{\partial z} \bigg)\, \dee y \wedge \dee z
        + \bigg( \frac{\partial v_1}{\partial z} - \frac{\partial v_3}{\partial x} \bigg)\, \dee z \wedge \dee x
        + \bigg( \frac{\partial v_2}{\partial x} - \frac{\partial v_1}{\partial y} \bigg)\, \dee x \wedge \dee y.
    \end{align*}
    Hence,
    \begin{align*}
        \dee w^1_{\ve{v}} = w^2_{\nabla \times \ve{v}}.
    \end{align*}
    </p><hr>

    <p>
    The <b>divergence</b> of a smooth vector field $\ve{v}$, denoted by $\nabla \cdot \ve{v}$ or $\mathrm{div}\,\ve{v}$, is the scalar field
    \begin{align*}
        \nabla \cdot \ve{v} = \frac{\partial v_1}{\partial x} + \frac{\partial v_2}{\partial y} + \frac{\partial v_3}{\partial z}.
    \end{align*}
    Now, we have that
    \begin{align*}
    \dee w_{\ve{v}}^2 
    &= \dee\big( v_1\, \dee y \wedge \dee z + v_2\, \dee z \wedge \dee x + v_3 \, \dee x \wedge \dee y \big) \\
    &= \dee( v_1\, \dee y) \wedge \dee z + \dee (v_2\, \dee z) \wedge \dee x + \dee(v_3 \, \dee x) \wedge \dee y.    
    \end{align*} 
    Consider the $\dee(v_1\, \dee y) \wedge \dee z$ term. We have that
    \begin{align*}
        \dee(v_1\, \dee y) \wedge \dee z
        &= \bigg( \frac{\partial v_1}{\partial x}\, \dee x \wedge \dee y + \frac{\partial v_1}{\partial y}\, \dee y \wedge \dee y + \frac{\partial v_1}{\partial z}\, \dee z \wedge \dee y \bigg) \wedge \dee z \\
        &= \frac{\partial v_1}{\partial x}\, \dee x \wedge \dee y \wedge \dee z + \frac{\partial v_1}{\partial y}\, \dee y \wedge \dee y \wedge \dee z + \frac{\partial v_1}{\partial z}\, \dee z \wedge \dee y \wedge \dee z \\
        &= \frac{\partial v_1}{\partial x}\, \dee x \wedge \dee y \wedge \dee z.
    \end{align*}
    We see that the $\dee(v_1\, \dee y)$ term produces three 2-forms. When these are multipled with $\dee z$, it will produces three 3-forms, and two of them will disappear because of repeated differential symbols. The only term that remains would be the term tha contains all three symbols. Using the same argument, we can deduce that
    \begin{align*}
        \dee(v_2\,\dee z) \wedge \dee x 
        &= \frac{\partial v_2}{\partial y}\, \dee y \wedge \dee z \wedge \dee x
        = \frac{\partial v_2}{\partial y}\, \dee x \wedge \dee y \wedge \dee z \\
        \dee(v_3\,\dee x) \wedge \dee y
        &= \frac{\partial v_3}{\partial z}\, \dee z \wedge \dee x \wedge \dee y 
        = \frac{\partial v_3}{\partial z}\, \dee x \wedge \dee y \wedge \dee z.
    \end{align*}
    As a result,
    \begin{align*}
    \dee w_{\ve{v}}^2 
    &= \frac{\partial v_1}{\partial x}\, \dee x \wedge \dee y \wedge \dee z
    + \frac{\partial v_2}{\partial y}\, \dee x \wedge \dee y \wedge \dee z
    + \frac{\partial v_3}{\partial z}\, \dee x \wedge \dee y \wedge \dee z \\
    &= \bigg( \frac{\partial v_1}{\partial x} + \frac{\partial v_2}{\partial y} + \frac{\partial v_3}{\partial z} \bigg) \, \dee x \wedge \dee y \wedge \dee z \\
    &= (\nabla \cdot \ve{v})\, \dee x \wedge \dee y \wedge \dee z.
    \end{align*}
    </p><hr>

    <h2>4 &nbsp; Poincare's Lemma</h2>

    <p><b>Definition.</b> A form $\omega$ is <b>closed</b> if $\dee \omega = 0$.</p><hr>

    <p><b>Definition.</b> A form $\omega$ is <b>exact</b> if $\omega = \dee \nu$ for some form $\nu$.</p><hr>

    <p>Because $\dee(\dee\nu) = 0$, every exact form is closed.</p><hr>

    <p>It is not true that every closed form is exact. Whether a closed form is exact, is the subject of <b>Poincare's lemma</b>. To state it, though, we need a notion of <i>simply connectedness.</i></p><hr>

    <p><b>Definition (informal).</b> A region $A$ is <b>simply connected</b > if and only if any simpled closed curve in $A$ can be continuously shrunk to a point in $K$.</p><hr>

    <p><b>Examples.</b>
    <ul>
        <li>A unit disk $\{(x,y) : x^2 + y^2 \leq 1 \}$ is simply connected.</li>

        <li>The annulus $\{ (x,y) : 1/2 \leq x^2 + y^2 \leq 1 \}$, while connected, is not simply connected. This is because the circle $\{ (x,y) : x^2 + y^2 = 3/4 \}$ cannot be shrunk to a point while staying in the annulus all the time.</li>
    </ul>
    </p><hr>

    <p>We now state without proof Poincare's lemma.</p>

    <p><b>Theorem (Poincare's Lemma).</b> Let $A$ be simply connected region in $\Real^n$ and $\omega$ be a $k$-form defined on $A$ such that $\dee\omega = 0$. Then, there exists a $(k-1)$-form $\nu$ such that $\omega = d\nu$. In other words, all closed form $\omega$ in $A$ is exact.</p>
    <hr>

    <p><b>Example.</b> Consider the form
    \begin{align*}
        \omega = \frac{x}{x^2 + y^2}\, \dee y - \frac{y}{x^2 + y^2}\, \dee x
    \end{align*}
    which is defined on the set $\Real^2 - \{(0,0)\}$. We have that
    \begin{align*}
        \dee\omega
        &= \frac{\partial}{\partial x}\bigg( \frac{x}{x^2 + y^2} \bigg)\, \dee x \wedge \dee y
        - \frac{\partial}{\partial y} \bigg( \frac{y}{x^2 + y^2} \bigg)\, \dee y \wedge \dee x \\
        &= \bigg[ \frac{\partial}{\partial x}\bigg( \frac{x}{x^2 + y^2} \bigg)
        + \frac{\partial}{\partial y} \bigg( \frac{y}{x^2 + y^2} \bigg)\bigg]\, \dee x \wedge \dee y \\
        &= \bigg[ \frac{(x^2 + y^2) - x(2x)}{(x^2 + y^2)^2} + \frac{(x^2 + y^2) - y(2y)}{(x^2 + y^2)^2} \bigg]\, \dee x \wedge \dee y \\
        &= \bigg[ \frac{-x^2 + y^2}{(x^2 + y^2)^2} + \frac{x^2 - y^2}{(x^2 + y^2)^2} \bigg]\, \dee x \wedge \dee y \\
        &= 0.
    \end{align*}
    So, $\omega$ is closed. However, it is not true that $\omega$ is exact. We will see this later.
    </p><hr>

    <h2>5 &nbsp; Pullbacks</h2>

    <p>The concept of <i>pullbacks</i> is related to the change of variables we peform when we compute an integral. Let's illustrate this with an example.</p><hr>

    <p><b>Example.</b> Let $\mathcal{U}$ and $\mathcal{X}$ be two subsets of $\Real^3$. Let us denote an element of $\mathcal{U}$ and $\mathcal{X}$ by $(u^1,u^2,u^3)$ and $(x^1,x^2,x^3)$, respectively. Consider a smooth function $\ve{g}: \mathcal{U} \rightarrow \mathcal{X}$. We can write
    \begin{align*}
        x^1 &= g_1(u^1,u^2,u^3) \\
        x^2 &= g_2(u^1,u^2,u^3) \\
        x^3 &= g_2(u^1,u^2,u^3).        
    \end{align*}
    We are interested in writing the 1-form
    \begin{align*}
        \alpha_1(\ve{x})\, \dee x^1
        + \alpha_2(\ve{x})\, \dee x^2
        + \alpha_3(\ve{x})\, \dee x^3
    \end{align*}
    defined on $\mathcal{X}$ as a 1-form
    \begin{align*}
        \beta_1(\ve{u})\, \dee u^1
        + \beta_2(\ve{u})\, \dee u^2
        + \beta_3(\ve{u})\, \dee u^3.
    \end{align*}
    We have that
    \begin{align*}
        \dee x 
        &= \frac{\partial g_1}{\partial u} \dee u
        + \frac{\partial g_1}{\partial v} \dee v 
        + \frac{\partial g_1}{\partial w} \dee w \\
        \dee y &= \frac{\partial g_2}{\partial u} \dee u
        + \frac{\partial g_2}{\partial v} \dee v 
        + \frac{\partial g_2}{\partial w} \dee w \\
        \dee z &= \frac{\partial g_3}{\partial u} \dee u
        + \frac{\partial g_3}{\partial v} \dee v 
        + \frac{\partial g_3}{\partial w} \dee w.
    \end{align*}
    In other words,
    \begin{align*}
        \begin{bmatrix}
            \dee x \\ \dee y \\ \dee z
        \end{bmatrix}
        = \begin{bmatrix}
            \frac{\partial g_1}{\partial u} & \frac{\partial g_1}{\partial v} & \frac{\partial g_1}{\partial w} \\
            \frac{\partial g_2}{\partial u} & \frac{\partial g_2}{\partial v} & \frac{\partial g_2}{\partial w} \\
            \frac{\partial g_3}{\partial u} & \frac{\partial g_3}{\partial v} & \frac{\partial g_3}{\partial w}
        \end{bmatrix}
        \begin{bmatrix}
            \dee u \\ \dee v \\ \dee w
        \end{bmatrix}
        = D\ve{g} \begin{bmatrix}
            \dee u \\ \dee v \\ \dee w
        \end{bmatrix}.
    \end{align*}
    Here $D\ve{g}$ is the Jacobian matrix of $\ve{g}$. Now, 
    \begin{align*}
    \alpha_1(\ve{x})\,\dee x^1 + \alpha_2(\ve{x})\,\dee x^2 + \alpha_3(\ve{x})\,\dee x^3
    &= \begin{bmatrix}
    \alpha_1(\ve{x}) & \alpha_2(\ve{x}) & \alpha_3(\ve{x})
    \end{bmatrix}
    \begin{bmatrix}
        \dee x^1 \\ \dee x^2 \\ \dee x^3
    \end{bmatrix} \\
    &= \begin{bmatrix}
    \alpha_1(\ve{x}) & \alpha_2(\ve{x}) & \alpha_3(\ve{x})
    \end{bmatrix}
    \, D\ve{g} \,
    \begin{bmatrix}
        \dee u^1 \\ \dee u^2 \\ \dee u^3
    \end{bmatrix} \\    
    &= \begin{bmatrix}
    \alpha_1(\ve{g}(\ve{u})) & \alpha_2(\ve{g}(\ve{u})) & \alpha_3(\ve{g}(\ve{u}))
    \end{bmatrix}
    \, D\ve{g} \,
    \begin{bmatrix}
        \dee u^1 \\ \dee u^2 \\ \dee u^3
    \end{bmatrix} \\
    &= \begin{bmatrix}
    (\alpha_1 \circ \ve{g})(\ve{u}) & (\alpha_2 \circ \ve{g})(\ve{u}) & (\alpha_3 \circ \ve{g})(\ve{u})
    \end{bmatrix}
    \, D\ve{g} \,
    \begin{bmatrix}
        \dee u^1 \\ \dee u^2 \\ \dee u^3
    \end{bmatrix}.    
    \end{align*}
    The last line gives us the formula for $ \beta_1(\ve{u})\, \dee u^1
    + \beta_2(\ve{u})\, \dee u^2
    + \beta_3(\ve{u})\, \dee u^3$.
    </p>
        
    <p>The map that sends $\alpha_1(\ve{x})\,\dee x^1 + \alpha_2(\ve{x})\,\dee x^2 + \alpha_3(\ve{x})\,\dee x^3$ to 
    \begin{align*}
    \begin{bmatrix}
    (\alpha_1 \circ \ve{g})(\ve{u}) & (\alpha_2 \circ \ve{g})(\ve{u}) & (\alpha_3 \circ \ve{g})(\ve{u})
    \end{bmatrix}
    \, D\ve{g} \,
    \begin{bmatrix}
        \dee u^1 \\ \dee u^2 \\ \dee u^3
    \end{bmatrix}
    \end{align*}
    is called the <b>pullback</b> associated with $\ve{g}$. It is denoted by $\ve{g}^*$.
    </p>

    <p>Note that he derivation in this examples gives the following identity:
    \begin{align*}
    \ve{g}^*\bigg( \sum_{i=1}^3 \alpha_i(\ve{x})\, \dee x^i \bigg) 
    &= \sum_{i=1}^3 (\alpha_i \circ \ve{g}) (\ve{u}) \bigg( \sum_{j=1}^3 \frac{\partial g_i}{\partial u^j}\, \dee u^j \bigg).
    \end{align*}
    </p>
    <hr>

    <p>We can generalize the above derivation to all forms in $\mathcal{X} \subseteq \Real^n$ and $\mathcal{U} \subseteq \Real^m$. The process of converting a form $\sum_{I} \alpha_I(\ve{x})\, \dee x^I$ in $\ve{X}$ to a form on $\ve{U}$ would be as follows:
    <ol>
        <li>For each coefficient function $\alpha_I(\ve{x})$, we convert it to $(\alpha_I \circ \ve{g})(\ve{u})$.</li>
        <li>For each differential symbol $\dee x^i$, we expand it to $\sum_{j=1}^m \frac{\partial g_i}{\partial u^j}\, \dee u^j$</li>

        <li>We then expand out all the terms, and the result should be a differential form on $\mathcal{U}$.</li>
    </ol>
    The process is captured by the following formula:
    \begin{align}
        \ve{g}^*\bigg( \sum_{I \in 2^{[n]}} \alpha_I(\ve{x})\, \dee x^I \bigg) = \sum_{I \in 2^{[n]}} (\alpha_I \circ \ve{g})(\ve{u}) \bigg[ \bigwedge_{i \in I}^n \bigg( \sum_{j=1}^m \frac{\partial g_i}{\partial u^j}\, \dee u^j \bigg) \bigg] \label{pullback}
    \end{align}
    where $2^{[n]}$ is the power set of $[n]$.
    </p><hr>

    <p>To facilitate further discussion, we shall introduce new notations. For a function $f: \Real^n \rightarrow \Real$, we let $\partial_i f$ denote the partial derivative of $f$ with respect to the $i$th argument. This notation allows us to easily write $\partial_i f (\ve{x})$, which means that the partial derivative function evaluated at point $\ve{x}$. This would have been quite clumsy to write in the more standard notation.
    </p>

    <p>With this notation, the differential of a function $f: \Real^m \rightarrow \Real$ would be a function that sends a point in $\Real^m$ to a 1-form whose coefficients are real numbers:
    \begin{align*}
        \dee f(\ve{x}) 
        &= \sum_{i=1}^n \partial_i f(\ve{x})\, \dee x^i        
    \end{align*}
    </p>

    <p>We can also consider the differential of $f \circ \ve{g}$, which can be written as follows:
    \begin{align*}
        \dee(f \circ \ve{g})(\ve{u})
        &= \sum_{j=1}^m \partial_j(f \circ \ve{g})(\ve{u})\, \dee u^j \\
        &= \sum_{j=1}^m \bigg( \sum_{i=1}^n \partial_i f(\ve{g}(\ve{u})) \partial_j g_i(\ve{u}) \bigg)\, \dee u^j \\
        &= \sum_{i=1}^n \partial_i f(\ve{g}(\ve{u})) \bigg( \sum_{j=1}^m   \partial_j g_i(\ve{u})\, \dee u^j \bigg) \\
        &= \sum_{i=1}^n (\partial_i f \circ \ve{g})(\ve{u}) \bigg( \sum_{j=1}^m   \partial_j g_i(\ve{u})\, \dee u^j \bigg).
    \end{align*}
    In other words,
    \begin{align*}
        \dee(f \circ \ve{g})
        &= \sum_{i=1}^n (\partial_i f \circ \ve{g}) \bigg( \sum_{j=1}^m   \partial_j g_i\, \dee u^j \bigg)
    \end{align*}
    </p>
    <hr>

    <p><b>Theorem.</b> Given a smooth mapping $\ve{g}: \mathcal{U} \rightarrow \mathcal{X}$. There is a linear map $\ve{g^*}$ taking forms on $\mathcal{X}$ to forms on $\mathcal{U}$ with the following properties:
    <ol>
        <li>If $f: \mathcal{X} \rightarrow R$, then $\ve{g}^*(f) = f \circ g$ (which is a function with signature $\mathcal{U} \rightarrow \Real$).</li>

        <li>If $\alpha$ and $\beta$ are forms on $\mathcal{X}$, then $\ve{g}^*(\alpha \wedge \beta) = \ve{g}^*(\alpha) \wedge \ve{g}^*(\beta)$.</li>

        <li>If $\alpha$ is a form on $\mathcal{X}$, then $\ve{g}^*(\dee \alpha) = \dee(\ve{g}^*(\alpha))$.</li>
    </ol>
    </p>

    <p><i>Proof.</i> We define $\ve{g}^*$ with equation $\eqref{pullback}$. Property 1 would follow immediately from the definition. It should also be clear that the map is linear because one can check from the definition that $\ve{g}^*(c_1 \alpha + c_2 \beta) = c_1 \ve{g}^*(\alpha) + c_2 \ve{g}^*(\beta)$ for any forms $\alpha$, $\beta$ and any $c_1, c_2 \in \Real$.</p>

    <p>To aid further discussion, let us observe that
    \begin{align}
        \ve{g}^*(\dee x^i) 
        = \sum_{j=1}^n \frac{\partial g_i}{\partial u^j}\, \dee u^j  
        = \sum_{j=1}^n \partial_j g_i\, \dee u^j  
        \label{pullback-differential}
    \end{align}
    So, we can rewrite $\eqref{pullback}$ as
    \begin{align*}
        \ve{g}^*\bigg( \sum_{I} \alpha_I(\ve{x})\, \dee x^I \bigg) = \sum_{I} \ve{g}^*(\alpha_I) \bigg( \bigwedge_{i\in I} \ve{g}^*(\dee x^i) \bigg)
    \end{align*}
    In other words, the $\ve{g}^*$ operator distributes through addition and wedge product.
    </p>

    <p>For Property 2, we have that
    \begin{align*}
        \ve{g}^*(\alpha \wedge \beta)
        &= \ve{g}^* \Bigg( \bigg( \sum_{I} \alpha_I(\ve{x}) \, \dee x^I \bigg) \wedge \bigg( \sum_{J} \beta_J(\ve{x}) \, \dee x^J \bigg) \Bigg)\\
        &= \ve{g}^* \bigg( \sum_I \sum_J \alpha_I(\ve{x})\beta_J(\ve{x})\, \dee x^I \wedge \dee x^J \bigg) \\        
        &= \ve{g}^* \Bigg( \sum_I \sum_J \alpha_I(\ve{x})\beta_J(\ve{x})\, \bigg( \bigwedge_{i\in I} \dee x^i \bigg) \wedge \bigg( \bigwedge_{j \in J} \dee x^j \bigg) \Bigg) \\
        &= \sum_I \sum_J \ve{g}^*(\alpha_I(\ve{x})\beta_J(\ve{x}))\, \bigg( \bigwedge_{i\in I} \ve{g}^*(\dee x^i) \bigg) \wedge \bigg( \bigwedge_{j \in J} \ve{g}^*(\dee x^j) \bigg) \\
        &= \sum_I \sum_J \alpha_I(\ve{g}(\ve{u}))\beta_J(\ve{g}(\ve{u})))\, \bigg( \bigwedge_{i\in I} \ve{g}^*(\dee x^i) \bigg) \wedge \bigg( \bigwedge_{j \in J} \ve{g}^*(\dee x^j) \bigg) \\
        &= \sum_I \sum_J \ve{g}^*(\alpha_I)\ve{g}^*(\beta_j) \, \bigg( \bigwedge_{i\in I} \ve{g}^*(\dee x^i) \bigg) \wedge \bigg( \bigwedge_{j \in J} \ve{g}^*(\dee x^j) \bigg) \\
        &= \bigg[ \sum_I \ve{g}^*(\alpha_I)\, \bigg( \bigwedge_{i\in I} \ve{g}^*(\dee x^i) \bigg) \bigg] \wedge
        \bigg[ \sum_J \ve{g}^*(\beta_j)\, \bigg( \bigwedge_{j \in J} \ve{g}^*(\dee x^j) \bigg) \bigg] \\
        &= \ve{g}^*(\alpha) \wedge \ve{g}^*(\beta).
    \end{align*}
    </p>

    <p>For Property 3, we first consider the variable $x^i$ as a function that maps $\ve{x}$ to its $i$th component. We have that $\ve{g}^*(x^i) = x^i \circ \ve{g} = g_i$. Taking the derivative in the $\mathcal{U}$ domain, we have that
    \begin{align*}
        \dee (\ve{g}^*(x^i)) = \dee g_i = \sum_{j=1}^n \partial_j g_i\, \dee u^j = \ve{g}^*(\dee x^i).
    \end{align*}
    The last equality comes from $\eqref{pullback-differential}$.
    </p>

    <p>Next, we consider a scalar function $f: \mathcal{X} \rightarrow \Real$. We have that
    \begin{align*}
        \dee(\ve{g}^*(f)) 
        &= \dee(f \circ \ve{g}) 
        = \sum_{i=1}^n (\partial_i f \circ \ve{g}) \bigg( \sum_{j=1}^m   \partial_j g_i\, \dee u^j \bigg).
    \end{align*}
    Also,
    \begin{align*}
        \ve{g}^*(\dee f)
        = \ve{g}^*\bigg( \sum_{i=1}^n \partial_if\, \dee x^i \bigg)
        = \sum_{i=1}^n \ve{g}^*(\partial_if)\, \ve{g}^*(\dee x^i)
        = \sum_{i=1}^n (\partial_if \circ \ve{g}) \bigg( \sum_{j=1}^m   \partial_j g_i\, \dee u^j \bigg).
    \end{align*}
    As a result,
    \begin{align*}
        \dee(\ve{g}^*(f)) = \ve{g}^*(\dee f)
    \end{align*}
    for all $f: \mathcal{X} \rightarrow \Real$.
    </p>

    <p>
    Next, we check forms that look like $f\, \dee x^I = f\, \dee x^{i_0} \wedge \dotsb \wedge \dee x^{i_k} = f \wedge \dee x^{i_0} \wedge \dotsb \wedge \dee x^{i_k}$.
    \begin{align*}
        \ve{g^*}(\dee (f \wedge \dee x^{i_0} \wedge \dotsb \wedge \dee x^{i_k}))
        &= \ve{g^*} \bigg( \sum_{i=1}^n \partial_i f\, \dee x^i \wedge \dee x^{i_0} \wedge \dotsb \wedge \dee x^{i_k} \bigg) \\
        &= \sum_{i=1}^n \ve{g^*}(\partial_i f) \, \ve{g^*}(\dee x^i) \wedge \ve{g^*}(\dee x^{i_0}) \wedge \dotsb \wedge \ve{g^*}(\dee x^{i_k}) \\
        &= \sum_{i=1}^n \ve{g^*}(\partial_i f) \, \dee(\ve{g^*}(x^i)) \wedge \dee(\ve{g^*}(x^{i_0})) \wedge \dotsb \wedge \dee(\ve{g^*}(x^{i_k})).
    \end{align*}
    We also have that
    \begin{align*}
    \dee[\ve{g^*} (f \wedge \dee x^{i_0} \wedge \dotsb \wedge \dee x^{i_k})]
    &= \dee[\ve{g^*}(f)\wedge \ve{g^*}(\dee x^{i_0}) \wedge \dotsb \ve{g^*}(\dee x^{i_k})]\\
    &= \dee[(f\circ \ve{g}) \wedge \dee(\ve{g^*}(x^{i_0})) \wedge \dotsb \dee(\ve{g^*}(x^{i_k}))] \\
    &= \dee(f\circ \ve{g}) \wedge \dee(\ve{g^*}(x^{i_0})) \wedge \dotsb \dee(\ve{g^*}(x^{i_k})) \\
    &= \sum_{i=1}^n \ve{g^*}(\partial_i f) \, \dee(\ve{g^*}(x^i)) \wedge \dee(\ve{g^*}(x^{i_0})) \wedge \dotsb \wedge \dee(\ve{g^*}(x^{i_k})).
    \end{align*}
    The above two equations imply that
    \begin{align*}
        \ve{g}^*(\dee(f\, \dee x^I)) = \dee(\ve{g}^*(f\, \dee x^I)).
    \end{align*}
    Because all forms can be written as $\alpha = \sum_I \alpha_I\, \dee x^I$ and both $\dee$ and $\ve{g}^*$ distribute through addition, we have that $\dee(\ve{g}^*(\alpha)) = \ve{g}^*(\dee \alpha)$ for every form $\alpha$. $\square$
    </p>
    <hr>    

    <p>
    Let $\mathcal{X}$ be a subset of $\Real^n$. The form $\dee x^1 \wedge \dotsb \wedge x^n$ is called the <b>volume from</b>.
    </p><hr>

    <p>
    An important special case is the effect of the pullback associated with $\ve{g}: \Real^n \rightarrow \Real^n$ on the volume form. We have that
    \begin{align*}
        \ve{g}^*(\dee x^1 \wedge \dotsb \wedge \dee x^n)
        &= \ve{g}^*(\dee x^1) \wedge \dotsb \wedge \ve{g}^*(\dee x^n) \\
        &= \bigg( \sum_{i=1}^n \frac{\partial g_1}{\partial u^i}\, \dee u^i \bigg) \wedge \dotsb \wedge \bigg( \sum_{i=1}^n \frac{\partial g_n}{\partial u^i}\, \dee u^i \bigg).
    \end{align*}    
    Our task would then be to compute the coefficienct of $\dee u^1 \wedge \dotsb \dee u^n$ of the above expression. To make a $\dee u^1 \wedge \dotsb \dee u^n$, we need to choose one $\dee u^1$ term, one $\dee u^2$ term, and one $\dee u^3$ term and so on from the $n$ sums. This corresponds to a permutation $\pi \in \mathfrak{S}_n$, which yields the term
    \begin{align*}
        \bigg(\prod_{i=1}^n \frac{\partial g_i}{\partial u^{\pi(i)}}\bigg)
        \, \dee u^{\pi(1)} \wedge \dotsb \wedge \dee u^{\pi(n)}.
    \end{align*}
    However, the differentials in $\dee u^{\pi(1)} \wedge \dotsb \wedge \dee u^{\pi(n)}$ are not in the right order because we want $\dee u^1 \wedge \dotsb \wedge \dee u^n$. So, we need to swap them to make $\dee u^1 \wedge \dotsb \wedge u^n$. The sign change corresponding to this swap is the sign of the permutation $\sgn(\pi)$. As a result, each permutation $\pi \in \mathfrak{S}_n$ yields the term
    \begin{align*}
        \bigg(\prod_{i=1}^n \frac{\partial g_i}{\partial u^{\pi(i)}}\bigg)\, \dee u^1 \wedge \dotsb \wedge \dee u^n.
    \end{align*}
    Summing over all permuntations, we have that
    \begin{align*}
        \ve{g}^*(\dee x^1 \wedge \dotsb \wedge \dee x^n)
        &= \dee u^1 \wedge \dotsb \wedge \dee u^n
        \bigg( \sum_{\pi \in \mathfrak{S}_n} \sgn(\pi) \prod_{i=1}^n \frac{\partial g_i}{\partial u^{\pi(i)}} \bigg) \\
        &= (\det D\ve{g})\, \dee u^1 \wedge \dotsb \wedge \dee u^n.
    \end{align*}
    We can see that this is the standard change of variable formula in integral calculus.
    </p><hr>

    <p>Let us identify the pullback in the case of $k$-forms in $\Real^n$. We have that a $k$-form can be written as
    \begin{align*}
        \sum_{I \subseteq [n],|I|=k} \alpha_I\, \dee x^I.
    \end{align*}
    Here, when we write $\dee x^I$, we turn the set into the sequence with increasing elements. Let us denote the elements of $I$ by $i_1$, $i_2$, $\dotsc$, $i_k$ with $i_1 < i_2 < \dotsb < i_k$. We have that
    \begin{align*}
        \sum_{I \subseteq [n],|I|=k} \alpha_I\, \bigwedge_{\ell=1}^k \dee x^{i_\ell}
        = \sum_{I \subseteq [n],|I|=k} \alpha_I\, \bigwedge_{\ell=1}^k \bigg( \sum_{j=1}^m \frac{\partial g_{i_\ell}}{\dee u^j}\, \dee u^j \bigg).
    \end{align*}
    Expanding the above expression out would result in an expression of the form
    \begin{align*}
        \sum_{J \subseteq [m],|J|=k} \beta_J\, \dee u^J.
    \end{align*}
    Our job is then to write $\beta_J$ in terms of $\alpha_I$ and the partial derivatives $\partial g_i / \partial u_j$. We know that $\beta_J$ would be a linear combination of the $\alpha_I$:
    \begin{align*}
        \beta_J = \sum_{I} c_{J,I} \alpha_I
    \end{align*}
    where $c_{J,I}$ is the element of the $J$-row and $I$-colmn of the matrix representation of $\ve{g}^*$. We have that $c_{J,I}$ is the coefficient of $\dee u^J$ in the expression
    \begin{align*}
    \bigwedge_{\ell=1}^k \bigg( \sum_{j=1}^m \frac{\partial g_{i_\ell}}{\dee u^j}\, \dee u^j \bigg).
    \end{align*}
    Using the logic of selecting each $\dee u^{j}$ for all $j \in J$ from the $k$ sums, we have that
    \begin{align*}
        c_{J,I} = \det(D\ve{g}[I,J]).
    \end{align*}
    Here, $D\ve{g}[I,J]$ denotes the submatrix of $D\ve{g}$ with only rows whose indices are in $I$ and columns whose indices are in $J$.
    </p><hr>

    <h2>4 &nbsp; Integration</h2>

    <p><b>Definition.</b> If $f: \Real^n \rightarrow \Real$, the <b>support</b> of $f$ is the closure of the set $\{ \ve{x} : \alpha(\ve{x}) = 0 \}$.</p>

    <p>If $\ve{x} \not\in \mathrm{Support}\ f$, then there is a neighborhood of $\ve{x}$ where $f$ vanishes.</p><hr>

    <p>
    <b>Definition.</b> Let $\alpha = f\, \dee x^1 \wedge \dotsb \wedge \dee x^n$ be an $n$-form on $\Real^n$, and suppose that it is compactly supported (i.e., $f$ is compactedly supported to allow manipulations such as Fubini's theorem). Define
    \begin{align*}
        \int_{\mathcal{X}} \alpha = \int_{\mathcal{X}} f(\ve{x})\, \dee x^1 \wedge \dee x^2 \wedge \dotsb \wedge \dee x^n = \int_{\mathcal{X}} f(\ve{x})\, |\dee x^1 \dee x^2 \dotsc \dee x^n|
    \end{align*}
    where $\mathcal{X}$ is any subset of $\Real^n$ where $f$ is compactly supported. The RHS is an ordinary Riemann integral, in which $|\dee x^1 \dee x^2 \dotsc \dee x^n|$ is the usual volume measure.
    </p><hr>

    <p>When $n = 0$, $\Real^n$ is a single point, and the form $\alpha$ is just a number. We take $\int \alpha$ to be that number.</p><hr>

    <p><b>Definition.</b> A <b>frame</b> is a sequence $(\ve{a}_1, \ve{a}_2, \dotsc, \ve{a}_n)$ of $n$ linearly independent vectors in an $n$-dimensional vector space.
    </p>    
    <hr>

    <p><b>Definition.</b>  We say a frame $(\ve{a}_1, \ve{a}_2, \dotsc, \ve{a}_n)$ in $\Real^n$ is <b>right-handed</b> or <b>positively oriented</b> if $\det \begin{bmatrix} \ve{a}_1 & \ve{a}_2 & \dotsm & \ve{a}_n \end{bmatrix} > 0$. Otherwise, we call it <b>left-handed</b> or <b>negatively oriented</b>.</p>

    <p>We can also extend this definition to any $n$-dimensional vector space $V$. Pick a linear isomorphism $T: \Real^n \rightarrow V$. The orientation of a frame $(\ve{v}_1, \dotsc, \ve{v}_n)$ is determined by $(T^{-1}(\ve{a}_1), T^{-1}(\ve{a}_2), \dotsc, T^{-1}(\ve{a}_n))$. Note that, for an arbitrary vector space, there is no well defined notation of right-handedness because it depends on the map $T$.</p>
    <hr>

    <p><b>Definition.</b> The collection of all right-handed frame in $\Real^n$ is called an <b>orientation</b> of $\Real^n$, and so is the collection of all left-handed frames.</p>    

    <p>These definitions also extend to any vector space $V$ in the same way as what was done in the previous definition.</p>
    <hr>

    <p><b>Definition.</b> A non-singular matrix $C \in \Real^{n \times n}$ is <b>orientation-preserving</b> if $\det C > 0$; otherwise, it is <b>orientation-reverseing</b>. We also say the same thing for the linear transformation $h(\ve{x}) = C\ve{x}$.</p><hr>

    <p><b>Definition.</b> A function $\ve{g}:\Real^n \rightarrow \Real^n$ is <b>orientation-preserving</b> at $\ve{x}$ if $D\ve{g}(\ve{x})$ is orientation-preserving. We say a function is orientation-preserving if it is orientation-preserving at all points in its domain.</p><hr>

    <p><b>Definition.</b> A <b>diffeomorphism</b> is an invertible function such that both itself and its inverse are smooth (i.e, having a continuous derivative).</p><hr>

    <p>If $\ve{g}$ is an orientation-preserving diffeomorphism from an open subset $\mathcal{U}$ of $\Real^n$ to another open set $\mathcal{X} \subseteq \Real^n$. Let $\alpha$ be a compactly supported $n$-form on $\mathcal{X}$. We have that
    \begin{align*}
    \int_{\mathcal{U}} \ve{g}^*\alpha = \int_{\mathcal{X}} \alpha.
    \end{align*}
    </p><hr>    

    <p><b>Proposition.</b> Let $\mathcal{A}$ be a collection of open sets in $\Real^n$, and let $A$ be their union. There exists a sequence $\rho_1$, $\rho_2$, $\dotsc$ of functions $\phi_i: \Real^n \rightarrow \Real$ such that:
    <ol>
        <li>$\rho_i(\ve{x}) \geq 0$ for all $\ve{x}$.</li>
        <li>The set $S_i = \mathrm{Support}\ \rho_i$ is contained in $A$.</li>
        <li>Each point of $A$ has a neighborhood that intersects only fintely many of the sets $S_i$.</li>
        <li>$\sum_{i=1}^\infty \rho_i(\ve{x}) = 1$ for each $\ve{x} \in A$.</li>
        <li>The function $\phi_i$ are of class $C^\infty$.</li>
        <li>The sets $S_i$ are compact.</li>
        <li>For each $i$, the set $S_i$ is contained in an element of $\mathcal{A}$.</li>
    </ol>
    </p><hr>

    <p><b>Definition.</b> A of functions $\{ \rho_i\}$ that satisfies Condition 1 to 4 in the previous proposition is called a <b>partition of unity</b>. If it also satisfies Condition 7, we say that it is <b>subordinate to $\mathcal{A}$.</b></p><hr>

    <p>If $\alpha$ is not compactly supported, we pick a partition of unity $\{ \rho_i \}$ such that each $\rho_i$ is compactly supported. We can then define $\int \alpha = \sum_i \int \rho_i \alpha$.</p>

    <p>This trick only works if the integral converges absolutely. That is, if $\int |f(\ve{x})|\, \dee x^1 \dee x^2 \dotsb \dee x^n$ converges as a Riemann integral, then everything works out.</p>
    <hr>    

    <h2>5 &nbsp; Differential Forms on Manifolds</h2>

    <p><b>Definition.</b> Let $k > 0$. A subset $M$ of $\Real^n$ is called a <b>$k$-dimensional manifold of class $C^r$ without boundary</b> if the following property holds:  for each $\ve{p} \in M$, there is a set $V \subseteq M$ containing $\ve{p}$ that is open in $M$, a set $U$ that is open in $\Real^k$, and a bijection $\psi: U \rightarrow V$ such that:
    <ul>
        <li>$\psi$ is $C^r$.</li>
        <li>$\psi^{-1}: V \rightarrow U$ is continuous.</li>
        <li>$D\psi(\ve{x})$ has rank $k$ for each $\ve{x} \in U$.</li>
    </ul>
    The map $\psi$ is called a <b>coordinate patch</b> on $M$ about $\ve{p}$.
    </p><hr>

    <p><b>Definition.</b> The <b>half space</b> is the set $\mathbb{H}^k = \{ \ve{x} \in \Real^k : x_k \geq 0 \}$.</p>

    <p>Also, define $\mathbb{H}^k_+ = \{ \ve{x} \in \Real^k : x_k > 0 \}$.</p><hr>

    <p><b>Definition.</b> Let $k > 0$. A subset $M$ of $\Real^n$ is called a <b>$k$-dimensional manifold of class $C^r$</b> if the following property holds:  for each $\ve{p} \in M$, there is a set $V \subseteq M$ containing $\ve{p}$ that is open in $M$, a set $U$ that is open in $\Real^k$ or $\mathbb{H}^k$, and a bijection $\psi: U \rightarrow V$ such that:
    <ul>
        <li>$\psi$ is $C^r$.</li>
        <li>$\psi^{-1}: V \rightarrow U$ is continuous.</li>
        <li>$D\psi(\ve{x})$ has rank $k$ for each $\ve{x} \in U$.</li>
    </ul>    
    </p><hr>

    <p><b>Proposition.</b> Let $M$ be a $k$-manifold in $\Real^n$ of class $C^r$. Let $\psi_0: U_0 \rightarrow V_0$ and $\psi_1: U_1 \rightarrow V_1$ be coordinates patches in $M$, with $W = V_0 \cap V_1$ non-empty. We $W_i = \psi_i^{-1}(W)$. Then the map $\psi_1^{-1} \circ \psi_0: W_0 \rightarrow W_1$ is of class $C^r$, and its derivative is non-singular.</p>

    <p>We call $\psi_1^{-1} \circ \psi_0$ the <b>transition function</b> between coordinate patches $\psi_0$ and $\psi_1$.</p>
    <hr>

    <p><b>Definition.</b> Let $M$ be a $k$-manifold in $\Real^n$. Let $\ve{p} \in M$. If there is a coordinate patch $\psi: U \rightarrow V$ on $M$ about $\ve{p}$ such that $U$ is open in $\Real^k$, we say that $\ve{p}$ is an <b>interior point</b> of $M$. Otherwise, we say that $\ve{p}$ is a <b>boundary point</b>.

    <p>We denote the set of boundary points of $M$ with $\partial M$.</p><hr>

    <p>It can be shown that a boundary point in $M$ are those points $\ve{p}$ such that $\ve{p} = \psi(\ve{x}_0)$ where $\ve{x}_0 \in \Real^{k-1} \times \{ 0 \}$. Here, $\psi$ is a coordinate patch about $\ve{p}$.</p><hr>

    <p><b>Definition.</b> Let $\ve{g}: A \rightarrow B$ be a diffeomorphidm of open sets in $\Real^k$. We say that $\ve{g}$ is <b>orientation-preserving</b> if $\det D\ve{g} > 0$ on $A$. We say $\ve{g}$ is <b>orientation-reversing</b> if $\det D\ve{g} < 0$ on $A$.</p><hr>

    <p><b>Definition.</b> Let $M$ be a $k$-manifold in $\Real^n$. Given coordinate patches $\psi_i: U_i \rightarrow V_i$ on $M$ for $i = 0,1$. We say they <b>overlap</b> if $V_0 \cap V_1$ is not empty. We way they <b>overlap positively</b> if the transition function $\psi^{-1}_1 \circ \psi_0$ is orientation preserving. If $M$ can be ocvered by a collection of coordinate patches, each pair of which overlap positively (if they overlap at all), then $M$ is said to be <b>orientable</b>. Otherwise, $M$ is said to be <b>non-orientable</b>.</p><hr>

    <p><b>Definition.</b> Let $M$ be a $k$-manifold in $\Real^n$. Suppose $M$ is orientable. Given a collection of coordinate patches covering $M$ that overlap positively, we add to this collection all the coordinat patches that overlap with these patches positively. This expanded collection is called an <b>orientation</b> of $M$. A manifold $M$ together with an orienation of $M$ is called an <b>oriented manifold.</b></p><hr>

    <p><b>Definition.</b> Let $M$ be a compact oriented $k$-manifold in $\Real^n$. Let $\omega$ be a $k$-form defined in an open set of $\Real^n$ containing $M$. Let $C = M \cap (\mathrm{Support}\ \omega)$. We know that $C$ is compact. Suppose there is a coordinate patch $\psi: U \rightarrow V$ on $M$ belonging to the orientation of $M$ such that $C \subseteq V$. By replacing $U$ by a smaller open set if necessary, we may assume that $U$ is bounded. We define the <b>integral of $\omega$ over $V$</b> by the equation:
    \begin{align*}
        \int_M \omega = \int_{\mathrm{Int}\ U} \psi^* \omega
    \end{align*}
    where $\mathrm{Int}\ U = U$ if $U$ is open in $\Real^n$, and $\mathrm{Int} U = U \cap \mathcal{H}^k_+$ if $U$ is open in $\mathcal{H}^k$ but not in $\Real^k$.
    </p><hr>

    <p>Note that we can show that the value of the integral does not depend on the choice of the coordinate patch. This is because (1) there would be transition function that would do the change of variable, and (2) the patches come from the same orientation, and so the determinant of the Jacobian of the transition function would always be positive.</p><hr>

    <p>If a form is not supported in a single coordinate patch, we do the following construction. For each point $\ve{p}$ in $M$, we identify a coordinate patch $\psi_{\ve{p}}: U_\ve{p} \rightarrow V_{\ve{p}}$ in the orientation. We have that $\{V_{\ve{p}}\}$ is a collection of open sets in $M$. We can then pick a partion of unity $\{ \rho_i \}$ subordinate to $\{V_{\ve{p}}\}$. Then, we can define
    \begin{align*}
        \int_M \omega = \sum_{i} \int_{\mathrm{Int}\ U_i} \rho_i \omega.
    \end{align*}
    This definition makes sense only if the form is <b>absolutely integrable.</b> In other words, for a form $\omega = f(\ve{x})\, dx^I$, let $|\omega| = |f(\ve{x})|\, dx^I$. We say that $\omega$ is absolutely integrable if each $|\psi_i^*(\rho_i \omega)|$ is integrable over $\mathrm{Int}\ U_i$.
    </p><hr>

    <p><b>Definition. </b> Let $M$ be an orientable $k$-manifold with non-empty boundary. Given an orientation of $M$, the corresponding <b>induced orientation</b> of $\partial M$< is defined as follows. If $k$ is even, it is the orientation obtained by simply restricting coordinate patches belonging to the orientation of $M$. If $k$ is odd, it is the opposiate of the orientation of $\partial M$ obtained this way.</p><hr>

    <p><b>Theorem (Generalized Stokes's).</b> Let $k \geq 1$. Let $M$ be a compact oriented $k$-manifold in $\Real^n$. Give $\partial M$ the induced orientation if $\partial M$ is not empty. Let $\omega$ be a $(k-1)$-form defined in an open set of $\Real^n$ containing $M$. Then
    \begin{align*}
        \int_M\, \dee\omega = \int_{\partial M} \omega
    \end{align*}
    if $\partial M$ is not empty, and $\int_M\, \dee\omega = 0$ if $\omega M$ is empty.
    </p><hr>

    <p><b>Example.</b> Let $\gamma$ be an oriented path in $\Real^3$. This means that there is a function $\ve{g}: (a,b) \rightarrow \Real^3$. Let $t$ denote the argument of $\ve{g}$. We have that
    \begin{align*}
        \dee x^1 &= \frac{\partial g_1}{\partial t}\, \dee t, &
        \dee x^2 &= \frac{\partial g_2}{\partial t}\, \dee t, &
        \dee x^3 &= \frac{\partial g_3}{\partial t}\, \dee t.
    \end{align*}
    Let $\ve{v}(\ve{x})$ be a vector field. We have that
    \begin{align*}
        w^1_\ve{x} = v_1(\ve{x})\, \dee x^1 + v_2(\ve{x})\, \dee x^2 + v_3(\ve{x})\, \dee x^3.
    \end{align*}
    We have that
    \begin{align*}
        \int_{\gamma} w^1_\ve{v}
        &= \int_a^b \ve{g}^*(w^1_\ve{v}) \\
        &= \int_{\gamma} \ve{g}^*\big( v_1(\ve{x})\, \dee x^1 + v_2(\ve{x})\, \dee x^2 + v_3(\ve{x})\, \dee x^3 \big) \\
        &= \int_a^b 
        v_1(\ve{g}(t)) \frac{\partial g_1}{\partial t}\, \dee t
        + v_2(\ve{g}(t)) \frac{\partial g_2}{\partial t}\, \dee t
        + v_3(\ve{g}(t)) \frac{\partial g_3}{\partial t}\, \dee t \\
        &= \int_a^b \ve{v}(\ve{g}(t)) \cdot \frac{\partial \ve{g}(t)}{\partial t}\, \dee t.
    \end{align*}
    Let $\ve{t}(t)$ denote the unit tangent vector to the curve at time $t$. In other words:
    \begin{align*}
        \ve{t}(t) = \frac{1}{\| \partial \ve{g}(t) / \partial t \|} \frac{\partial \ve{g}(t)}{\partial t}.
    \end{align*}
    The arc length measure $\dee s$ is given by:
    \begin{align*}
        \dee s = \bigg\| \frac{\partial \ve{g}(t)}{\partial t} \bigg\|\, \dee t.
    \end{align*}
    So,
    \begin{align*}
        \int_{\gamma} w^1_\ve{v}
        = \int_a^b \bigg( \ve{v}(\ve{g}(t)) \cdot \ve{t}(t) \bigg\| \frac{\partial \ve{g}(t)}{\partial t} \bigg\|\bigg) \, \dee t
        = \int_a^b \big( \ve{v}(\ve{g}(t)) \cdot \ve{t}(t)\big)\, \dee s
        = \int_\gamma \ve{v} \cdot \ve{t}\, \dee s.
    \end{align*}
    </p>    
    <hr> 

    <p><b>Example.</b> Let's get back to the 1-form $\omega = (x\,\dee y - y\,\dee x) / (x^2 + y^2)$. We know that $\dee \omega = 0$. However, we said earlier that it is not exact. That is, there is no $\nu$ such that $\omega = \dee\nu$. To see this, let us assume that it exists. Because $\omega$ is a 1-form, $\nu$ would be a 0-form, basically a function $\nu: \Real^2 \rightarrow \Real$. So, for any oriented path $\gamma$ that starts from point $\ve{a}$ and ends at point $\ve{b}$, we have that
    \begin{align*}
        \int_{\gamma} \omega = \int_{\gamma} \dee\nu = \int_{\partial \gamma} \nu = \nu(\ve{b}) - \nu(\ve{a}).
    \end{align*}
    That is, the path integral involving $\omega$ would exhibit path independence. However, it is easy to find two paths that would result in different values with $\omega$. For example, consider (a) a path that goes straight from $(1,0)$ to $(100,0)$ and (b) another path that goes from $(1,0)$ to $(1,100)$ then to $(100,100)$ and then to $(100,0)$. The first path's integral is $0$, but the second is not.
    </p>
    <hr>

    <div class="page-header"></div>
    <p>Last modified: 2021/02/15</p>    
</div>

<script type="text/javascript">
$.bigfoot();
</script>

</body>
</html>


